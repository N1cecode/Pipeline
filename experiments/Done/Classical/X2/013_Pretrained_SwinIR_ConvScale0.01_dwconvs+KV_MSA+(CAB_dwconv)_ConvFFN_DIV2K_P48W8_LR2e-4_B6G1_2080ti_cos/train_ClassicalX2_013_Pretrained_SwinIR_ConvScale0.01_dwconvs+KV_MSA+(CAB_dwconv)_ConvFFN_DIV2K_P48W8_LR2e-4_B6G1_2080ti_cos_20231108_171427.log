2023-11-08 17:14:27,968 INFO: 
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-11-08 17:14:27,969 INFO: 
  name: ClassicalX2_013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
  model_type: SwinIRModel
  scale: 2
  num_gpu: 1
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: ./datasets/BSDS100/GTmod12
      dataroot_lq: ./datasets/BSDS100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: ./datasets/urban100/GTmod12
      dataroot_lq: ./datasets/urban100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: ./datasets/manga109/GTmod12
      dataroot_lq: ./datasets/manga109/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR_Modified
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    conv_scale: 0.01
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_30000.pth
    strict_load_g: False
    resume_state: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/training_states/30000.state
    experiments_root: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
    models: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights
    training_states: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/training_states
    log: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
    visualization: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/visualization
    tb_logger: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/tb_logger
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.001
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [100000, 100000, 100000, 100000, 100000]
      restart_weights: [1, 0.5, 0.5, 0.5, 0.25]
    ]
    total_iter: 500000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao

2023-11-08 17:14:40,180 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-11-08 17:14:40,181 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 1
	Require iter number per epoch: 5432
	Total epochs: 93; iters: 500000.
2023-11-08 17:14:40,183 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-11-08 17:14:40,183 INFO: Number of val images/folders in Set5: 5
2023-11-08 17:14:40,187 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-11-08 17:14:40,187 INFO: Number of val images/folders in Set14: 14
2023-11-08 17:14:40,196 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-11-08 17:14:40,197 INFO: Number of val images/folders in BSD100: 100
2023-11-08 17:14:40,205 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-11-08 17:14:40,205 INFO: Number of val images/folders in Urban100: 100
2023-11-08 17:14:40,214 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-11-08 17:14:40,214 INFO: Number of val images/folders in Manga109: 109
2023-11-08 17:14:47,072 INFO: Network: SwinIR_Modified, with parameters: 12,267,593
2023-11-08 17:14:47,072 INFO: SwinIR_Modified(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-11-08 17:14:48,466 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_30000.pth, with param key: [params].
2023-11-08 17:14:50,317 INFO: Use Exponential Moving Average with decay: 0.999
2023-11-08 17:14:50,591 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_30000.pth, with param key: [params_ema].
2023-11-08 17:14:51,910 INFO: Loss [L1Loss] is created.
2023-11-08 17:14:51,910 WARNING: Params edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-11-08 17:14:51,910 WARNING: Params edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-11-08 17:14:51,922 INFO: Model [SwinIRModel] is created.
2023-11-08 17:14:52,297 INFO: Resuming training from epoch: 4, iter: 30000.
2023-11-08 17:14:53,038 INFO: Start training from epoch: 4, iter: 30000
2023-11-08 17:16:01,265 INFO: [Class..][epoch:  4, iter:  30,100, lr:(7.926e-04,)] [eta: 3 days, 17:07:40, time (data): 0.682 (0.018)] l_pix: 1.4682e-02 
2023-11-08 17:17:02,930 INFO: [Class..][epoch:  4, iter:  30,200, lr:(7.914e-04,)] [eta: 3 days, 12:48:46, time (data): 0.649 (0.011)] l_pix: 1.5736e-02 
2023-11-08 17:18:02,003 INFO: [Class..][epoch:  4, iter:  30,300, lr:(7.901e-04,)] [eta: 3 days, 10:13:46, time (data): 0.591 (0.003)] l_pix: 1.2155e-02 
2023-11-08 17:19:01,322 INFO: [Class..][epoch:  4, iter:  30,400, lr:(7.888e-04,)] [eta: 3 days, 9:00:24, time (data): 0.592 (0.003)] l_pix: 1.1008e-02 
2023-11-08 17:20:00,094 INFO: [Class..][epoch:  4, iter:  30,500, lr:(7.875e-04,)] [eta: 3 days, 8:07:22, time (data): 0.587 (0.003)] l_pix: 1.7255e-02 
2023-11-08 17:20:59,908 INFO: [Class..][epoch:  4, iter:  30,600, lr:(7.862e-04,)] [eta: 3 days, 7:45:13, time (data): 0.593 (0.003)] l_pix: 1.5576e-02 
2023-11-08 17:22:01,000 INFO: [Class..][epoch:  4, iter:  30,700, lr:(7.849e-04,)] [eta: 3 days, 7:43:23, time (data): 0.610 (0.003)] l_pix: 1.6109e-02 
2023-11-08 17:23:00,170 INFO: [Class..][epoch:  4, iter:  30,800, lr:(7.836e-04,)] [eta: 3 days, 7:22:58, time (data): 0.601 (0.003)] l_pix: 1.6109e-02 
2023-11-08 17:23:57,386 INFO: [Class..][epoch:  4, iter:  30,900, lr:(7.824e-04,)] [eta: 3 days, 6:49:56, time (data): 0.572 (0.002)] l_pix: 1.5869e-02 
2023-11-08 17:24:53,830 INFO: [Class..][epoch:  4, iter:  31,000, lr:(7.811e-04,)] [eta: 3 days, 6:17:16, time (data): 0.568 (0.003)] l_pix: 1.8960e-02 
2023-11-08 17:25:52,207 INFO: [Class..][epoch:  4, iter:  31,100, lr:(7.798e-04,)] [eta: 3 days, 6:04:04, time (data): 0.584 (0.003)] l_pix: 2.1200e-02 
2023-11-08 17:26:50,488 INFO: [Class..][epoch:  4, iter:  31,200, lr:(7.785e-04,)] [eta: 3 days, 5:52:18, time (data): 0.584 (0.003)] l_pix: 1.8443e-02 
2023-11-08 17:27:49,069 INFO: [Class..][epoch:  4, iter:  31,300, lr:(7.771e-04,)] [eta: 3 days, 5:43:59, time (data): 0.581 (0.003)] l_pix: 1.8951e-02 
2023-11-08 17:28:48,187 INFO: [Class..][epoch:  4, iter:  31,400, lr:(7.758e-04,)] [eta: 3 days, 5:39:43, time (data): 0.586 (0.003)] l_pix: 9.1402e-03 
2023-11-08 17:29:46,422 INFO: [Class..][epoch:  4, iter:  31,500, lr:(7.745e-04,)] [eta: 3 days, 5:31:17, time (data): 0.582 (0.003)] l_pix: 1.7019e-02 
2023-11-08 17:30:47,408 INFO: [Class..][epoch:  4, iter:  31,600, lr:(7.732e-04,)] [eta: 3 days, 5:37:12, time (data): 0.596 (0.003)] l_pix: 1.3743e-02 
2023-11-08 17:31:45,433 INFO: [Class..][epoch:  4, iter:  31,700, lr:(7.719e-04,)] [eta: 3 days, 5:28:44, time (data): 0.579 (0.003)] l_pix: 2.5061e-02 
2023-11-08 17:32:43,460 INFO: [Class..][epoch:  4, iter:  31,800, lr:(7.706e-04,)] [eta: 3 days, 5:21:05, time (data): 0.579 (0.003)] l_pix: 1.2361e-02 
2023-11-08 17:33:42,967 INFO: [Class..][epoch:  4, iter:  31,900, lr:(7.693e-04,)] [eta: 3 days, 5:20:14, time (data): 0.594 (0.003)] l_pix: 1.2948e-02 
2023-11-08 17:34:37,753 INFO: [Class..][epoch:  4, iter:  32,000, lr:(7.679e-04,)] [eta: 3 days, 5:00:57, time (data): 0.570 (0.003)] l_pix: 1.4199e-02 
2023-11-08 17:35:37,284 INFO: [Class..][epoch:  4, iter:  32,100, lr:(7.666e-04,)] [eta: 3 days, 5:01:02, time (data): 0.594 (0.003)] l_pix: 1.4651e-02 
2023-11-08 17:36:36,146 INFO: [Class..][epoch:  4, iter:  32,200, lr:(7.653e-04,)] [eta: 3 days, 4:58:38, time (data): 0.591 (0.003)] l_pix: 2.6476e-02 
2023-11-08 17:37:34,904 INFO: [Class..][epoch:  4, iter:  32,300, lr:(7.639e-04,)] [eta: 3 days, 4:56:01, time (data): 0.589 (0.003)] l_pix: 9.7155e-03 
2023-11-08 17:38:33,782 INFO: [Class..][epoch:  4, iter:  32,400, lr:(7.626e-04,)] [eta: 3 days, 4:53:56, time (data): 0.589 (0.003)] l_pix: 2.1791e-02 
2023-11-08 17:39:32,352 INFO: [Class..][epoch:  4, iter:  32,500, lr:(7.613e-04,)] [eta: 3 days, 4:50:58, time (data): 0.587 (0.003)] l_pix: 1.3977e-02 
2023-11-08 17:40:31,744 INFO: [Class..][epoch:  4, iter:  32,600, lr:(7.599e-04,)] [eta: 3 days, 4:50:38, time (data): 0.591 (0.003)] l_pix: 1.9644e-02 
2023-11-08 17:41:30,129 INFO: [Class..][epoch:  4, iter:  32,700, lr:(7.586e-04,)] [eta: 3 days, 4:47:20, time (data): 0.582 (0.003)] l_pix: 7.5200e-03 
2023-11-08 17:42:29,502 INFO: [Class..][epoch:  4, iter:  32,800, lr:(7.572e-04,)] [eta: 3 days, 4:46:57, time (data): 0.588 (0.003)] l_pix: 2.1001e-02 
2023-11-08 17:43:27,557 INFO: [Class..][epoch:  4, iter:  32,900, lr:(7.559e-04,)] [eta: 3 days, 4:42:59, time (data): 0.582 (0.002)] l_pix: 2.4226e-02 
2023-11-08 17:44:25,899 INFO: [Class..][epoch:  4, iter:  33,000, lr:(7.545e-04,)] [eta: 3 days, 4:39:57, time (data): 0.583 (0.003)] l_pix: 2.3219e-02 
2023-11-08 17:45:23,361 INFO: [Class..][epoch:  4, iter:  33,100, lr:(7.532e-04,)] [eta: 3 days, 4:34:52, time (data): 0.575 (0.003)] l_pix: 2.4404e-02 
2023-11-08 17:46:22,172 INFO: [Class..][epoch:  4, iter:  33,200, lr:(7.518e-04,)] [eta: 3 days, 4:33:18, time (data): 0.582 (0.003)] l_pix: 1.6921e-02 
2023-11-08 17:47:20,583 INFO: [Class..][epoch:  4, iter:  33,300, lr:(7.505e-04,)] [eta: 3 days, 4:30:50, time (data): 0.584 (0.003)] l_pix: 1.9644e-02 
2023-11-08 17:48:18,368 INFO: [Class..][epoch:  4, iter:  33,400, lr:(7.491e-04,)] [eta: 3 days, 4:27:01, time (data): 0.581 (0.003)] l_pix: 1.3712e-02 
2023-11-08 17:49:16,382 INFO: [Class..][epoch:  4, iter:  33,500, lr:(7.477e-04,)] [eta: 3 days, 4:23:53, time (data): 0.580 (0.003)] l_pix: 2.0508e-02 
2023-11-08 17:50:13,971 INFO: [Class..][epoch:  4, iter:  33,600, lr:(7.464e-04,)] [eta: 3 days, 4:19:57, time (data): 0.578 (0.003)] l_pix: 1.2328e-02 
2023-11-08 17:51:11,935 INFO: [Class..][epoch:  4, iter:  33,700, lr:(7.450e-04,)] [eta: 3 days, 4:16:58, time (data): 0.579 (0.003)] l_pix: 2.4636e-02 
2023-11-08 17:52:09,808 INFO: [Class..][epoch:  4, iter:  33,800, lr:(7.436e-04,)] [eta: 3 days, 4:13:54, time (data): 0.579 (0.003)] l_pix: 1.5120e-02 
2023-11-08 17:53:07,692 INFO: [Class..][epoch:  4, iter:  33,900, lr:(7.423e-04,)] [eta: 3 days, 4:10:58, time (data): 0.573 (0.003)] l_pix: 1.9115e-02 
2023-11-08 17:54:05,171 INFO: [Class..][epoch:  4, iter:  34,000, lr:(7.409e-04,)] [eta: 3 days, 4:07:20, time (data): 0.574 (0.003)] l_pix: 1.5966e-02 
2023-11-08 17:55:03,322 INFO: [Class..][epoch:  4, iter:  34,100, lr:(7.395e-04,)] [eta: 3 days, 4:05:07, time (data): 0.581 (0.003)] l_pix: 1.0700e-02 
2023-11-08 17:56:00,846 INFO: [Class..][epoch:  4, iter:  34,200, lr:(7.381e-04,)] [eta: 3 days, 4:01:47, time (data): 0.578 (0.003)] l_pix: 1.2793e-02 
2023-11-08 17:56:58,132 INFO: [Class..][epoch:  4, iter:  34,300, lr:(7.368e-04,)] [eta: 3 days, 3:58:09, time (data): 0.569 (0.003)] l_pix: 9.2705e-03 
2023-11-08 17:57:55,720 INFO: [Class..][epoch:  4, iter:  34,400, lr:(7.354e-04,)] [eta: 3 days, 3:55:10, time (data): 0.573 (0.003)] l_pix: 7.3016e-03 
2023-11-08 17:58:53,681 INFO: [Class..][epoch:  4, iter:  34,500, lr:(7.340e-04,)] [eta: 3 days, 3:52:55, time (data): 0.577 (0.003)] l_pix: 1.6792e-02 
2023-11-08 17:59:51,659 INFO: [Class..][epoch:  4, iter:  34,600, lr:(7.326e-04,)] [eta: 3 days, 3:50:45, time (data): 0.579 (0.003)] l_pix: 1.9250e-02 
2023-11-08 18:00:50,157 INFO: [Class..][epoch:  4, iter:  34,700, lr:(7.312e-04,)] [eta: 3 days, 3:49:29, time (data): 0.590 (0.004)] l_pix: 1.3698e-02 
2023-11-08 18:01:46,938 INFO: [Class..][epoch:  4, iter:  34,800, lr:(7.298e-04,)] [eta: 3 days, 3:45:28, time (data): 0.577 (0.003)] l_pix: 1.0788e-02 
2023-11-08 18:02:45,223 INFO: [Class..][epoch:  4, iter:  34,900, lr:(7.284e-04,)] [eta: 3 days, 3:43:57, time (data): 0.586 (0.003)] l_pix: 1.6136e-02 
2023-11-08 18:03:42,931 INFO: [Class..][epoch:  4, iter:  35,000, lr:(7.270e-04,)] [eta: 3 days, 3:41:33, time (data): 0.581 (0.003)] l_pix: 1.2729e-02 
2023-11-08 18:03:42,932 INFO: Saving models and training states.
2023-11-08 18:03:45,515 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-08 18:03:57,847 INFO: Validation Set5
	 # psnr: 37.2961	Best: 37.2961 @ 35000 iter
	 # ssim: 0.9587	Best: 0.9587 @ 35000 iter

2023-11-08 18:04:46,486 INFO: Validation Set14
	 # psnr: 33.0150	Best: 33.0150 @ 35000 iter
	 # ssim: 0.9134	Best: 0.9134 @ 35000 iter

2023-11-08 18:09:12,085 INFO: Validation BSD100
	 # psnr: 31.8263	Best: 31.8263 @ 35000 iter
	 # ssim: 0.8964	Best: 0.8964 @ 35000 iter

2023-11-08 18:21:15,857 INFO: Validation Urban100
	 # psnr: 30.7548	Best: 30.7548 @ 35000 iter
	 # ssim: 0.9148	Best: 0.9148 @ 35000 iter

2023-11-08 18:34:51,552 INFO: Validation Manga109
	 # psnr: 37.0362	Best: 37.0362 @ 35000 iter
	 # ssim: 0.9736	Best: 0.9736 @ 35000 iter

2023-11-08 18:35:50,142 INFO: [Class..][epoch:  4, iter:  35,100, lr:(7.256e-04,)] [eta: 5 days, 2:58:58, time (data): 0.584 (0.003)] l_pix: 1.3847e-02 
2023-11-08 18:36:50,209 INFO: [Class..][epoch:  4, iter:  35,200, lr:(7.242e-04,)] [eta: 5 days, 2:05:00, time (data): 0.593 (0.003)] l_pix: 1.1991e-02 
2023-11-08 18:37:49,419 INFO: [Class..][epoch:  4, iter:  35,300, lr:(7.228e-04,)] [eta: 5 days, 1:11:46, time (data): 0.589 (0.003)] l_pix: 1.8055e-02 
2023-11-08 18:38:48,420 INFO: [Class..][epoch:  4, iter:  35,400, lr:(7.214e-04,)] [eta: 5 days, 0:20:11, time (data): 0.589 (0.003)] l_pix: 1.0717e-02 
2023-11-08 18:39:50,452 INFO: [Class..][epoch:  5, iter:  35,500, lr:(7.200e-04,)] [eta: 4 days, 23:34:43, time (data): 0.637 (0.039)] l_pix: 1.7754e-02 
