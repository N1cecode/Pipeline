2023-11-08 15:48:15,783 INFO: 
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-11-08 15:48:15,784 INFO: 
  name: ClassicalX2_013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
  model_type: SwinIRModel
  scale: 2
  num_gpu: 1
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: ./datasets/BSDS100/GTmod12
      dataroot_lq: ./datasets/BSDS100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: ./datasets/urban100/GTmod12
      dataroot_lq: ./datasets/urban100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: ./datasets/manga109/GTmod12
      dataroot_lq: ./datasets/manga109/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR_Modified
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    conv_scale: 0.01
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_25000.pth
    strict_load_g: False
    resume_state: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/training_states/25000.state
    experiments_root: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
    models: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights
    training_states: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/training_states
    log: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos
    visualization: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/visualization
    tb_logger: /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/tb_logger
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.001
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [100000, 100000, 100000, 100000, 100000]
      restart_weights: [1, 0.5, 0.5, 0.5, 0.25]
    ]
    total_iter: 500000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao

2023-11-08 15:48:26,122 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-11-08 15:48:26,123 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 1
	Require iter number per epoch: 5432
	Total epochs: 93; iters: 500000.
2023-11-08 15:48:26,124 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-11-08 15:48:26,125 INFO: Number of val images/folders in Set5: 5
2023-11-08 15:48:26,126 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-11-08 15:48:26,126 INFO: Number of val images/folders in Set14: 14
2023-11-08 15:48:26,133 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-11-08 15:48:26,133 INFO: Number of val images/folders in BSD100: 100
2023-11-08 15:48:26,140 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-11-08 15:48:26,140 INFO: Number of val images/folders in Urban100: 100
2023-11-08 15:48:26,147 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-11-08 15:48:26,148 INFO: Number of val images/folders in Manga109: 109
2023-11-08 15:48:28,593 INFO: Network: SwinIR_Modified, with parameters: 12,267,593
2023-11-08 15:48:28,594 INFO: SwinIR_Modified(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-11-08 15:48:29,979 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_25000.pth, with param key: [params].
2023-11-08 15:48:31,149 INFO: Use Exponential Moving Average with decay: 0.999
2023-11-08 15:48:31,405 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/013_Pretrained_SwinIR_ConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_B6G1_2080ti_cos/weights/net_g_25000.pth, with param key: [params_ema].
2023-11-08 15:48:33,094 INFO: Loss [L1Loss] is created.
2023-11-08 15:48:33,094 WARNING: Params edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-11-08 15:48:33,094 WARNING: Params edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-11-08 15:48:33,102 INFO: Model [SwinIRModel] is created.
2023-11-08 15:48:33,435 INFO: Resuming training from epoch: 4, iter: 25000.
2023-11-08 15:48:34,176 INFO: Start training from epoch: 4, iter: 25000
2023-11-08 15:49:33,396 INFO: [Class..][epoch:  4, iter:  25,100, lr:(8.525e-04,)] [eta: 3 days, 6:18:46, time (data): 0.592 (0.014)] l_pix: 1.6398e-02 
2023-11-08 15:50:28,347 INFO: [Class..][epoch:  4, iter:  25,200, lr:(8.513e-04,)] [eta: 3 days, 3:24:00, time (data): 0.571 (0.008)] l_pix: 1.6167e-02 
2023-11-08 15:51:24,493 INFO: [Class..][epoch:  4, iter:  25,300, lr:(8.502e-04,)] [eta: 3 days, 2:56:09, time (data): 0.562 (0.003)] l_pix: 1.2613e-02 
2023-11-08 15:52:20,204 INFO: [Class..][epoch:  4, iter:  25,400, lr:(8.491e-04,)] [eta: 3 days, 2:33:08, time (data): 0.559 (0.003)] l_pix: 1.2133e-02 
2023-11-08 15:53:15,975 INFO: [Class..][epoch:  4, iter:  25,500, lr:(8.480e-04,)] [eta: 3 days, 2:19:53, time (data): 0.558 (0.003)] l_pix: 1.9143e-02 
2023-11-08 15:54:11,956 INFO: [Class..][epoch:  4, iter:  25,600, lr:(8.468e-04,)] [eta: 3 days, 2:13:30, time (data): 0.559 (0.002)] l_pix: 1.6095e-02 
2023-11-08 15:55:08,040 INFO: [Class..][epoch:  4, iter:  25,700, lr:(8.457e-04,)] [eta: 3 days, 2:09:50, time (data): 0.561 (0.002)] l_pix: 1.8075e-02 
2023-11-08 15:56:04,207 INFO: [Class..][epoch:  4, iter:  25,800, lr:(8.446e-04,)] [eta: 3 days, 2:07:40, time (data): 0.561 (0.003)] l_pix: 1.5769e-02 
2023-11-08 15:57:00,540 INFO: [Class..][epoch:  4, iter:  25,900, lr:(8.434e-04,)] [eta: 3 days, 2:07:13, time (data): 0.563 (0.003)] l_pix: 1.6058e-02 
2023-11-08 15:57:56,400 INFO: [Class..][epoch:  4, iter:  26,000, lr:(8.423e-04,)] [eta: 3 days, 2:02:57, time (data): 0.561 (0.002)] l_pix: 2.0438e-02 
2023-11-08 15:58:52,176 INFO: [Class..][epoch:  4, iter:  26,100, lr:(8.411e-04,)] [eta: 3 days, 1:58:41, time (data): 0.559 (0.002)] l_pix: 2.2781e-02 
2023-11-08 15:59:47,337 INFO: [Class..][epoch:  4, iter:  26,200, lr:(8.400e-04,)] [eta: 3 days, 1:50:56, time (data): 0.555 (0.002)] l_pix: 1.9669e-02 
2023-11-08 16:00:42,191 INFO: [Class..][epoch:  4, iter:  26,300, lr:(8.388e-04,)] [eta: 3 days, 1:42:22, time (data): 0.546 (0.002)] l_pix: 1.9071e-02 
2023-11-08 16:01:36,635 INFO: [Class..][epoch:  4, iter:  26,400, lr:(8.377e-04,)] [eta: 3 days, 1:32:35, time (data): 0.545 (0.002)] l_pix: 1.0021e-02 
2023-11-08 16:02:31,557 INFO: [Class..][epoch:  4, iter:  26,500, lr:(8.365e-04,)] [eta: 3 days, 1:26:30, time (data): 0.549 (0.002)] l_pix: 1.7110e-02 
2023-11-08 16:03:26,804 INFO: [Class..][epoch:  4, iter:  26,600, lr:(8.354e-04,)] [eta: 3 days, 1:22:39, time (data): 0.551 (0.002)] l_pix: 1.3473e-02 
2023-11-08 16:04:21,624 INFO: [Class..][epoch:  4, iter:  26,700, lr:(8.342e-04,)] [eta: 3 days, 1:17:11, time (data): 0.550 (0.002)] l_pix: 2.5386e-02 
2023-11-08 16:05:16,962 INFO: [Class..][epoch:  4, iter:  26,800, lr:(8.330e-04,)] [eta: 3 days, 1:14:28, time (data): 0.552 (0.002)] l_pix: 1.2330e-02 
2023-11-08 16:06:12,590 INFO: [Class..][epoch:  4, iter:  26,900, lr:(8.318e-04,)] [eta: 3 days, 1:13:10, time (data): 0.555 (0.002)] l_pix: 1.2419e-02 
2023-11-08 16:07:07,850 INFO: [Class..][epoch:  4, iter:  27,000, lr:(8.307e-04,)] [eta: 3 days, 1:10:26, time (data): 0.554 (0.002)] l_pix: 1.5118e-02 
2023-11-08 16:08:03,167 INFO: [Class..][epoch:  4, iter:  27,100, lr:(8.295e-04,)] [eta: 3 days, 1:08:06, time (data): 0.552 (0.002)] l_pix: 1.4624e-02 
2023-11-08 16:08:58,572 INFO: [Class..][epoch:  4, iter:  27,200, lr:(8.283e-04,)] [eta: 3 days, 1:06:12, time (data): 0.553 (0.002)] l_pix: 2.5608e-02 
2023-11-08 16:09:53,855 INFO: [Class..][epoch:  4, iter:  27,300, lr:(8.271e-04,)] [eta: 3 days, 1:03:59, time (data): 0.555 (0.002)] l_pix: 9.3784e-03 
2023-11-08 16:10:49,081 INFO: [Class..][epoch:  4, iter:  27,400, lr:(8.259e-04,)] [eta: 3 days, 1:01:40, time (data): 0.554 (0.002)] l_pix: 2.2081e-02 
2023-11-08 16:11:44,465 INFO: [Class..][epoch:  4, iter:  27,500, lr:(8.247e-04,)] [eta: 3 days, 0:59:58, time (data): 0.550 (0.002)] l_pix: 1.5115e-02 
2023-11-08 16:12:40,217 INFO: [Class..][epoch:  4, iter:  27,600, lr:(8.235e-04,)] [eta: 3 days, 0:59:27, time (data): 0.554 (0.002)] l_pix: 1.8697e-02 
2023-11-08 16:13:36,101 INFO: [Class..][epoch:  4, iter:  27,700, lr:(8.223e-04,)] [eta: 3 days, 0:59:17, time (data): 0.557 (0.002)] l_pix: 7.7578e-03 
2023-11-08 16:14:31,263 INFO: [Class..][epoch:  4, iter:  27,800, lr:(8.211e-04,)] [eta: 3 days, 0:57:02, time (data): 0.554 (0.002)] l_pix: 2.0985e-02 
2023-11-08 16:15:27,138 INFO: [Class..][epoch:  4, iter:  27,900, lr:(8.199e-04,)] [eta: 3 days, 0:56:48, time (data): 0.560 (0.002)] l_pix: 2.4831e-02 
2023-11-08 16:16:23,797 INFO: [Class..][epoch:  4, iter:  28,000, lr:(8.187e-04,)] [eta: 3 days, 0:58:35, time (data): 0.564 (0.002)] l_pix: 1.6756e-02 
2023-11-08 16:17:20,135 INFO: [Class..][epoch:  4, iter:  28,100, lr:(8.175e-04,)] [eta: 3 days, 0:59:22, time (data): 0.565 (0.002)] l_pix: 2.3890e-02 
2023-11-08 16:18:16,119 INFO: [Class..][epoch:  4, iter:  28,200, lr:(8.163e-04,)] [eta: 3 days, 0:59:11, time (data): 0.562 (0.002)] l_pix: 1.6311e-02 
2023-11-08 16:19:11,603 INFO: [Class..][epoch:  4, iter:  28,300, lr:(8.151e-04,)] [eta: 3 days, 0:57:46, time (data): 0.554 (0.002)] l_pix: 2.0001e-02 
2023-11-08 16:20:07,327 INFO: [Class..][epoch:  4, iter:  28,400, lr:(8.139e-04,)] [eta: 3 days, 0:56:56, time (data): 0.556 (0.002)] l_pix: 1.3229e-02 
2023-11-08 16:21:03,678 INFO: [Class..][epoch:  4, iter:  28,500, lr:(8.126e-04,)] [eta: 3 days, 0:57:29, time (data): 0.564 (0.002)] l_pix: 2.0545e-02 
2023-11-08 16:21:58,346 INFO: [Class..][epoch:  4, iter:  28,600, lr:(8.114e-04,)] [eta: 3 days, 0:54:18, time (data): 0.555 (0.002)] l_pix: 1.3357e-02 
2023-11-08 16:22:53,370 INFO: [Class..][epoch:  4, iter:  28,700, lr:(8.102e-04,)] [eta: 3 days, 0:51:59, time (data): 0.547 (0.002)] l_pix: 2.4860e-02 
2023-11-08 16:23:48,872 INFO: [Class..][epoch:  4, iter:  28,800, lr:(8.089e-04,)] [eta: 3 days, 0:50:44, time (data): 0.552 (0.002)] l_pix: 1.4390e-02 
2023-11-08 16:24:44,971 INFO: [Class..][epoch:  4, iter:  28,900, lr:(8.077e-04,)] [eta: 3 days, 0:50:42, time (data): 0.560 (0.002)] l_pix: 2.3042e-02 
2023-11-08 16:25:41,047 INFO: [Class..][epoch:  4, iter:  29,000, lr:(8.065e-04,)] [eta: 3 days, 0:50:35, time (data): 0.561 (0.002)] l_pix: 1.6227e-02 
2023-11-08 16:26:37,520 INFO: [Class..][epoch:  4, iter:  29,100, lr:(8.052e-04,)] [eta: 3 days, 0:51:10, time (data): 0.566 (0.003)] l_pix: 1.2080e-02 
2023-11-08 16:27:35,985 INFO: [Class..][epoch:  4, iter:  29,200, lr:(8.040e-04,)] [eta: 3 days, 0:55:25, time (data): 0.576 (0.003)] l_pix: 1.3420e-02 
2023-11-08 16:28:33,493 INFO: [Class..][epoch:  4, iter:  29,300, lr:(8.027e-04,)] [eta: 3 days, 0:57:40, time (data): 0.575 (0.003)] l_pix: 7.8541e-03 
2023-11-08 16:29:30,167 INFO: [Class..][epoch:  4, iter:  29,400, lr:(8.015e-04,)] [eta: 3 days, 0:58:18, time (data): 0.570 (0.003)] l_pix: 5.9093e-03 
2023-11-08 16:30:28,774 INFO: [Class..][epoch:  4, iter:  29,500, lr:(8.002e-04,)] [eta: 3 days, 1:02:13, time (data): 0.588 (0.003)] l_pix: 1.7298e-02 
2023-11-08 16:31:26,657 INFO: [Class..][epoch:  4, iter:  29,600, lr:(7.990e-04,)] [eta: 3 days, 1:04:42, time (data): 0.583 (0.003)] l_pix: 1.9249e-02 
2023-11-08 16:32:24,912 INFO: [Class..][epoch:  4, iter:  29,700, lr:(7.977e-04,)] [eta: 3 days, 1:07:39, time (data): 0.583 (0.003)] l_pix: 1.4206e-02 
2023-11-08 16:33:22,554 INFO: [Class..][epoch:  4, iter:  29,800, lr:(7.964e-04,)] [eta: 3 days, 1:09:26, time (data): 0.579 (0.003)] l_pix: 1.1042e-02 
2023-11-08 16:34:20,855 INFO: [Class..][epoch:  4, iter:  29,900, lr:(7.952e-04,)] [eta: 3 days, 1:12:09, time (data): 0.578 (0.003)] l_pix: 1.6500e-02 
2023-11-08 16:35:18,695 INFO: [Class..][epoch:  4, iter:  30,000, lr:(7.939e-04,)] [eta: 3 days, 1:14:01, time (data): 0.578 (0.003)] l_pix: 1.3057e-02 
2023-11-08 16:35:18,696 INFO: Saving models and training states.
2023-11-08 16:35:20,762 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-08 16:35:38,703 INFO: Validation Set5
	 # psnr: 37.2262	Best: 37.2262 @ 30000 iter
	 # ssim: 0.9583	Best: 0.9583 @ 30000 iter

2023-11-08 16:36:51,381 INFO: Validation Set14
	 # psnr: 32.9438	Best: 32.9438 @ 30000 iter
	 # ssim: 0.9127	Best: 0.9127 @ 30000 iter

2023-11-08 16:43:53,321 INFO: Validation BSD100
	 # psnr: 31.7784	Best: 31.7784 @ 30000 iter
	 # ssim: 0.8956	Best: 0.8956 @ 30000 iter

2023-11-08 16:57:51,118 INFO: Validation Urban100
	 # psnr: 30.6277	Best: 30.6277 @ 30000 iter
	 # ssim: 0.9130	Best: 0.9130 @ 30000 iter

2023-11-08 17:12:46,303 INFO: Validation Manga109
	 # psnr: 36.8711	Best: 36.8711 @ 30000 iter
	 # ssim: 0.9729	Best: 0.9729 @ 30000 iter

2023-11-08 17:13:43,189 INFO: [Class..][epoch:  4, iter:  30,100, lr:(7.926e-04,)] [eta: 5 days, 10:45:05, time (data): 0.570 (0.003)] l_pix: 1.4811e-02 
