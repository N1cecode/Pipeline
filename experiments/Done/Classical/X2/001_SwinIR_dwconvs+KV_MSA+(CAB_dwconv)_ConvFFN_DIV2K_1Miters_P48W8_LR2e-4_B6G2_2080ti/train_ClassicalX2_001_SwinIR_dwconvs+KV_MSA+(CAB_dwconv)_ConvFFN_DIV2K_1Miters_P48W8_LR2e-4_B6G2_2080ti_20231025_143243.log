2023-10-25 14:32:43,129 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.4.2
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-10-25 14:32:43,129 INFO: 
  name: ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
  model_type: SwinIRModel
  scale: 2
  num_gpu: 2
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: basicsr/data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR_Modified
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_235000.pth
    strict_load_g: True
    resume_state: experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/training_states/235000.state
    experiments_root: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
    models: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models
    training_states: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/training_states
    log: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
    visualization: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/visualization
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [500000, 800000, 900000, 950000]
      gamma: 0.5
    ]
    total_iter: 1000000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  world_size: 2
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao/BasicSR

2023-10-25 14:33:07,840 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-10-25 14:33:07,841 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 2
	Require iter number per epoch: 2716
	Total epochs: 369; iters: 1000000.
2023-10-25 14:33:07,842 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-10-25 14:33:07,843 INFO: Number of val images/folders in Set5: 5
2023-10-25 14:33:07,845 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-10-25 14:33:07,845 INFO: Number of val images/folders in Set14: 14
2023-10-25 14:33:08,271 INFO: Network [SwinIR_Modified] is created.
2023-10-25 14:33:09,226 INFO: Network: DistributedDataParallel - SwinIR_Modified, with parameters: 12,267,593
2023-10-25 14:33:09,226 INFO: SwinIR_Modified(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-10-25 14:33:09,542 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_235000.pth, with param key: [params].
2023-10-25 14:33:09,736 INFO: Use Exponential Moving Average with decay: 0.999
2023-10-25 14:33:10,043 INFO: Network [SwinIR_Modified] is created.
2023-10-25 14:33:10,343 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/BasicSR/experiments/ClassicalX2_001_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_235000.pth, with param key: [params_ema].
2023-10-25 14:33:10,493 INFO: Loss [L1Loss] is created.
2023-10-25 14:33:10,494 WARNING: Params module.edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-10-25 14:33:10,494 WARNING: Params module.edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-10-25 14:33:10,500 INFO: Model [SwinIRModel] is created.
2023-10-25 14:33:10,969 INFO: Resuming training from epoch: 86, iter: 235000.
2023-10-25 14:33:48,059 INFO: Start training from epoch: 86, iter: 235000
2023-10-25 14:35:26,107 INFO: [Class..][epoch: 86, iter: 235,100, lr:(2.000e-04,)] [eta: 11 days, 20:17:07, time (data): 0.980 (0.369)] l_pix: 1.6688e-02 
2023-10-25 14:36:23,302 INFO: [Class..][epoch: 86, iter: 235,200, lr:(2.000e-04,)] [eta: 8 days, 11:16:58, time (data): 0.776 (0.186)] l_pix: 9.2299e-03 
2023-10-25 14:37:20,817 INFO: [Class..][epoch: 86, iter: 235,300, lr:(2.000e-04,)] [eta: 7 days, 8:19:04, time (data): 0.575 (0.002)] l_pix: 1.9345e-02 
2023-10-25 14:38:18,979 INFO: [Class..][epoch: 86, iter: 235,400, lr:(2.000e-04,)] [eta: 6 days, 19:08:11, time (data): 0.578 (0.002)] l_pix: 1.6229e-02 
2023-10-25 14:39:16,393 INFO: [Class..][epoch: 86, iter: 235,500, lr:(2.000e-04,)] [eta: 6 days, 10:53:36, time (data): 0.574 (0.002)] l_pix: 9.3179e-03 
2023-10-25 14:40:14,099 INFO: [Class..][epoch: 86, iter: 235,600, lr:(2.000e-04,)] [eta: 6 days, 5:29:29, time (data): 0.576 (0.002)] l_pix: 1.0545e-02 
2023-10-25 14:41:11,935 INFO: [Class..][epoch: 86, iter: 235,700, lr:(2.000e-04,)] [eta: 6 days, 1:39:55, time (data): 0.578 (0.002)] l_pix: 1.2806e-02 
2023-10-25 14:42:09,758 INFO: [Class..][epoch: 86, iter: 235,800, lr:(2.000e-04,)] [eta: 5 days, 22:47:14, time (data): 0.578 (0.002)] l_pix: 1.4238e-02 
2023-10-25 14:43:09,084 INFO: [Class..][epoch: 86, iter: 235,900, lr:(2.000e-04,)] [eta: 5 days, 20:53:55, time (data): 0.594 (0.011)] l_pix: 1.2286e-02 
2023-10-25 14:44:06,822 INFO: [Class..][epoch: 86, iter: 236,000, lr:(2.000e-04,)] [eta: 5 days, 19:02:49, time (data): 0.585 (0.006)] l_pix: 1.3858e-02 
2023-10-25 14:45:04,977 INFO: [Class..][epoch: 86, iter: 236,100, lr:(2.000e-04,)] [eta: 5 days, 17:36:34, time (data): 0.582 (0.002)] l_pix: 8.8464e-03 
2023-10-25 14:46:03,086 INFO: [Class..][epoch: 86, iter: 236,200, lr:(2.000e-04,)] [eta: 5 days, 16:24:02, time (data): 0.581 (0.002)] l_pix: 1.6154e-02 
2023-10-25 14:47:01,425 INFO: [Class..][epoch: 86, iter: 236,300, lr:(2.000e-04,)] [eta: 5 days, 15:24:44, time (data): 0.583 (0.002)] l_pix: 1.0019e-02 
2023-10-25 14:47:59,412 INFO: [Class..][epoch: 86, iter: 236,400, lr:(2.000e-04,)] [eta: 5 days, 14:30:35, time (data): 0.582 (0.002)] l_pix: 1.2280e-02 
2023-10-25 14:48:56,871 INFO: [Class..][epoch: 86, iter: 236,500, lr:(2.000e-04,)] [eta: 5 days, 13:39:02, time (data): 0.574 (0.002)] l_pix: 1.3955e-02 
2023-10-25 14:49:54,303 INFO: [Class..][epoch: 86, iter: 236,600, lr:(2.000e-04,)] [eta: 5 days, 12:53:35, time (data): 0.574 (0.002)] l_pix: 1.3456e-02 
2023-10-25 14:50:52,088 INFO: [Class..][epoch: 86, iter: 236,700, lr:(2.000e-04,)] [eta: 5 days, 12:16:01, time (data): 0.576 (0.002)] l_pix: 1.4014e-02 
2023-10-25 14:51:50,238 INFO: [Class..][epoch: 86, iter: 236,800, lr:(2.000e-04,)] [eta: 5 days, 11:45:05, time (data): 0.579 (0.002)] l_pix: 1.2427e-02 
2023-10-25 14:52:48,464 INFO: [Class..][epoch: 86, iter: 236,900, lr:(2.000e-04,)] [eta: 5 days, 11:17:49, time (data): 0.583 (0.002)] l_pix: 1.3406e-02 
2023-10-25 14:53:46,762 INFO: [Class..][epoch: 86, iter: 237,000, lr:(2.000e-04,)] [eta: 5 days, 10:53:38, time (data): 0.583 (0.002)] l_pix: 1.3194e-02 
2023-10-25 14:54:45,236 INFO: [Class..][epoch: 86, iter: 237,100, lr:(2.000e-04,)] [eta: 5 days, 10:32:44, time (data): 0.584 (0.002)] l_pix: 9.5495e-03 
2023-10-25 14:55:43,587 INFO: [Class..][epoch: 86, iter: 237,200, lr:(2.000e-04,)] [eta: 5 days, 10:12:55, time (data): 0.584 (0.002)] l_pix: 1.2306e-02 
2023-10-25 14:56:41,799 INFO: [Class..][epoch: 86, iter: 237,300, lr:(2.000e-04,)] [eta: 5 days, 9:53:59, time (data): 0.583 (0.002)] l_pix: 1.4502e-02 
2023-10-25 14:57:40,182 INFO: [Class..][epoch: 86, iter: 237,400, lr:(2.000e-04,)] [eta: 5 days, 9:37:27, time (data): 0.583 (0.002)] l_pix: 9.8183e-03 
2023-10-25 14:58:38,478 INFO: [Class..][epoch: 86, iter: 237,500, lr:(2.000e-04,)] [eta: 5 days, 9:21:43, time (data): 0.584 (0.002)] l_pix: 1.1565e-02 
2023-10-25 14:59:36,963 INFO: [Class..][epoch: 86, iter: 237,600, lr:(2.000e-04,)] [eta: 5 days, 9:08:02, time (data): 0.584 (0.002)] l_pix: 2.1300e-02 
2023-10-25 15:00:35,270 INFO: [Class..][epoch: 86, iter: 237,700, lr:(2.000e-04,)] [eta: 5 days, 8:54:28, time (data): 0.584 (0.002)] l_pix: 1.7112e-02 
2023-10-25 15:02:10,162 INFO: [Class..][epoch: 87, iter: 237,800, lr:(2.000e-04,)] [eta: 5 days, 11:27:43, time (data): 0.779 (0.206)] l_pix: 1.1937e-02 
2023-10-25 15:03:07,781 INFO: [Class..][epoch: 87, iter: 237,900, lr:(2.000e-04,)] [eta: 5 days, 11:07:06, time (data): 0.577 (0.002)] l_pix: 1.0037e-02 
2023-10-25 15:04:05,187 INFO: [Class..][epoch: 87, iter: 238,000, lr:(2.000e-04,)] [eta: 5 days, 10:46:53, time (data): 0.576 (0.002)] l_pix: 1.0248e-02 
2023-10-25 15:05:03,238 INFO: [Class..][epoch: 87, iter: 238,100, lr:(2.000e-04,)] [eta: 5 days, 10:30:34, time (data): 0.581 (0.002)] l_pix: 1.3635e-02 
2023-10-25 15:06:01,394 INFO: [Class..][epoch: 87, iter: 238,200, lr:(2.000e-04,)] [eta: 5 days, 10:15:37, time (data): 0.581 (0.002)] l_pix: 1.0775e-02 
2023-10-25 15:06:59,691 INFO: [Class..][epoch: 87, iter: 238,300, lr:(2.000e-04,)] [eta: 5 days, 10:02:03, time (data): 0.582 (0.002)] l_pix: 8.4193e-03 
2023-10-25 15:07:58,014 INFO: [Class..][epoch: 87, iter: 238,400, lr:(2.000e-04,)] [eta: 5 days, 9:49:19, time (data): 0.582 (0.002)] l_pix: 1.2995e-02 
2023-10-25 15:08:56,292 INFO: [Class..][epoch: 87, iter: 238,500, lr:(2.000e-04,)] [eta: 5 days, 9:37:06, time (data): 0.583 (0.002)] l_pix: 1.3315e-02 
2023-10-25 15:09:54,978 INFO: [Class..][epoch: 87, iter: 238,600, lr:(2.000e-04,)] [eta: 5 days, 9:26:57, time (data): 0.585 (0.002)] l_pix: 1.6535e-02 
2023-10-25 15:10:53,146 INFO: [Class..][epoch: 87, iter: 238,700, lr:(2.000e-04,)] [eta: 5 days, 9:15:31, time (data): 0.582 (0.002)] l_pix: 1.0632e-02 
2023-10-25 15:11:51,846 INFO: [Class..][epoch: 87, iter: 238,800, lr:(2.000e-04,)] [eta: 5 days, 9:06:25, time (data): 0.585 (0.002)] l_pix: 1.2197e-02 
2023-10-25 15:12:50,503 INFO: [Class..][epoch: 87, iter: 238,900, lr:(2.000e-04,)] [eta: 5 days, 8:57:35, time (data): 0.587 (0.002)] l_pix: 1.3860e-02 
2023-10-25 15:13:48,776 INFO: [Class..][epoch: 87, iter: 239,000, lr:(2.000e-04,)] [eta: 5 days, 8:47:56, time (data): 0.585 (0.002)] l_pix: 1.2979e-02 
2023-10-25 15:14:46,300 INFO: [Class..][epoch: 87, iter: 239,100, lr:(2.000e-04,)] [eta: 5 days, 8:36:23, time (data): 0.575 (0.002)] l_pix: 7.6273e-03 
2023-10-25 15:15:43,669 INFO: [Class..][epoch: 87, iter: 239,200, lr:(2.000e-04,)] [eta: 5 days, 8:24:52, time (data): 0.574 (0.002)] l_pix: 1.2439e-02 
2023-10-25 15:16:40,417 INFO: [Class..][epoch: 87, iter: 239,300, lr:(2.000e-04,)] [eta: 5 days, 8:12:01, time (data): 0.569 (0.002)] l_pix: 1.3740e-02 
2023-10-25 15:17:36,979 INFO: [Class..][epoch: 87, iter: 239,400, lr:(2.000e-04,)] [eta: 5 days, 7:59:10, time (data): 0.567 (0.002)] l_pix: 1.2325e-02 
2023-10-25 15:18:33,499 INFO: [Class..][epoch: 87, iter: 239,500, lr:(2.000e-04,)] [eta: 5 days, 7:46:44, time (data): 0.566 (0.002)] l_pix: 1.9491e-02 
2023-10-25 15:19:29,881 INFO: [Class..][epoch: 87, iter: 239,600, lr:(2.000e-04,)] [eta: 5 days, 7:34:25, time (data): 0.565 (0.002)] l_pix: 1.8653e-02 
2023-10-25 15:20:26,421 INFO: [Class..][epoch: 87, iter: 239,700, lr:(2.000e-04,)] [eta: 5 days, 7:23:01, time (data): 0.566 (0.002)] l_pix: 1.6372e-02 
2023-10-25 15:21:23,048 INFO: [Class..][epoch: 87, iter: 239,800, lr:(2.000e-04,)] [eta: 5 days, 7:12:16, time (data): 0.566 (0.002)] l_pix: 1.3473e-02 
2023-10-25 15:22:20,126 INFO: [Class..][epoch: 87, iter: 239,900, lr:(2.000e-04,)] [eta: 5 days, 7:03:06, time (data): 0.569 (0.002)] l_pix: 8.5169e-03 
2023-10-25 15:23:16,445 INFO: [Class..][epoch: 87, iter: 240,000, lr:(2.000e-04,)] [eta: 5 days, 6:52:20, time (data): 0.565 (0.002)] l_pix: 1.3576e-02 
2023-10-25 15:23:16,445 INFO: Saving models and training states.
2023-10-25 15:23:37,771 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-10-25 15:23:42,014 INFO: Validation Set5
	 # psnr: 38.2232	Best: 38.2232 @ 240000 iter
	 # ssim: 0.9620	Best: 0.9620 @ 240000 iter

2023-10-25 15:24:02,821 INFO: Validation Set14
	 # psnr: 34.0160	Best: 34.0160 @ 240000 iter
	 # ssim: 0.9214	Best: 0.9214 @ 240000 iter

2023-10-25 15:24:59,470 INFO: [Class..][epoch: 87, iter: 240,100, lr:(2.000e-04,)] [eta: 5 days, 8:37:55, time (data): 0.568 (0.002)] l_pix: 8.3411e-03 
2023-10-25 15:25:56,150 INFO: [Class..][epoch: 87, iter: 240,200, lr:(2.000e-04,)] [eta: 5 days, 8:26:32, time (data): 0.567 (0.002)] l_pix: 1.4505e-02 
2023-10-25 15:26:52,801 INFO: [Class..][epoch: 87, iter: 240,300, lr:(2.000e-04,)] [eta: 5 days, 8:15:28, time (data): 0.566 (0.002)] l_pix: 1.1038e-02 
2023-10-25 15:27:50,326 INFO: [Class..][epoch: 87, iter: 240,400, lr:(2.000e-04,)] [eta: 5 days, 8:06:50, time (data): 0.571 (0.002)] l_pix: 1.3468e-02 
