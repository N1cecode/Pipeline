2023-11-24 06:40:42,352 INFO: 
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-11-24 06:40:42,352 INFO: 
  name: ClassicalX2_016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti
  model_type: SwinIRModel
  scale: 2
  num_gpu: 1
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: datasets/BSDS100/GTmod12
      dataroot_lq: datasets/BSDS100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: datasets/urban100/GTmod12
      dataroot_lq: datasets/urban100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: datasets/manga109/GTmod12
      dataroot_lq: datasets/manga109/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR_Modified
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    conv_scale: 0.01
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/weights/net_g_150000.pth
    strict_load_g: False
    resume_state: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/training_states/150000.state
    experiments_root: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti
    models: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/weights
    training_states: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/training_states
    log: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti
    visualization: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/visualization
    tb_logger: /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/tb_logger
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [100000, 100000, 100000, 100000, 100000]
      restart_weights: [1, 0.5, 0.5, 0.5, 0.25]
    ]
    total_iter: 500000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 10000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 10000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao

2023-11-24 06:40:44,490 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-11-24 06:40:44,491 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 1
	Require iter number per epoch: 5432
	Total epochs: 93; iters: 500000.
2023-11-24 06:40:44,491 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-11-24 06:40:44,491 INFO: Number of val images/folders in Set5: 5
2023-11-24 06:40:44,492 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-11-24 06:40:44,492 INFO: Number of val images/folders in Set14: 14
2023-11-24 06:40:44,496 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-11-24 06:40:44,496 INFO: Number of val images/folders in BSD100: 100
2023-11-24 06:40:44,499 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-11-24 06:40:44,499 INFO: Number of val images/folders in Urban100: 100
2023-11-24 06:40:44,503 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-11-24 06:40:44,503 INFO: Number of val images/folders in Manga109: 109
2023-11-24 06:40:46,459 INFO: Network: SwinIR_Modified, with parameters: 12,267,557
2023-11-24 06:40:46,460 INFO: SwinIR_Modified(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-11-24 06:40:47,826 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/weights/net_g_150000.pth, with param key: [params].
2023-11-24 06:40:48,467 INFO: Use Exponential Moving Average with decay: 0.999
2023-11-24 06:40:48,592 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/Pipeline/experiments/Doing/016_Pretrained_SwinIR_ConstantConvScale0.01_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_P48W8_LR2e-4_cos_B6G1_2080ti/weights/net_g_150000.pth, with param key: [params_ema].
2023-11-24 06:40:49,175 INFO: Loss [L1Loss] is created.
2023-11-24 06:40:49,176 WARNING: Params edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-11-24 06:40:49,176 WARNING: Params edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-11-24 06:40:49,180 INFO: Model [SwinIRModel] is created.
2023-11-24 06:40:49,342 INFO: Resuming training from epoch: 27, iter: 150000.
2023-11-24 06:40:49,522 INFO: Start training from epoch: 27, iter: 150000
2023-11-24 06:42:28,567 INFO: [Class..][epoch: 27, iter: 150,100, lr:(4.984e-05,)] [eta: 3 days, 23:29:06, time (data): 0.990 (0.008)] l_pix: 8.0412e-03 
2023-11-24 06:44:15,050 INFO: [Class..][epoch: 27, iter: 150,200, lr:(4.969e-05,)] [eta: 4 days, 3:26:31, time (data): 1.028 (0.005)] l_pix: 8.1538e-03 
2023-11-24 06:46:06,173 INFO: [Class..][epoch: 27, iter: 150,300, lr:(4.953e-05,)] [eta: 4 days, 6:14:50, time (data): 1.111 (0.002)] l_pix: 1.1815e-02 
2023-11-24 06:47:57,544 INFO: [Class..][epoch: 27, iter: 150,400, lr:(4.937e-05,)] [eta: 4 days, 7:41:53, time (data): 1.113 (0.002)] l_pix: 8.3757e-03 
2023-11-24 06:49:48,238 INFO: [Class..][epoch: 27, iter: 150,500, lr:(4.922e-05,)] [eta: 4 days, 8:25:34, time (data): 1.107 (0.002)] l_pix: 1.0691e-02 
2023-11-24 06:51:39,391 INFO: [Class..][epoch: 27, iter: 150,600, lr:(4.906e-05,)] [eta: 4 days, 8:58:33, time (data): 1.109 (0.002)] l_pix: 8.2327e-03 
2023-11-24 06:53:30,470 INFO: [Class..][epoch: 27, iter: 150,700, lr:(4.890e-05,)] [eta: 4 days, 9:20:59, time (data): 1.111 (0.002)] l_pix: 5.9041e-03 
2023-11-24 06:55:20,793 INFO: [Class..][epoch: 27, iter: 150,800, lr:(4.875e-05,)] [eta: 4 days, 9:31:52, time (data): 1.107 (0.002)] l_pix: 1.5181e-02 
2023-11-24 06:57:10,874 INFO: [Class..][epoch: 27, iter: 150,900, lr:(4.859e-05,)] [eta: 4 days, 9:38:21, time (data): 1.100 (0.002)] l_pix: 1.0886e-02 
2023-11-24 06:59:00,887 INFO: [Class..][epoch: 27, iter: 151,000, lr:(4.843e-05,)] [eta: 4 days, 9:42:47, time (data): 1.100 (0.002)] l_pix: 2.1577e-02 
2023-11-24 07:00:50,846 INFO: [Class..][epoch: 27, iter: 151,100, lr:(4.827e-05,)] [eta: 4 days, 9:45:47, time (data): 1.099 (0.002)] l_pix: 1.3528e-02 
2023-11-24 07:02:40,821 INFO: [Class..][epoch: 27, iter: 151,200, lr:(4.812e-05,)] [eta: 4 days, 9:48:04, time (data): 1.099 (0.002)] l_pix: 1.8389e-02 
2023-11-24 07:04:30,441 INFO: [Class..][epoch: 27, iter: 151,300, lr:(4.796e-05,)] [eta: 4 days, 9:48:08, time (data): 1.097 (0.002)] l_pix: 1.2851e-02 
2023-11-24 07:06:20,381 INFO: [Class..][epoch: 27, iter: 151,400, lr:(4.780e-05,)] [eta: 4 days, 9:49:15, time (data): 1.098 (0.002)] l_pix: 1.3872e-02 
2023-11-24 07:08:10,334 INFO: [Class..][epoch: 27, iter: 151,500, lr:(4.765e-05,)] [eta: 4 days, 9:50:01, time (data): 1.099 (0.002)] l_pix: 9.0046e-03 
2023-11-24 07:10:00,381 INFO: [Class..][epoch: 27, iter: 151,600, lr:(4.749e-05,)] [eta: 4 days, 9:50:49, time (data): 1.100 (0.002)] l_pix: 1.1430e-02 
2023-11-24 07:11:50,301 INFO: [Class..][epoch: 27, iter: 151,700, lr:(4.733e-05,)] [eta: 4 days, 9:50:52, time (data): 1.100 (0.002)] l_pix: 1.1998e-02 
2023-11-24 07:13:40,283 INFO: [Class..][epoch: 27, iter: 151,800, lr:(4.718e-05,)] [eta: 4 days, 9:50:54, time (data): 1.100 (0.002)] l_pix: 1.0445e-02 
2023-11-24 07:15:31,165 INFO: [Class..][epoch: 27, iter: 151,900, lr:(4.702e-05,)] [eta: 4 days, 9:53:30, time (data): 1.110 (0.002)] l_pix: 1.2013e-02 
2023-11-24 07:17:22,037 INFO: [Class..][epoch: 27, iter: 152,000, lr:(4.686e-05,)] [eta: 4 days, 9:55:37, time (data): 1.109 (0.002)] l_pix: 1.3347e-02 
2023-11-24 07:19:12,740 INFO: [Class..][epoch: 27, iter: 152,100, lr:(4.671e-05,)] [eta: 4 days, 9:56:53, time (data): 1.107 (0.002)] l_pix: 1.9016e-02 
2023-11-24 07:21:02,965 INFO: [Class..][epoch: 27, iter: 152,200, lr:(4.655e-05,)] [eta: 4 days, 9:56:37, time (data): 1.104 (0.002)] l_pix: 2.2881e-02 
2023-11-24 07:22:52,860 INFO: [Class..][epoch: 27, iter: 152,300, lr:(4.639e-05,)] [eta: 4 days, 9:55:23, time (data): 1.100 (0.002)] l_pix: 1.2596e-02 
2023-11-24 07:24:42,250 INFO: [Class..][epoch: 27, iter: 152,400, lr:(4.624e-05,)] [eta: 4 days, 9:52:52, time (data): 1.097 (0.002)] l_pix: 1.3316e-02 
2023-11-24 07:26:32,167 INFO: [Class..][epoch: 27, iter: 152,500, lr:(4.608e-05,)] [eta: 4 days, 9:51:39, time (data): 1.095 (0.002)] l_pix: 6.3404e-03 
2023-11-24 07:28:22,177 INFO: [Class..][epoch: 27, iter: 152,600, lr:(4.592e-05,)] [eta: 4 days, 9:50:34, time (data): 1.098 (0.002)] l_pix: 1.6263e-02 
2023-11-24 07:30:12,151 INFO: [Class..][epoch: 27, iter: 152,700, lr:(4.577e-05,)] [eta: 4 days, 9:49:22, time (data): 1.098 (0.002)] l_pix: 1.5303e-02 
2023-11-24 07:32:01,983 INFO: [Class..][epoch: 27, iter: 152,800, lr:(4.561e-05,)] [eta: 4 days, 9:47:50, time (data): 1.098 (0.002)] l_pix: 1.7215e-02 
2023-11-24 07:33:51,838 INFO: [Class..][epoch: 27, iter: 152,900, lr:(4.545e-05,)] [eta: 4 days, 9:46:19, time (data): 1.098 (0.002)] l_pix: 1.2432e-02 
2023-11-24 07:35:41,927 INFO: [Class..][epoch: 27, iter: 153,000, lr:(4.530e-05,)] [eta: 4 days, 9:45:14, time (data): 1.099 (0.002)] l_pix: 1.6768e-02 
2023-11-24 07:37:32,548 INFO: [Class..][epoch: 27, iter: 153,100, lr:(4.514e-05,)] [eta: 4 days, 9:45:05, time (data): 1.106 (0.002)] l_pix: 1.9726e-02 
2023-11-24 07:39:23,316 INFO: [Class..][epoch: 27, iter: 153,200, lr:(4.498e-05,)] [eta: 4 days, 9:45:06, time (data): 1.107 (0.002)] l_pix: 9.2169e-03 
2023-11-24 07:41:14,256 INFO: [Class..][epoch: 27, iter: 153,300, lr:(4.483e-05,)] [eta: 4 days, 9:45:19, time (data): 1.111 (0.002)] l_pix: 6.6369e-03 
2023-11-24 07:43:04,817 INFO: [Class..][epoch: 27, iter: 153,400, lr:(4.467e-05,)] [eta: 4 days, 9:44:45, time (data): 1.108 (0.002)] l_pix: 1.9070e-02 
2023-11-24 07:44:54,945 INFO: [Class..][epoch: 27, iter: 153,500, lr:(4.451e-05,)] [eta: 4 days, 9:43:24, time (data): 1.101 (0.002)] l_pix: 1.7641e-02 
2023-11-24 07:46:44,981 INFO: [Class..][epoch: 27, iter: 153,600, lr:(4.436e-05,)] [eta: 4 days, 9:41:53, time (data): 1.101 (0.002)] l_pix: 1.0452e-02 
2023-11-24 07:48:34,464 INFO: [Class..][epoch: 27, iter: 153,700, lr:(4.420e-05,)] [eta: 4 days, 9:39:29, time (data): 1.096 (0.002)] l_pix: 1.2814e-02 
2023-11-24 07:50:24,787 INFO: [Class..][epoch: 27, iter: 153,800, lr:(4.405e-05,)] [eta: 4 days, 9:38:23, time (data): 1.100 (0.002)] l_pix: 1.4779e-02 
2023-11-24 07:52:14,618 INFO: [Class..][epoch: 27, iter: 153,900, lr:(4.389e-05,)] [eta: 4 days, 9:36:32, time (data): 1.098 (0.002)] l_pix: 1.4373e-02 
2023-11-24 07:54:04,377 INFO: [Class..][epoch: 27, iter: 154,000, lr:(4.373e-05,)] [eta: 4 days, 9:34:34, time (data): 1.098 (0.002)] l_pix: 1.8731e-02 
2023-11-24 07:55:54,290 INFO: [Class..][epoch: 27, iter: 154,100, lr:(4.358e-05,)] [eta: 4 days, 9:32:49, time (data): 1.100 (0.002)] l_pix: 2.9988e-02 
2023-11-24 07:57:44,277 INFO: [Class..][epoch: 27, iter: 154,200, lr:(4.342e-05,)] [eta: 4 days, 9:31:11, time (data): 1.100 (0.002)] l_pix: 8.6896e-03 
2023-11-24 07:59:34,276 INFO: [Class..][epoch: 27, iter: 154,300, lr:(4.327e-05,)] [eta: 4 days, 9:29:33, time (data): 1.102 (0.002)] l_pix: 1.1824e-02 
2023-11-24 08:01:24,965 INFO: [Class..][epoch: 27, iter: 154,400, lr:(4.311e-05,)] [eta: 4 days, 9:28:48, time (data): 1.105 (0.002)] l_pix: 1.5273e-02 
2023-11-24 08:03:15,748 INFO: [Class..][epoch: 27, iter: 154,500, lr:(4.296e-05,)] [eta: 4 days, 9:28:08, time (data): 1.109 (0.002)] l_pix: 6.7180e-03 
2023-11-24 08:05:06,643 INFO: [Class..][epoch: 27, iter: 154,600, lr:(4.280e-05,)] [eta: 4 days, 9:27:33, time (data): 1.109 (0.002)] l_pix: 1.3475e-02 
2023-11-24 08:06:56,703 INFO: [Class..][epoch: 27, iter: 154,700, lr:(4.265e-05,)] [eta: 4 days, 9:25:54, time (data): 1.097 (0.002)] l_pix: 1.0215e-02 
2023-11-24 08:08:47,122 INFO: [Class..][epoch: 27, iter: 154,800, lr:(4.249e-05,)] [eta: 4 days, 9:24:40, time (data): 1.101 (0.002)] l_pix: 1.7414e-02 
2023-11-24 08:10:37,053 INFO: [Class..][epoch: 27, iter: 154,900, lr:(4.234e-05,)] [eta: 4 days, 9:22:50, time (data): 1.100 (0.002)] l_pix: 1.2842e-02 
2023-11-24 08:12:26,823 INFO: [Class..][epoch: 27, iter: 155,000, lr:(4.218e-05,)] [eta: 4 days, 9:20:49, time (data): 1.099 (0.002)] l_pix: 8.7805e-03 
2023-11-24 08:14:16,575 INFO: [Class..][epoch: 27, iter: 155,100, lr:(4.202e-05,)] [eta: 4 days, 9:18:47, time (data): 1.096 (0.002)] l_pix: 1.1915e-02 
2023-11-24 08:16:06,571 INFO: [Class..][epoch: 27, iter: 155,200, lr:(4.187e-05,)] [eta: 4 days, 9:17:02, time (data): 1.098 (0.002)] l_pix: 6.1937e-03 
2023-11-24 08:17:56,685 INFO: [Class..][epoch: 27, iter: 155,300, lr:(4.171e-05,)] [eta: 4 days, 9:15:24, time (data): 1.102 (0.002)] l_pix: 1.5322e-02 
2023-11-24 08:19:46,839 INFO: [Class..][epoch: 27, iter: 155,400, lr:(4.156e-05,)] [eta: 4 days, 9:13:48, time (data): 1.102 (0.002)] l_pix: 3.4114e-03 
2023-11-24 08:21:36,768 INFO: [Class..][epoch: 28, iter: 155,500, lr:(4.141e-05,)] [eta: 4 days, 9:11:58, time (data): 1.104 (0.008)] l_pix: 1.6660e-02 
2023-11-24 08:23:26,723 INFO: [Class..][epoch: 28, iter: 155,600, lr:(4.125e-05,)] [eta: 4 days, 9:10:10, time (data): 1.101 (0.004)] l_pix: 5.2304e-03 
2023-11-24 08:25:17,191 INFO: [Class..][epoch: 28, iter: 155,700, lr:(4.110e-05,)] [eta: 4 days, 9:08:52, time (data): 1.108 (0.002)] l_pix: 1.3256e-02 
2023-11-24 08:27:07,663 INFO: [Class..][epoch: 28, iter: 155,800, lr:(4.094e-05,)] [eta: 4 days, 9:07:33, time (data): 1.106 (0.002)] l_pix: 8.1533e-03 
2023-11-24 08:28:57,789 INFO: [Class..][epoch: 28, iter: 155,900, lr:(4.079e-05,)] [eta: 4 days, 9:05:54, time (data): 1.101 (0.002)] l_pix: 8.7256e-03 
2023-11-24 08:30:47,904 INFO: [Class..][epoch: 28, iter: 156,000, lr:(4.063e-05,)] [eta: 4 days, 9:04:13, time (data): 1.101 (0.002)] l_pix: 1.1628e-02 
2023-11-24 08:32:37,519 INFO: [Class..][epoch: 28, iter: 156,100, lr:(4.048e-05,)] [eta: 4 days, 9:02:04, time (data): 1.094 (0.002)] l_pix: 4.7562e-03 
2023-11-24 08:34:27,303 INFO: [Class..][epoch: 28, iter: 156,200, lr:(4.032e-05,)] [eta: 4 days, 9:00:04, time (data): 1.096 (0.002)] l_pix: 1.1387e-02 
2023-11-24 08:36:17,167 INFO: [Class..][epoch: 28, iter: 156,300, lr:(4.017e-05,)] [eta: 4 days, 8:58:10, time (data): 1.099 (0.002)] l_pix: 8.2329e-03 
2023-11-24 08:38:07,241 INFO: [Class..][epoch: 28, iter: 156,400, lr:(4.002e-05,)] [eta: 4 days, 8:56:27, time (data): 1.100 (0.002)] l_pix: 9.8098e-03 
2023-11-24 08:39:57,656 INFO: [Class..][epoch: 28, iter: 156,500, lr:(3.986e-05,)] [eta: 4 days, 8:55:01, time (data): 1.105 (0.002)] l_pix: 1.1566e-02 
2023-11-24 08:41:46,976 INFO: [Class..][epoch: 28, iter: 156,600, lr:(3.971e-05,)] [eta: 4 days, 8:52:38, time (data): 1.098 (0.002)] l_pix: 1.7463e-02 
2023-11-24 08:43:36,318 INFO: [Class..][epoch: 28, iter: 156,700, lr:(3.955e-05,)] [eta: 4 days, 8:50:17, time (data): 1.090 (0.002)] l_pix: 1.1124e-02 
2023-11-24 08:45:26,807 INFO: [Class..][epoch: 28, iter: 156,800, lr:(3.940e-05,)] [eta: 4 days, 8:48:55, time (data): 1.099 (0.002)] l_pix: 1.8502e-02 
2023-11-24 08:47:17,027 INFO: [Class..][epoch: 28, iter: 156,900, lr:(3.925e-05,)] [eta: 4 days, 8:47:19, time (data): 1.100 (0.002)] l_pix: 1.1288e-02 
2023-11-24 08:49:07,791 INFO: [Class..][epoch: 28, iter: 157,000, lr:(3.909e-05,)] [eta: 4 days, 8:46:08, time (data): 1.104 (0.002)] l_pix: 1.5014e-02 
2023-11-24 08:50:58,246 INFO: [Class..][epoch: 28, iter: 157,100, lr:(3.894e-05,)] [eta: 4 days, 8:44:42, time (data): 1.104 (0.002)] l_pix: 1.7354e-02 
2023-11-24 08:52:48,456 INFO: [Class..][epoch: 28, iter: 157,200, lr:(3.879e-05,)] [eta: 4 days, 8:43:04, time (data): 1.103 (0.002)] l_pix: 8.8521e-03 
2023-11-24 08:54:38,426 INFO: [Class..][epoch: 28, iter: 157,300, lr:(3.863e-05,)] [eta: 4 days, 8:41:14, time (data): 1.098 (0.002)] l_pix: 4.9967e-03 
2023-11-24 08:56:28,687 INFO: [Class..][epoch: 28, iter: 157,400, lr:(3.848e-05,)] [eta: 4 days, 8:39:37, time (data): 1.101 (0.002)] l_pix: 1.6799e-02 
2023-11-24 08:58:18,499 INFO: [Class..][epoch: 28, iter: 157,500, lr:(3.833e-05,)] [eta: 4 days, 8:37:40, time (data): 1.098 (0.002)] l_pix: 1.1140e-02 
2023-11-24 09:00:08,328 INFO: [Class..][epoch: 28, iter: 157,600, lr:(3.818e-05,)] [eta: 4 days, 8:35:43, time (data): 1.098 (0.002)] l_pix: 1.9950e-02 
2023-11-24 09:01:58,561 INFO: [Class..][epoch: 28, iter: 157,700, lr:(3.802e-05,)] [eta: 4 days, 8:34:05, time (data): 1.105 (0.002)] l_pix: 1.9847e-02 
2023-11-24 09:03:48,410 INFO: [Class..][epoch: 28, iter: 157,800, lr:(3.787e-05,)] [eta: 4 days, 8:32:09, time (data): 1.101 (0.002)] l_pix: 1.9703e-02 
2023-11-24 09:05:38,045 INFO: [Class..][epoch: 28, iter: 157,900, lr:(3.772e-05,)] [eta: 4 days, 8:30:05, time (data): 1.098 (0.002)] l_pix: 8.1004e-03 
2023-11-24 09:07:28,259 INFO: [Class..][epoch: 28, iter: 158,000, lr:(3.757e-05,)] [eta: 4 days, 8:28:25, time (data): 1.100 (0.002)] l_pix: 1.6125e-02 
2023-11-24 09:09:18,954 INFO: [Class..][epoch: 28, iter: 158,100, lr:(3.741e-05,)] [eta: 4 days, 8:27:06, time (data): 1.104 (0.002)] l_pix: 9.5308e-03 
2023-11-24 09:11:09,448 INFO: [Class..][epoch: 28, iter: 158,200, lr:(3.726e-05,)] [eta: 4 days, 8:25:37, time (data): 1.105 (0.002)] l_pix: 1.9115e-02 
2023-11-24 09:13:00,162 INFO: [Class..][epoch: 28, iter: 158,300, lr:(3.711e-05,)] [eta: 4 days, 8:24:17, time (data): 1.104 (0.002)] l_pix: 1.3906e-02 
2023-11-24 09:14:50,152 INFO: [Class..][epoch: 28, iter: 158,400, lr:(3.696e-05,)] [eta: 4 days, 8:22:27, time (data): 1.102 (0.002)] l_pix: 1.0588e-02 
2023-11-24 09:16:40,092 INFO: [Class..][epoch: 28, iter: 158,500, lr:(3.681e-05,)] [eta: 4 days, 8:20:34, time (data): 1.098 (0.002)] l_pix: 1.3073e-02 
2023-11-24 09:18:30,219 INFO: [Class..][epoch: 28, iter: 158,600, lr:(3.666e-05,)] [eta: 4 days, 8:18:50, time (data): 1.100 (0.002)] l_pix: 1.4260e-02 
2023-11-24 09:20:20,177 INFO: [Class..][epoch: 28, iter: 158,700, lr:(3.651e-05,)] [eta: 4 days, 8:16:58, time (data): 1.100 (0.002)] l_pix: 6.5110e-03 
2023-11-24 09:22:10,192 INFO: [Class..][epoch: 28, iter: 158,800, lr:(3.635e-05,)] [eta: 4 days, 8:15:09, time (data): 1.100 (0.002)] l_pix: 1.5630e-02 
2023-11-24 09:24:00,105 INFO: [Class..][epoch: 28, iter: 158,900, lr:(3.620e-05,)] [eta: 4 days, 8:13:15, time (data): 1.104 (0.002)] l_pix: 1.2874e-02 
2023-11-24 09:25:49,946 INFO: [Class..][epoch: 28, iter: 159,000, lr:(3.605e-05,)] [eta: 4 days, 8:11:20, time (data): 1.100 (0.002)] l_pix: 8.9663e-03 
2023-11-24 09:27:40,308 INFO: [Class..][epoch: 28, iter: 159,100, lr:(3.590e-05,)] [eta: 4 days, 8:09:43, time (data): 1.104 (0.002)] l_pix: 1.3996e-02 
2023-11-24 09:29:30,666 INFO: [Class..][epoch: 28, iter: 159,200, lr:(3.575e-05,)] [eta: 4 days, 8:08:07, time (data): 1.104 (0.002)] l_pix: 2.6654e-02 
2023-11-24 09:31:21,670 INFO: [Class..][epoch: 28, iter: 159,300, lr:(3.560e-05,)] [eta: 4 days, 8:06:53, time (data): 1.113 (0.002)] l_pix: 8.5130e-03 
2023-11-24 09:33:12,586 INFO: [Class..][epoch: 28, iter: 159,400, lr:(3.545e-05,)] [eta: 4 days, 8:05:36, time (data): 1.110 (0.002)] l_pix: 9.9581e-03 
2023-11-24 09:35:02,782 INFO: [Class..][epoch: 28, iter: 159,500, lr:(3.530e-05,)] [eta: 4 days, 8:03:52, time (data): 1.104 (0.002)] l_pix: 1.2457e-02 
2023-11-24 09:36:52,952 INFO: [Class..][epoch: 28, iter: 159,600, lr:(3.515e-05,)] [eta: 4 days, 8:02:07, time (data): 1.102 (0.002)] l_pix: 1.2574e-02 
2023-11-24 09:38:42,768 INFO: [Class..][epoch: 28, iter: 159,700, lr:(3.500e-05,)] [eta: 4 days, 8:00:10, time (data): 1.100 (0.002)] l_pix: 1.2461e-02 
2023-11-24 09:40:32,717 INFO: [Class..][epoch: 28, iter: 159,800, lr:(3.485e-05,)] [eta: 4 days, 7:58:17, time (data): 1.100 (0.002)] l_pix: 1.2477e-02 
2023-11-24 09:42:22,747 INFO: [Class..][epoch: 28, iter: 159,900, lr:(3.470e-05,)] [eta: 4 days, 7:56:28, time (data): 1.100 (0.002)] l_pix: 7.9820e-03 
2023-11-24 09:44:13,248 INFO: [Class..][epoch: 28, iter: 160,000, lr:(3.455e-05,)] [eta: 4 days, 7:54:54, time (data): 1.103 (0.002)] l_pix: 1.0398e-02 
2023-11-24 09:44:13,249 INFO: Saving models and training states.
2023-11-24 09:44:14,154 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-24 09:44:22,824 INFO: Validation Set5
	 # psnr: 38.2593	Best: 38.2593 @ 160000 iter
	 # ssim: 0.9622	Best: 0.9622 @ 160000 iter

2023-11-24 09:45:04,761 INFO: Validation Set14
	 # psnr: 34.0022	Best: 34.0022 @ 160000 iter
	 # ssim: 0.9215	Best: 0.9215 @ 160000 iter

2023-11-24 09:47:25,733 INFO: Validation BSD100
	 # psnr: 32.4052	Best: 32.4052 @ 160000 iter
	 # ssim: 0.9034	Best: 0.9034 @ 160000 iter

2023-11-24 10:01:11,369 INFO: Validation Urban100
	 # psnr: 33.1248	Best: 33.1248 @ 160000 iter
	 # ssim: 0.9374	Best: 0.9374 @ 160000 iter

2023-11-24 10:19:56,980 INFO: Validation Manga109
	 # psnr: 39.4479	Best: 39.4479 @ 160000 iter
	 # ssim: 0.9789	Best: 0.9789 @ 160000 iter

2023-11-24 10:21:29,851 INFO: [Class..][epoch: 28, iter: 160,100, lr:(3.440e-05,)] [eta: 5 days, 3:45:43, time (data): 0.928 (0.002)] l_pix: 1.0148e-02 
2023-11-24 10:23:03,203 INFO: [Class..][epoch: 28, iter: 160,200, lr:(3.425e-05,)] [eta: 5 days, 3:22:35, time (data): 0.932 (0.002)] l_pix: 1.5027e-02 
2023-11-24 10:24:35,272 INFO: [Class..][epoch: 28, iter: 160,300, lr:(3.410e-05,)] [eta: 5 days, 2:59:10, time (data): 0.916 (0.003)] l_pix: 8.9684e-03 
2023-11-24 10:26:08,190 INFO: [Class..][epoch: 28, iter: 160,400, lr:(3.395e-05,)] [eta: 5 days, 2:36:38, time (data): 0.925 (0.002)] l_pix: 1.2683e-02 
2023-11-24 10:27:41,122 INFO: [Class..][epoch: 28, iter: 160,500, lr:(3.381e-05,)] [eta: 5 days, 2:14:30, time (data): 0.931 (0.002)] l_pix: 1.3373e-02 
2023-11-24 10:29:14,251 INFO: [Class..][epoch: 28, iter: 160,600, lr:(3.366e-05,)] [eta: 5 days, 1:52:52, time (data): 0.931 (0.002)] l_pix: 1.9649e-02 
2023-11-24 10:30:45,405 INFO: [Class..][epoch: 28, iter: 160,700, lr:(3.351e-05,)] [eta: 5 days, 1:30:34, time (data): 0.907 (0.002)] l_pix: 1.4992e-02 
2023-11-24 10:32:16,711 INFO: [Class..][epoch: 28, iter: 160,800, lr:(3.336e-05,)] [eta: 5 days, 1:08:44, time (data): 0.911 (0.002)] l_pix: 1.2140e-02 
2023-11-24 10:33:49,947 INFO: [Class..][epoch: 29, iter: 160,900, lr:(3.321e-05,)] [eta: 5 days, 0:48:16, time (data): 0.942 (0.023)] l_pix: 1.1912e-02 
2023-11-24 10:35:21,471 INFO: [Class..][epoch: 29, iter: 161,000, lr:(3.306e-05,)] [eta: 5 days, 0:27:16, time (data): 0.924 (0.009)] l_pix: 1.1962e-02 
2023-11-24 10:36:53,866 INFO: [Class..][epoch: 29, iter: 161,100, lr:(3.292e-05,)] [eta: 5 days, 0:07:04, time (data): 0.919 (0.002)] l_pix: 1.9134e-02 
2023-11-24 10:38:25,095 INFO: [Class..][epoch: 29, iter: 161,200, lr:(3.277e-05,)] [eta: 4 days, 23:46:36, time (data): 0.914 (0.002)] l_pix: 1.3484e-02 
2023-11-24 10:39:56,553 INFO: [Class..][epoch: 29, iter: 161,300, lr:(3.262e-05,)] [eta: 4 days, 23:26:36, time (data): 0.907 (0.002)] l_pix: 2.5351e-02 
2023-11-24 10:41:28,847 INFO: [Class..][epoch: 29, iter: 161,400, lr:(3.247e-05,)] [eta: 4 days, 23:07:19, time (data): 0.918 (0.002)] l_pix: 7.9780e-03 
2023-11-24 10:43:17,160 INFO: [Class..][epoch: 29, iter: 161,500, lr:(3.233e-05,)] [eta: 4 days, 22:56:13, time (data): 1.109 (0.002)] l_pix: 8.4237e-03 
2023-11-24 10:45:07,837 INFO: [Class..][epoch: 29, iter: 161,600, lr:(3.218e-05,)] [eta: 4 days, 22:46:25, time (data): 1.107 (0.002)] l_pix: 1.8616e-02 
2023-11-24 10:46:57,914 INFO: [Class..][epoch: 29, iter: 161,700, lr:(3.203e-05,)] [eta: 4 days, 22:36:28, time (data): 1.103 (0.002)] l_pix: 1.1273e-02 
2023-11-24 10:48:47,939 INFO: [Class..][epoch: 29, iter: 161,800, lr:(3.189e-05,)] [eta: 4 days, 22:26:38, time (data): 1.101 (0.002)] l_pix: 7.2020e-03 
2023-11-24 10:50:37,815 INFO: [Class..][epoch: 29, iter: 161,900, lr:(3.174e-05,)] [eta: 4 days, 22:16:51, time (data): 1.099 (0.002)] l_pix: 1.0182e-02 
2023-11-24 10:52:27,796 INFO: [Class..][epoch: 29, iter: 162,000, lr:(3.160e-05,)] [eta: 4 days, 22:07:16, time (data): 1.100 (0.002)] l_pix: 1.2128e-02 
2023-11-24 10:54:17,804 INFO: [Class..][epoch: 29, iter: 162,100, lr:(3.145e-05,)] [eta: 4 days, 21:57:49, time (data): 1.100 (0.002)] l_pix: 1.3505e-02 
2023-11-24 10:56:07,909 INFO: [Class..][epoch: 29, iter: 162,200, lr:(3.130e-05,)] [eta: 4 days, 21:48:32, time (data): 1.101 (0.002)] l_pix: 1.4264e-02 
2023-11-24 10:57:57,938 INFO: [Class..][epoch: 29, iter: 162,300, lr:(3.116e-05,)] [eta: 4 days, 21:39:20, time (data): 1.103 (0.002)] l_pix: 1.8842e-02 
2023-11-24 10:59:47,991 INFO: [Class..][epoch: 29, iter: 162,400, lr:(3.101e-05,)] [eta: 4 days, 21:30:16, time (data): 1.101 (0.002)] l_pix: 1.4323e-02 
2023-11-24 11:01:38,115 INFO: [Class..][epoch: 29, iter: 162,500, lr:(3.087e-05,)] [eta: 4 days, 21:21:21, time (data): 1.100 (0.002)] l_pix: 6.9862e-03 
2023-11-24 11:03:27,979 INFO: [Class..][epoch: 29, iter: 162,600, lr:(3.072e-05,)] [eta: 4 days, 21:12:26, time (data): 1.099 (0.002)] l_pix: 4.4636e-03 
2023-11-24 11:05:18,013 INFO: [Class..][epoch: 29, iter: 162,700, lr:(3.058e-05,)] [eta: 4 days, 21:03:42, time (data): 1.100 (0.002)] l_pix: 1.5558e-02 
2023-11-24 11:07:08,312 INFO: [Class..][epoch: 29, iter: 162,800, lr:(3.043e-05,)] [eta: 4 days, 20:55:11, time (data): 1.102 (0.002)] l_pix: 2.4498e-02 
2023-11-24 11:08:58,523 INFO: [Class..][epoch: 29, iter: 162,900, lr:(3.029e-05,)] [eta: 4 days, 20:46:45, time (data): 1.102 (0.002)] l_pix: 1.4036e-02 
2023-11-24 11:10:48,659 INFO: [Class..][epoch: 29, iter: 163,000, lr:(3.014e-05,)] [eta: 4 days, 20:38:22, time (data): 1.101 (0.002)] l_pix: 7.4667e-03 
2023-11-24 11:12:38,696 INFO: [Class..][epoch: 29, iter: 163,100, lr:(3.000e-05,)] [eta: 4 days, 20:30:03, time (data): 1.103 (0.002)] l_pix: 5.4145e-03 
2023-11-24 11:14:28,334 INFO: [Class..][epoch: 29, iter: 163,200, lr:(2.986e-05,)] [eta: 4 days, 20:21:40, time (data): 1.098 (0.002)] l_pix: 8.8653e-03 
2023-11-24 11:16:18,827 INFO: [Class..][epoch: 29, iter: 163,300, lr:(2.971e-05,)] [eta: 4 days, 20:13:44, time (data): 1.101 (0.002)] l_pix: 1.6769e-02 
2023-11-24 11:18:08,994 INFO: [Class..][epoch: 29, iter: 163,400, lr:(2.957e-05,)] [eta: 4 days, 20:05:45, time (data): 1.101 (0.002)] l_pix: 1.2957e-02 
2023-11-24 11:19:59,406 INFO: [Class..][epoch: 29, iter: 163,500, lr:(2.943e-05,)] [eta: 4 days, 19:57:58, time (data): 1.102 (0.002)] l_pix: 1.3490e-02 
2023-11-24 11:21:49,514 INFO: [Class..][epoch: 29, iter: 163,600, lr:(2.928e-05,)] [eta: 4 days, 19:50:09, time (data): 1.101 (0.002)] l_pix: 1.4198e-02 
2023-11-24 11:23:39,059 INFO: [Class..][epoch: 29, iter: 163,700, lr:(2.914e-05,)] [eta: 4 days, 19:42:11, time (data): 1.087 (0.002)] l_pix: 5.2289e-03 
2023-11-24 11:25:27,900 INFO: [Class..][epoch: 29, iter: 163,800, lr:(2.900e-05,)] [eta: 4 days, 19:34:01, time (data): 1.088 (0.002)] l_pix: 2.1732e-02 
2023-11-24 11:27:16,019 INFO: [Class..][epoch: 29, iter: 163,900, lr:(2.885e-05,)] [eta: 4 days, 19:25:40, time (data): 1.081 (0.002)] l_pix: 1.2104e-02 
2023-11-24 11:29:03,434 INFO: [Class..][epoch: 29, iter: 164,000, lr:(2.871e-05,)] [eta: 4 days, 19:17:07, time (data): 1.076 (0.002)] l_pix: 1.1481e-02 
2023-11-24 11:30:50,844 INFO: [Class..][epoch: 29, iter: 164,100, lr:(2.857e-05,)] [eta: 4 days, 19:08:40, time (data): 1.076 (0.002)] l_pix: 9.8619e-03 
2023-11-24 11:32:38,184 INFO: [Class..][epoch: 29, iter: 164,200, lr:(2.843e-05,)] [eta: 4 days, 19:00:16, time (data): 1.074 (0.002)] l_pix: 6.8466e-03 
2023-11-24 11:34:25,516 INFO: [Class..][epoch: 29, iter: 164,300, lr:(2.829e-05,)] [eta: 4 days, 18:51:58, time (data): 1.075 (0.002)] l_pix: 1.3795e-02 
2023-11-24 11:36:13,214 INFO: [Class..][epoch: 29, iter: 164,400, lr:(2.815e-05,)] [eta: 4 days, 18:43:54, time (data): 1.077 (0.002)] l_pix: 1.1438e-02 
2023-11-24 11:38:00,584 INFO: [Class..][epoch: 29, iter: 164,500, lr:(2.800e-05,)] [eta: 4 days, 18:35:48, time (data): 1.077 (0.002)] l_pix: 2.5172e-02 
2023-11-24 11:39:46,500 INFO: [Class..][epoch: 29, iter: 164,600, lr:(2.786e-05,)] [eta: 4 days, 18:27:13, time (data): 1.063 (0.002)] l_pix: 9.9068e-03 
2023-11-24 11:41:33,754 INFO: [Class..][epoch: 29, iter: 164,700, lr:(2.772e-05,)] [eta: 4 days, 18:19:15, time (data): 1.071 (0.002)] l_pix: 1.0943e-02 
2023-11-24 11:43:20,952 INFO: [Class..][epoch: 29, iter: 164,800, lr:(2.758e-05,)] [eta: 4 days, 18:11:20, time (data): 1.072 (0.002)] l_pix: 1.5612e-02 
2023-11-24 11:45:08,054 INFO: [Class..][epoch: 29, iter: 164,900, lr:(2.744e-05,)] [eta: 4 days, 18:03:28, time (data): 1.067 (0.002)] l_pix: 1.5373e-02 
2023-11-24 11:46:55,365 INFO: [Class..][epoch: 29, iter: 165,000, lr:(2.730e-05,)] [eta: 4 days, 17:55:45, time (data): 1.072 (0.002)] l_pix: 1.2088e-02 
2023-11-24 11:48:42,523 INFO: [Class..][epoch: 29, iter: 165,100, lr:(2.716e-05,)] [eta: 4 days, 17:48:04, time (data): 1.071 (0.002)] l_pix: 1.0648e-02 
2023-11-24 11:50:29,822 INFO: [Class..][epoch: 29, iter: 165,200, lr:(2.702e-05,)] [eta: 4 days, 17:40:31, time (data): 1.073 (0.002)] l_pix: 1.6675e-02 
2023-11-24 11:52:17,786 INFO: [Class..][epoch: 29, iter: 165,300, lr:(2.688e-05,)] [eta: 4 days, 17:33:17, time (data): 1.080 (0.002)] l_pix: 6.9793e-03 
2023-11-24 11:54:05,574 INFO: [Class..][epoch: 29, iter: 165,400, lr:(2.674e-05,)] [eta: 4 days, 17:26:03, time (data): 1.078 (0.002)] l_pix: 6.9793e-03 
2023-11-24 11:55:52,665 INFO: [Class..][epoch: 29, iter: 165,500, lr:(2.660e-05,)] [eta: 4 days, 17:18:38, time (data): 1.068 (0.002)] l_pix: 6.6692e-03 
2023-11-24 11:57:39,083 INFO: [Class..][epoch: 29, iter: 165,600, lr:(2.647e-05,)] [eta: 4 days, 17:11:03, time (data): 1.065 (0.002)] l_pix: 1.1115e-02 
2023-11-24 11:59:26,182 INFO: [Class..][epoch: 29, iter: 165,700, lr:(2.633e-05,)] [eta: 4 days, 17:03:47, time (data): 1.070 (0.002)] l_pix: 1.4803e-02 
2023-11-24 12:01:13,005 INFO: [Class..][epoch: 29, iter: 165,800, lr:(2.619e-05,)] [eta: 4 days, 16:56:30, time (data): 1.068 (0.002)] l_pix: 1.0716e-02 
2023-11-24 12:02:59,593 INFO: [Class..][epoch: 29, iter: 165,900, lr:(2.605e-05,)] [eta: 4 days, 16:49:11, time (data): 1.061 (0.002)] l_pix: 5.5239e-03 
2023-11-24 12:04:46,480 INFO: [Class..][epoch: 29, iter: 166,000, lr:(2.591e-05,)] [eta: 4 days, 16:42:03, time (data): 1.068 (0.002)] l_pix: 1.2988e-02 
2023-11-24 12:06:33,486 INFO: [Class..][epoch: 29, iter: 166,100, lr:(2.578e-05,)] [eta: 4 days, 16:35:02, time (data): 1.071 (0.002)] l_pix: 1.0688e-02 
2023-11-24 12:08:20,710 INFO: [Class..][epoch: 29, iter: 166,200, lr:(2.564e-05,)] [eta: 4 days, 16:28:09, time (data): 1.072 (0.002)] l_pix: 1.1095e-02 
2023-11-24 12:10:08,496 INFO: [Class..][epoch: 30, iter: 166,300, lr:(2.550e-05,)] [eta: 4 days, 16:21:31, time (data): 1.098 (0.033)] l_pix: 1.8954e-02 
2023-11-24 12:11:56,400 INFO: [Class..][epoch: 30, iter: 166,400, lr:(2.536e-05,)] [eta: 4 days, 16:14:59, time (data): 1.082 (0.007)] l_pix: 1.9657e-02 
2023-11-24 12:13:43,743 INFO: [Class..][epoch: 30, iter: 166,500, lr:(2.523e-05,)] [eta: 4 days, 16:08:19, time (data): 1.077 (0.002)] l_pix: 1.5144e-02 
2023-11-24 12:15:31,413 INFO: [Class..][epoch: 30, iter: 166,600, lr:(2.509e-05,)] [eta: 4 days, 16:01:49, time (data): 1.077 (0.002)] l_pix: 1.4540e-02 
2023-11-24 12:17:18,899 INFO: [Class..][epoch: 30, iter: 166,700, lr:(2.496e-05,)] [eta: 4 days, 15:55:19, time (data): 1.072 (0.002)] l_pix: 1.7213e-02 
2023-11-24 12:19:06,269 INFO: [Class..][epoch: 30, iter: 166,800, lr:(2.482e-05,)] [eta: 4 days, 15:48:50, time (data): 1.073 (0.002)] l_pix: 1.7558e-02 
2023-11-24 12:20:53,682 INFO: [Class..][epoch: 30, iter: 166,900, lr:(2.468e-05,)] [eta: 4 days, 15:42:25, time (data): 1.074 (0.002)] l_pix: 1.2194e-02 
2023-11-24 12:22:40,726 INFO: [Class..][epoch: 30, iter: 167,000, lr:(2.455e-05,)] [eta: 4 days, 15:35:56, time (data): 1.071 (0.002)] l_pix: 7.1871e-03 
2023-11-24 12:24:27,801 INFO: [Class..][epoch: 30, iter: 167,100, lr:(2.441e-05,)] [eta: 4 days, 15:29:32, time (data): 1.087 (0.002)] l_pix: 1.1106e-02 
2023-11-24 12:26:15,073 INFO: [Class..][epoch: 30, iter: 167,200, lr:(2.428e-05,)] [eta: 4 days, 15:23:14, time (data): 1.075 (0.002)] l_pix: 1.4333e-02 
2023-11-24 12:28:02,440 INFO: [Class..][epoch: 30, iter: 167,300, lr:(2.414e-05,)] [eta: 4 days, 15:17:01, time (data): 1.073 (0.002)] l_pix: 9.9854e-03 
2023-11-24 12:29:49,839 INFO: [Class..][epoch: 30, iter: 167,400, lr:(2.401e-05,)] [eta: 4 days, 15:10:52, time (data): 1.074 (0.002)] l_pix: 2.3541e-02 
2023-11-24 12:31:37,306 INFO: [Class..][epoch: 30, iter: 167,500, lr:(2.388e-05,)] [eta: 4 days, 15:04:47, time (data): 1.071 (0.002)] l_pix: 1.5969e-02 
2023-11-24 12:33:24,504 INFO: [Class..][epoch: 30, iter: 167,600, lr:(2.374e-05,)] [eta: 4 days, 14:58:40, time (data): 1.072 (0.002)] l_pix: 2.3166e-02 
2023-11-24 12:35:11,699 INFO: [Class..][epoch: 30, iter: 167,700, lr:(2.361e-05,)] [eta: 4 days, 14:52:35, time (data): 1.058 (0.002)] l_pix: 5.4076e-03 
2023-11-24 12:36:59,457 INFO: [Class..][epoch: 30, iter: 167,800, lr:(2.348e-05,)] [eta: 4 days, 14:46:45, time (data): 1.075 (0.002)] l_pix: 1.3054e-02 
2023-11-24 12:38:46,687 INFO: [Class..][epoch: 30, iter: 167,900, lr:(2.334e-05,)] [eta: 4 days, 14:40:47, time (data): 1.088 (0.002)] l_pix: 8.7965e-03 
2023-11-24 12:40:34,188 INFO: [Class..][epoch: 30, iter: 168,000, lr:(2.321e-05,)] [eta: 4 days, 14:34:57, time (data): 1.076 (0.002)] l_pix: 1.4241e-02 
2023-11-24 12:42:21,874 INFO: [Class..][epoch: 30, iter: 168,100, lr:(2.308e-05,)] [eta: 4 days, 14:29:13, time (data): 1.082 (0.002)] l_pix: 1.3040e-02 
2023-11-24 12:44:09,151 INFO: [Class..][epoch: 30, iter: 168,200, lr:(2.295e-05,)] [eta: 4 days, 14:23:24, time (data): 1.074 (0.002)] l_pix: 1.6945e-02 
2023-11-24 12:45:56,372 INFO: [Class..][epoch: 30, iter: 168,300, lr:(2.281e-05,)] [eta: 4 days, 14:17:36, time (data): 1.083 (0.002)] l_pix: 9.8574e-03 
2023-11-24 12:47:44,130 INFO: [Class..][epoch: 30, iter: 168,400, lr:(2.268e-05,)] [eta: 4 days, 14:12:02, time (data): 1.078 (0.002)] l_pix: 9.4004e-03 
2023-11-24 12:49:31,580 INFO: [Class..][epoch: 30, iter: 168,500, lr:(2.255e-05,)] [eta: 4 days, 14:06:23, time (data): 1.071 (0.002)] l_pix: 1.1110e-02 
2023-11-24 12:51:19,176 INFO: [Class..][epoch: 30, iter: 168,600, lr:(2.242e-05,)] [eta: 4 days, 14:00:50, time (data): 1.076 (0.002)] l_pix: 1.2663e-02 
2023-11-24 12:53:06,241 INFO: [Class..][epoch: 30, iter: 168,700, lr:(2.229e-05,)] [eta: 4 days, 13:55:11, time (data): 1.096 (0.002)] l_pix: 1.6033e-02 
2023-11-24 12:54:53,321 INFO: [Class..][epoch: 30, iter: 168,800, lr:(2.216e-05,)] [eta: 4 days, 13:49:33, time (data): 1.072 (0.002)] l_pix: 6.1771e-03 
2023-11-24 12:56:40,906 INFO: [Class..][epoch: 30, iter: 168,900, lr:(2.203e-05,)] [eta: 4 days, 13:44:07, time (data): 1.101 (0.002)] l_pix: 1.7720e-02 
