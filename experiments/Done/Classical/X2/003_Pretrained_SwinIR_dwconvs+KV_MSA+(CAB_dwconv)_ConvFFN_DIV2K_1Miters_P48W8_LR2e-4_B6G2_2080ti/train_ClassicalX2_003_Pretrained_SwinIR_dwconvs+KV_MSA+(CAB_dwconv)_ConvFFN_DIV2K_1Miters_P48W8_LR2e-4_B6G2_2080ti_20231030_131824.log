2023-10-30 13:18:24,544 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.4.2
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-10-30 13:18:24,545 INFO: 
  name: ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
  model_type: SwinIRModel
  scale: 2
  num_gpu: 2
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: basicsr/data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: ./datasets/BSDS100/GTmod12
      dataroot_lq: ./datasets/BSDS100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: ./datasets/urban100/GTmod12
      dataroot_lq: ./datasets/urban100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: ./datasets/manga109/GTmod12
      dataroot_lq: ./datasets/manga109/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR_Modified
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_35000.pth
    strict_load_g: False
    resume_state: experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/training_states/35000.state
    experiments_root: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
    models: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models
    training_states: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/training_states
    log: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti
    visualization: /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/visualization
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [50000, 200000, 250000, 275000]
      gamma: 0.5
    ]
    total_iter: 300000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 5000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: True
  rank: 0
  world_size: 2
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao/BasicSR

2023-10-30 13:18:33,504 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-10-30 13:18:33,505 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 2
	Require iter number per epoch: 2716
	Total epochs: 111; iters: 300000.
2023-10-30 13:18:33,507 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-10-30 13:18:33,507 INFO: Number of val images/folders in Set5: 5
2023-10-30 13:18:33,509 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-10-30 13:18:33,509 INFO: Number of val images/folders in Set14: 14
2023-10-30 13:18:33,517 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-10-30 13:18:33,518 INFO: Number of val images/folders in BSD100: 100
2023-10-30 13:18:33,526 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-10-30 13:18:33,526 INFO: Number of val images/folders in Urban100: 100
2023-10-30 13:18:33,536 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-10-30 13:18:33,536 INFO: Number of val images/folders in Manga109: 109
2023-10-30 13:18:34,219 INFO: Network [SwinIR_Modified] is created.
2023-10-30 13:18:36,101 INFO: Network: DistributedDataParallel - SwinIR_Modified, with parameters: 12,267,593
2023-10-30 13:18:36,102 INFO: SwinIR_Modified(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (q): Linear(in_features=180, out_features=180, bias=True)
              (kv): Linear(in_features=180, out_features=360, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-10-30 13:18:47,069 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_35000.pth, with param key: [params].
2023-10-30 13:18:47,469 INFO: Use Exponential Moving Average with decay: 0.999
2023-10-30 13:18:48,080 INFO: Network [SwinIR_Modified] is created.
2023-10-30 13:18:49,019 INFO: Loading SwinIR_Modified model from /share3/home/renzihao/BasicSR/experiments/ClassicalX2_003_Pretrained_SwinIR_dwconvs+KV_MSA+(CAB_dwconv)_ConvFFN_DIV2K_1Miters_P48W8_LR2e-4_B6G2_2080ti/models/net_g_35000.pth, with param key: [params_ema].
2023-10-30 13:18:49,271 INFO: Loss [L1Loss] is created.
2023-10-30 13:18:49,272 WARNING: Params module.edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-10-30 13:18:49,272 WARNING: Params module.edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-10-30 13:18:49,285 INFO: Model [SwinIRModel] is created.
2023-10-30 13:18:49,727 INFO: Resuming training from epoch: 11, iter: 35000.
2023-10-30 13:19:32,286 INFO: Start training from epoch: 11, iter: 35000
2023-10-30 13:21:32,454 INFO: [Class..][epoch: 11, iter:  35,100, lr:(2.000e-04,)] [eta: 4 days, 22:33:10, time (data): 1.202 (0.441)] l_pix: 1.1955e-02 
2023-10-30 13:22:44,659 INFO: [Class..][epoch: 11, iter:  35,200, lr:(2.000e-04,)] [eta: 3 days, 13:58:19, time (data): 0.962 (0.222)] l_pix: 9.7891e-03 
2023-10-30 13:23:58,453 INFO: [Class..][epoch: 11, iter:  35,300, lr:(2.000e-04,)] [eta: 3 days, 3:24:52, time (data): 0.738 (0.004)] l_pix: 6.1888e-03 
2023-10-30 13:25:12,198 INFO: [Class..][epoch: 11, iter:  35,400, lr:(2.000e-04,)] [eta: 2 days, 22:06:12, time (data): 0.738 (0.004)] l_pix: 1.1624e-02 
2023-10-30 13:26:25,714 INFO: [Class..][epoch: 11, iter:  35,500, lr:(2.000e-04,)] [eta: 2 days, 18:52:14, time (data): 0.733 (0.003)] l_pix: 9.1698e-03 
2023-10-30 13:27:39,788 INFO: [Class..][epoch: 11, iter:  35,600, lr:(2.000e-04,)] [eta: 2 days, 16:46:30, time (data): 0.737 (0.003)] l_pix: 9.0111e-03 
2023-10-30 13:28:54,026 INFO: [Class..][epoch: 11, iter:  35,700, lr:(2.000e-04,)] [eta: 2 days, 15:17:19, time (data): 0.742 (0.003)] l_pix: 1.5728e-02 
2023-10-30 13:30:07,465 INFO: [Class..][epoch: 11, iter:  35,800, lr:(2.000e-04,)] [eta: 2 days, 14:05:42, time (data): 0.738 (0.003)] l_pix: 1.0506e-02 
2023-10-30 13:31:21,624 INFO: [Class..][epoch: 11, iter:  35,900, lr:(2.000e-04,)] [eta: 2 days, 13:13:14, time (data): 0.740 (0.003)] l_pix: 1.1923e-02 
2023-10-30 13:32:33,892 INFO: [Class..][epoch: 11, iter:  36,000, lr:(2.000e-04,)] [eta: 2 days, 12:22:41, time (data): 0.731 (0.003)] l_pix: 1.0336e-02 
2023-10-30 13:33:51,619 INFO: [Class..][epoch: 11, iter:  36,100, lr:(2.000e-04,)] [eta: 2 days, 12:02:54, time (data): 0.779 (0.004)] l_pix: 1.4615e-02 
2023-10-30 13:35:13,838 INFO: [Class..][epoch: 11, iter:  36,200, lr:(2.000e-04,)] [eta: 2 days, 12:02:39, time (data): 0.801 (0.005)] l_pix: 1.7040e-02 
2023-10-30 13:36:32,287 INFO: [Class..][epoch: 11, iter:  36,300, lr:(2.000e-04,)] [eta: 2 days, 11:49:29, time (data): 0.779 (0.004)] l_pix: 1.3251e-02 
2023-10-30 13:37:49,175 INFO: [Class..][epoch: 11, iter:  36,400, lr:(2.000e-04,)] [eta: 2 days, 11:33:07, time (data): 0.774 (0.004)] l_pix: 1.2724e-02 
2023-10-30 13:39:01,230 INFO: [Class..][epoch: 11, iter:  36,500, lr:(2.000e-04,)] [eta: 2 days, 11:04:38, time (data): 0.718 (0.004)] l_pix: 1.1550e-02 
2023-10-30 13:40:18,917 INFO: [Class..][epoch: 11, iter:  36,600, lr:(2.000e-04,)] [eta: 2 days, 10:54:59, time (data): 0.748 (0.004)] l_pix: 1.1995e-02 
2023-10-30 13:41:33,612 INFO: [Class..][epoch: 11, iter:  36,700, lr:(2.000e-04,)] [eta: 2 days, 10:38:36, time (data): 0.753 (0.004)] l_pix: 1.1896e-02 
2023-10-30 13:42:48,929 INFO: [Class..][epoch: 11, iter:  36,800, lr:(2.000e-04,)] [eta: 2 days, 10:25:25, time (data): 0.753 (0.004)] l_pix: 1.6156e-02 
2023-10-30 13:44:03,906 INFO: [Class..][epoch: 11, iter:  36,900, lr:(2.000e-04,)] [eta: 2 days, 10:12:42, time (data): 0.753 (0.004)] l_pix: 1.1259e-02 
2023-10-30 13:45:18,611 INFO: [Class..][epoch: 11, iter:  37,000, lr:(2.000e-04,)] [eta: 2 days, 10:00:33, time (data): 0.750 (0.004)] l_pix: 1.9571e-02 
2023-10-30 13:46:32,391 INFO: [Class..][epoch: 11, iter:  37,100, lr:(2.000e-04,)] [eta: 2 days, 9:47:29, time (data): 0.743 (0.004)] l_pix: 1.8993e-02 
2023-10-30 13:47:48,013 INFO: [Class..][epoch: 11, iter:  37,200, lr:(2.000e-04,)] [eta: 2 days, 9:39:10, time (data): 0.750 (0.004)] l_pix: 1.4711e-02 
2023-10-30 13:48:55,953 INFO: [Class..][epoch: 11, iter:  37,300, lr:(2.000e-04,)] [eta: 2 days, 9:16:51, time (data): 0.675 (0.003)] l_pix: 1.5891e-02 
2023-10-30 13:50:00,284 INFO: [Class..][epoch: 11, iter:  37,400, lr:(2.000e-04,)] [eta: 2 days, 8:49:44, time (data): 0.658 (0.003)] l_pix: 1.5004e-02 
2023-10-30 13:51:15,358 INFO: [Class..][epoch: 11, iter:  37,500, lr:(2.000e-04,)] [eta: 2 days, 8:43:28, time (data): 0.746 (0.003)] l_pix: 8.8719e-03 
2023-10-30 13:52:32,295 INFO: [Class..][epoch: 11, iter:  37,600, lr:(2.000e-04,)] [eta: 2 days, 8:40:44, time (data): 0.759 (0.004)] l_pix: 1.3165e-02 
2023-10-30 13:53:47,576 INFO: [Class..][epoch: 11, iter:  37,700, lr:(2.000e-04,)] [eta: 2 days, 8:35:25, time (data): 0.754 (0.004)] l_pix: 1.0838e-02 
2023-10-30 13:56:40,587 INFO: [Class..][epoch: 12, iter:  37,800, lr:(2.000e-04,)] [eta: 2 days, 11:02:52, time (data): 1.276 (0.542)] l_pix: 1.5141e-02 
2023-10-30 13:57:54,218 INFO: [Class..][epoch: 12, iter:  37,900, lr:(2.000e-04,)] [eta: 2 days, 10:50:19, time (data): 0.735 (0.003)] l_pix: 1.3727e-02 
2023-10-30 13:59:08,636 INFO: [Class..][epoch: 12, iter:  38,000, lr:(2.000e-04,)] [eta: 2 days, 10:39:40, time (data): 0.740 (0.003)] l_pix: 1.7974e-02 
2023-10-30 14:00:24,509 INFO: [Class..][epoch: 12, iter:  38,100, lr:(2.000e-04,)] [eta: 2 days, 10:31:40, time (data): 0.742 (0.004)] l_pix: 1.2288e-02 
2023-10-30 14:01:39,441 INFO: [Class..][epoch: 12, iter:  38,200, lr:(2.000e-04,)] [eta: 2 days, 10:22:48, time (data): 0.746 (0.003)] l_pix: 1.2859e-02 
2023-10-30 14:02:53,985 INFO: [Class..][epoch: 12, iter:  38,300, lr:(2.000e-04,)] [eta: 2 days, 10:13:53, time (data): 0.746 (0.003)] l_pix: 1.0948e-02 
2023-10-30 14:04:13,404 INFO: [Class..][epoch: 12, iter:  38,400, lr:(2.000e-04,)] [eta: 2 days, 10:11:40, time (data): 0.772 (0.004)] l_pix: 1.0165e-02 
2023-10-30 14:05:30,578 INFO: [Class..][epoch: 12, iter:  38,500, lr:(2.000e-04,)] [eta: 2 days, 10:06:42, time (data): 0.765 (0.004)] l_pix: 2.0225e-02 
2023-10-30 14:06:47,810 INFO: [Class..][epoch: 12, iter:  38,600, lr:(2.000e-04,)] [eta: 2 days, 10:02:01, time (data): 0.769 (0.004)] l_pix: 1.3080e-02 
2023-10-30 14:08:03,283 INFO: [Class..][epoch: 12, iter:  38,700, lr:(2.000e-04,)] [eta: 2 days, 9:55:27, time (data): 0.748 (0.003)] l_pix: 1.1405e-02 
2023-10-30 14:09:15,905 INFO: [Class..][epoch: 12, iter:  38,800, lr:(2.000e-04,)] [eta: 2 days, 9:45:54, time (data): 0.736 (0.003)] l_pix: 1.4083e-02 
2023-10-30 14:10:31,293 INFO: [Class..][epoch: 12, iter:  38,900, lr:(2.000e-04,)] [eta: 2 days, 9:39:51, time (data): 0.757 (0.004)] l_pix: 1.2366e-02 
2023-10-30 14:11:47,280 INFO: [Class..][epoch: 12, iter:  39,000, lr:(2.000e-04,)] [eta: 2 days, 9:34:42, time (data): 0.758 (0.004)] l_pix: 9.1995e-03 
2023-10-30 14:13:07,648 INFO: [Class..][epoch: 12, iter:  39,100, lr:(2.000e-04,)] [eta: 2 days, 9:34:23, time (data): 0.801 (0.004)] l_pix: 1.2774e-02 
2023-10-30 14:14:27,032 INFO: [Class..][epoch: 12, iter:  39,200, lr:(2.000e-04,)] [eta: 2 days, 9:33:00, time (data): 0.797 (0.004)] l_pix: 1.5437e-02 
2023-10-30 14:15:40,721 INFO: [Class..][epoch: 12, iter:  39,300, lr:(2.000e-04,)] [eta: 2 days, 9:25:52, time (data): 0.734 (0.003)] l_pix: 1.5629e-02 
2023-10-30 14:16:55,164 INFO: [Class..][epoch: 12, iter:  39,400, lr:(2.000e-04,)] [eta: 2 days, 9:19:45, time (data): 0.740 (0.004)] l_pix: 1.2938e-02 
2023-10-30 14:18:05,806 INFO: [Class..][epoch: 12, iter:  39,500, lr:(2.000e-04,)] [eta: 2 days, 9:10:10, time (data): 0.688 (0.003)] l_pix: 1.3237e-02 
2023-10-30 14:19:23,476 INFO: [Class..][epoch: 12, iter:  39,600, lr:(2.000e-04,)] [eta: 2 days, 9:07:36, time (data): 0.738 (0.003)] l_pix: 8.8927e-03 
2023-10-30 14:20:37,691 INFO: [Class..][epoch: 12, iter:  39,700, lr:(2.000e-04,)] [eta: 2 days, 9:01:53, time (data): 0.741 (0.005)] l_pix: 1.0453e-02 
2023-10-30 14:21:45,007 INFO: [Class..][epoch: 12, iter:  39,800, lr:(2.000e-04,)] [eta: 2 days, 8:50:08, time (data): 0.703 (0.004)] l_pix: 1.1735e-02 
2023-10-30 14:22:59,037 INFO: [Class..][epoch: 12, iter:  39,900, lr:(2.000e-04,)] [eta: 2 days, 8:44:45, time (data): 0.744 (0.004)] l_pix: 1.3704e-02 
2023-10-30 14:24:13,599 INFO: [Class..][epoch: 12, iter:  40,000, lr:(2.000e-04,)] [eta: 2 days, 8:39:59, time (data): 0.745 (0.004)] l_pix: 9.4816e-03 
2023-10-30 14:24:13,601 INFO: Saving models and training states.
2023-10-30 14:24:35,078 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-10-30 14:24:44,793 INFO: Validation Set5
	 # psnr: 38.2192	Best: 38.2192 @ 40000 iter
	 # ssim: 0.9619	Best: 0.9619 @ 40000 iter

2023-10-30 14:25:33,510 INFO: Validation Set14
	 # psnr: 33.9360	Best: 33.9360 @ 40000 iter
	 # ssim: 0.9214	Best: 0.9214 @ 40000 iter

2023-10-30 14:29:24,030 INFO: Validation BSD100
	 # psnr: 32.3963	Best: 32.3963 @ 40000 iter
	 # ssim: 0.9031	Best: 0.9031 @ 40000 iter

2023-10-30 14:46:59,591 INFO: Validation Urban100
	 # psnr: 32.9770	Best: 32.9770 @ 40000 iter
	 # ssim: 0.9360	Best: 0.9360 @ 40000 iter

