2023-11-24 06:39:24,653 INFO: 
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-11-24 06:39:24,653 INFO: 
  name: ClassicalX2_012_Pretrained_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
  model_type: SwinIRModel
  scale: 2
  num_gpu: 1
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 6
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Test/HR/Set5/x2
      dataroot_lq: datasets/Test/LR/Set5/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Test/HR/Set14/x2
      dataroot_lq: datasets/Test/LR/Set14/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: datasets/Test/HR/BSD100/x2
      dataroot_lq: datasets/Test/LR/BSD100/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: datasets/Test/HR/Urban100/x2
      dataroot_lq: datasets/Test/LR/Urban100/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: datasets/Test/HR/Manga109/x2
      dataroot_lq: datasets/Test/LR/Manga109/x2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_780000.pth
    strict_load_g: False
    resume_state: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/training_states/780000.state
    experiments_root: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
    models: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights
    training_states: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/training_states
    log: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
    visualization: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/visualization
    tb_logger: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/tb_logger
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [200000, 200000, 200000, 200000, 200000]
      restart_weights: [1, 1, 0.5, 0.5, 0.5]
    ]
    total_iter: 1000000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 10000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 10000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao

2023-11-24 06:39:49,120 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-11-24 06:39:49,120 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 6
	World size (gpu number): 1
	Require iter number per epoch: 5432
	Total epochs: 185; iters: 1000000.
2023-11-24 06:39:49,120 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-11-24 06:39:49,120 INFO: Number of val images/folders in Set5: 5
2023-11-24 06:39:49,121 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-11-24 06:39:49,121 INFO: Number of val images/folders in Set14: 14
2023-11-24 06:39:49,125 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-11-24 06:39:49,125 INFO: Number of val images/folders in BSD100: 100
2023-11-24 06:39:49,129 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-11-24 06:39:49,129 INFO: Number of val images/folders in Urban100: 100
2023-11-24 06:39:49,133 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-11-24 06:39:49,133 INFO: Number of val images/folders in Manga109: 109
2023-11-24 06:39:53,354 INFO: Network: SwinIR, with parameters: 12,267,593
2023-11-24 06:39:53,354 INFO: SwinIR(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-11-24 06:39:56,933 INFO: Loading SwinIR model from /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_780000.pth, with param key: [params].
2023-11-24 06:39:57,078 INFO: Use Exponential Moving Average with decay: 0.999
2023-11-24 06:39:57,207 INFO: Loading SwinIR model from /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_780000.pth, with param key: [params_ema].
2023-11-24 06:39:57,345 INFO: Loss [L1Loss] is created.
2023-11-24 06:39:57,345 WARNING: Params edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-11-24 06:39:57,345 WARNING: Params edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-11-24 06:39:57,349 INFO: Model [SwinIRModel] is created.
2023-11-24 06:39:57,525 INFO: Resuming training from epoch: 254, iter: 780000.
2023-11-24 06:39:57,716 INFO: Start training from epoch: 143, iter: 780000
2023-11-24 06:41:55,034 INFO: [Class..][epoch:143, iter: 780,100, lr:(2.423e-06,)] [eta: 2 days, 23:04:02, time (data): 1.173 (0.008)] l_pix: 1.7466e-02 
2023-11-24 06:43:41,722 INFO: [Class..][epoch:143, iter: 780,200, lr:(2.399e-06,)] [eta: 2 days, 20:06:05, time (data): 1.120 (0.005)] l_pix: 2.0020e-02 
2023-11-24 06:45:37,727 INFO: [Class..][epoch:143, iter: 780,300, lr:(2.375e-06,)] [eta: 2 days, 20:58:32, time (data): 1.160 (0.002)] l_pix: 7.7517e-03 
2023-11-24 06:47:35,461 INFO: [Class..][epoch:143, iter: 780,400, lr:(2.351e-06,)] [eta: 2 days, 21:39:38, time (data): 1.169 (0.002)] l_pix: 1.2342e-02 
2023-11-24 06:49:32,280 INFO: [Class..][epoch:143, iter: 780,500, lr:(2.328e-06,)] [eta: 2 days, 21:56:52, time (data): 1.168 (0.002)] l_pix: 9.5535e-03 
2023-11-24 06:51:29,252 INFO: [Class..][epoch:143, iter: 780,600, lr:(2.304e-06,)] [eta: 2 days, 22:08:39, time (data): 1.169 (0.002)] l_pix: 7.2689e-03 
2023-11-24 06:53:26,646 INFO: [Class..][epoch:143, iter: 780,700, lr:(2.280e-06,)] [eta: 2 days, 22:18:43, time (data): 1.174 (0.002)] l_pix: 6.4995e-03 
2023-11-24 06:55:23,573 INFO: [Class..][epoch:143, iter: 780,800, lr:(2.257e-06,)] [eta: 2 days, 22:23:39, time (data): 1.172 (0.002)] l_pix: 1.4208e-02 
2023-11-24 06:57:20,008 INFO: [Class..][epoch:143, iter: 780,900, lr:(2.234e-06,)] [eta: 2 days, 22:25:03, time (data): 1.164 (0.002)] l_pix: 7.8565e-03 
2023-11-24 06:59:16,072 INFO: [Class..][epoch:143, iter: 781,000, lr:(2.211e-06,)] [eta: 2 days, 22:24:26, time (data): 1.162 (0.002)] l_pix: 2.0678e-03 
2023-11-24 07:01:12,311 INFO: [Class..][epoch:143, iter: 781,100, lr:(2.188e-06,)] [eta: 2 days, 22:24:10, time (data): 1.163 (0.002)] l_pix: 1.5120e-02 
2023-11-24 07:03:08,117 INFO: [Class..][epoch:143, iter: 781,200, lr:(2.165e-06,)] [eta: 2 days, 22:22:18, time (data): 1.160 (0.002)] l_pix: 6.8346e-03 
2023-11-24 07:05:04,048 INFO: [Class..][epoch:143, iter: 781,300, lr:(2.142e-06,)] [eta: 2 days, 22:20:47, time (data): 1.157 (0.002)] l_pix: 8.3509e-03 
2023-11-24 07:06:59,925 INFO: [Class..][epoch:143, iter: 781,400, lr:(2.119e-06,)] [eta: 2 days, 22:19:04, time (data): 1.158 (0.002)] l_pix: 1.1967e-02 
2023-11-24 07:08:56,120 INFO: [Class..][epoch:143, iter: 781,500, lr:(2.097e-06,)] [eta: 2 days, 22:18:05, time (data): 1.161 (0.002)] l_pix: 1.6187e-02 
2023-11-24 07:10:52,748 INFO: [Class..][epoch:143, iter: 781,600, lr:(2.074e-06,)] [eta: 2 days, 22:17:58, time (data): 1.164 (0.002)] l_pix: 9.6284e-03 
2023-11-24 07:12:48,942 INFO: [Class..][epoch:143, iter: 781,700, lr:(2.052e-06,)] [eta: 2 days, 22:16:43, time (data): 1.162 (0.002)] l_pix: 1.0486e-02 
2023-11-24 07:14:45,961 INFO: [Class..][epoch:143, iter: 781,800, lr:(2.030e-06,)] [eta: 2 days, 22:17:03, time (data): 1.166 (0.002)] l_pix: 1.5284e-02 
2023-11-24 07:16:43,330 INFO: [Class..][epoch:143, iter: 781,900, lr:(2.008e-06,)] [eta: 2 days, 22:17:48, time (data): 1.175 (0.002)] l_pix: 1.7465e-02 
2023-11-24 07:18:40,557 INFO: [Class..][epoch:143, iter: 782,000, lr:(1.986e-06,)] [eta: 2 days, 22:18:02, time (data): 1.174 (0.002)] l_pix: 1.0666e-02 
2023-11-24 07:20:37,500 INFO: [Class..][epoch:143, iter: 782,100, lr:(1.964e-06,)] [eta: 2 days, 22:17:34, time (data): 1.169 (0.002)] l_pix: 1.3936e-02 
2023-11-24 07:22:33,787 INFO: [Class..][epoch:143, iter: 782,200, lr:(1.942e-06,)] [eta: 2 days, 22:15:53, time (data): 1.166 (0.002)] l_pix: 1.4832e-02 
2023-11-24 07:24:29,178 INFO: [Class..][epoch:143, iter: 782,300, lr:(1.920e-06,)] [eta: 2 days, 22:12:46, time (data): 1.153 (0.002)] l_pix: 4.7731e-03 
2023-11-24 07:26:24,996 INFO: [Class..][epoch:143, iter: 782,400, lr:(1.899e-06,)] [eta: 2 days, 22:10:24, time (data): 1.156 (0.002)] l_pix: 1.2434e-02 
2023-11-24 07:28:20,623 INFO: [Class..][epoch:143, iter: 782,500, lr:(1.877e-06,)] [eta: 2 days, 22:07:47, time (data): 1.157 (0.002)] l_pix: 1.4246e-02 
2023-11-24 07:30:16,415 INFO: [Class..][epoch:143, iter: 782,600, lr:(1.856e-06,)] [eta: 2 days, 22:05:27, time (data): 1.157 (0.002)] l_pix: 8.1579e-03 
2023-11-24 07:32:12,044 INFO: [Class..][epoch:143, iter: 782,700, lr:(1.835e-06,)] [eta: 2 days, 22:02:56, time (data): 1.155 (0.002)] l_pix: 1.1332e-02 
2023-11-24 07:34:07,394 INFO: [Class..][epoch:143, iter: 782,800, lr:(1.814e-06,)] [eta: 2 days, 22:00:05, time (data): 1.154 (0.002)] l_pix: 1.5513e-02 
2023-11-24 07:36:03,153 INFO: [Class..][epoch:143, iter: 782,900, lr:(1.793e-06,)] [eta: 2 days, 21:57:49, time (data): 1.159 (0.002)] l_pix: 1.6804e-02 
2023-11-24 07:37:59,015 INFO: [Class..][epoch:143, iter: 783,000, lr:(1.772e-06,)] [eta: 2 days, 21:55:42, time (data): 1.159 (0.002)] l_pix: 2.0939e-02 
2023-11-24 07:39:54,752 INFO: [Class..][epoch:143, iter: 783,100, lr:(1.752e-06,)] [eta: 2 days, 21:53:27, time (data): 1.157 (0.002)] l_pix: 1.9808e-02 
2023-11-24 07:41:50,900 INFO: [Class..][epoch:143, iter: 783,200, lr:(1.731e-06,)] [eta: 2 days, 21:51:41, time (data): 1.159 (0.002)] l_pix: 9.9918e-03 
2023-11-24 07:43:47,457 INFO: [Class..][epoch:143, iter: 783,300, lr:(1.711e-06,)] [eta: 2 days, 21:50:21, time (data): 1.165 (0.002)] l_pix: 2.0042e-02 
2023-11-24 07:45:43,927 INFO: [Class..][epoch:143, iter: 783,400, lr:(1.690e-06,)] [eta: 2 days, 21:48:53, time (data): 1.165 (0.002)] l_pix: 1.4416e-02 
2023-11-24 07:47:40,285 INFO: [Class..][epoch:143, iter: 783,500, lr:(1.670e-06,)] [eta: 2 days, 21:47:17, time (data): 1.165 (0.002)] l_pix: 1.1551e-02 
2023-11-24 07:49:36,638 INFO: [Class..][epoch:143, iter: 783,600, lr:(1.650e-06,)] [eta: 2 days, 21:45:40, time (data): 1.164 (0.002)] l_pix: 1.5021e-02 
2023-11-24 07:51:33,053 INFO: [Class..][epoch:143, iter: 783,700, lr:(1.630e-06,)] [eta: 2 days, 21:44:05, time (data): 1.166 (0.002)] l_pix: 8.3634e-03 
2023-11-24 07:53:29,564 INFO: [Class..][epoch:143, iter: 783,800, lr:(1.610e-06,)] [eta: 2 days, 21:42:34, time (data): 1.166 (0.002)] l_pix: 1.4976e-02 
2023-11-24 07:55:25,905 INFO: [Class..][epoch:143, iter: 783,900, lr:(1.591e-06,)] [eta: 2 days, 21:40:53, time (data): 1.163 (0.002)] l_pix: 1.8653e-02 
2023-11-24 07:57:21,936 INFO: [Class..][epoch:143, iter: 784,000, lr:(1.571e-06,)] [eta: 2 days, 21:38:54, time (data): 1.161 (0.002)] l_pix: 5.1820e-03 
2023-11-24 07:59:18,430 INFO: [Class..][epoch:143, iter: 784,100, lr:(1.552e-06,)] [eta: 2 days, 21:37:19, time (data): 1.166 (0.002)] l_pix: 1.6254e-02 
2023-11-24 08:01:15,522 INFO: [Class..][epoch:143, iter: 784,200, lr:(1.532e-06,)] [eta: 2 days, 21:36:15, time (data): 1.169 (0.002)] l_pix: 1.3523e-02 
2023-11-24 08:03:12,772 INFO: [Class..][epoch:143, iter: 784,300, lr:(1.513e-06,)] [eta: 2 days, 21:35:16, time (data): 1.173 (0.002)] l_pix: 5.7336e-03 
2023-11-24 08:05:09,783 INFO: [Class..][epoch:143, iter: 784,400, lr:(1.494e-06,)] [eta: 2 days, 21:34:02, time (data): 1.171 (0.002)] l_pix: 6.8991e-03 
2023-11-24 08:07:06,620 INFO: [Class..][epoch:143, iter: 784,500, lr:(1.475e-06,)] [eta: 2 days, 21:32:38, time (data): 1.169 (0.002)] l_pix: 7.6921e-03 
2023-11-24 08:09:02,874 INFO: [Class..][epoch:143, iter: 784,600, lr:(1.456e-06,)] [eta: 2 days, 21:30:46, time (data): 1.165 (0.002)] l_pix: 1.0491e-02 
2023-11-24 08:10:59,319 INFO: [Class..][epoch:143, iter: 784,700, lr:(1.437e-06,)] [eta: 2 days, 21:29:02, time (data): 1.163 (0.002)] l_pix: 4.1153e-03 
2023-11-24 08:12:55,736 INFO: [Class..][epoch:143, iter: 784,800, lr:(1.419e-06,)] [eta: 2 days, 21:27:16, time (data): 1.163 (0.002)] l_pix: 9.5505e-03 
2023-11-24 08:14:51,678 INFO: [Class..][epoch:143, iter: 784,900, lr:(1.400e-06,)] [eta: 2 days, 21:25:09, time (data): 1.158 (0.002)] l_pix: 1.6439e-02 
2023-11-24 08:16:48,207 INFO: [Class..][epoch:143, iter: 785,000, lr:(1.382e-06,)] [eta: 2 days, 21:23:28, time (data): 1.162 (0.002)] l_pix: 6.0686e-03 
2023-11-24 08:18:44,495 INFO: [Class..][epoch:143, iter: 785,100, lr:(1.363e-06,)] [eta: 2 days, 21:21:36, time (data): 1.162 (0.002)] l_pix: 9.2230e-03 
2023-11-24 08:20:39,117 INFO: [Class..][epoch:143, iter: 785,200, lr:(1.345e-06,)] [eta: 2 days, 21:18:35, time (data): 1.153 (0.002)] l_pix: 8.4950e-03 
2023-11-24 08:22:35,787 INFO: [Class..][epoch:143, iter: 785,300, lr:(1.327e-06,)] [eta: 2 days, 21:16:59, time (data): 1.168 (0.002)] l_pix: 5.2859e-03 
2023-11-24 08:24:32,899 INFO: [Class..][epoch:143, iter: 785,400, lr:(1.309e-06,)] [eta: 2 days, 21:15:40, time (data): 1.170 (0.002)] l_pix: 6.0079e-03 
2023-11-24 08:26:30,604 INFO: [Class..][epoch:144, iter: 785,500, lr:(1.292e-06,)] [eta: 2 days, 21:14:43, time (data): 1.179 (0.008)] l_pix: 7.4885e-03 
2023-11-24 08:28:27,658 INFO: [Class..][epoch:144, iter: 785,600, lr:(1.274e-06,)] [eta: 2 days, 21:13:19, time (data): 1.174 (0.004)] l_pix: 1.5557e-02 
2023-11-24 08:30:24,153 INFO: [Class..][epoch:144, iter: 785,700, lr:(1.256e-06,)] [eta: 2 days, 21:11:33, time (data): 1.165 (0.002)] l_pix: 1.4417e-02 
2023-11-24 08:32:20,158 INFO: [Class..][epoch:144, iter: 785,800, lr:(1.239e-06,)] [eta: 2 days, 21:09:28, time (data): 1.162 (0.002)] l_pix: 3.9926e-03 
2023-11-24 08:34:15,754 INFO: [Class..][epoch:144, iter: 785,900, lr:(1.222e-06,)] [eta: 2 days, 21:07:08, time (data): 1.153 (0.002)] l_pix: 1.3241e-02 
2023-11-24 08:36:12,260 INFO: [Class..][epoch:144, iter: 786,000, lr:(1.204e-06,)] [eta: 2 days, 21:05:22, time (data): 1.160 (0.002)] l_pix: 1.6031e-02 
2023-11-24 08:38:08,977 INFO: [Class..][epoch:144, iter: 786,100, lr:(1.187e-06,)] [eta: 2 days, 21:03:43, time (data): 1.166 (0.002)] l_pix: 9.1476e-03 
2023-11-24 08:40:05,454 INFO: [Class..][epoch:144, iter: 786,200, lr:(1.170e-06,)] [eta: 2 days, 21:01:56, time (data): 1.165 (0.002)] l_pix: 7.5644e-03 
2023-11-24 08:42:01,766 INFO: [Class..][epoch:144, iter: 786,300, lr:(1.153e-06,)] [eta: 2 days, 21:00:02, time (data): 1.163 (0.002)] l_pix: 1.3127e-02 
2023-11-24 08:43:58,016 INFO: [Class..][epoch:144, iter: 786,400, lr:(1.137e-06,)] [eta: 2 days, 20:58:06, time (data): 1.162 (0.002)] l_pix: 8.5097e-03 
2023-11-24 08:45:55,563 INFO: [Class..][epoch:144, iter: 786,500, lr:(1.120e-06,)] [eta: 2 days, 20:56:53, time (data): 1.178 (0.002)] l_pix: 4.6970e-03 
2023-11-24 08:47:52,170 INFO: [Class..][epoch:144, iter: 786,600, lr:(1.104e-06,)] [eta: 2 days, 20:55:08, time (data): 1.171 (0.002)] l_pix: 9.2564e-03 
2023-11-24 08:49:49,324 INFO: [Class..][epoch:144, iter: 786,700, lr:(1.087e-06,)] [eta: 2 days, 20:53:40, time (data): 1.173 (0.002)] l_pix: 9.1627e-03 
2023-11-24 08:51:46,156 INFO: [Class..][epoch:144, iter: 786,800, lr:(1.071e-06,)] [eta: 2 days, 20:52:01, time (data): 1.170 (0.002)] l_pix: 7.8832e-03 
2023-11-24 08:53:43,315 INFO: [Class..][epoch:144, iter: 786,900, lr:(1.055e-06,)] [eta: 2 days, 20:50:31, time (data): 1.171 (0.002)] l_pix: 1.8836e-02 
2023-11-24 08:55:39,949 INFO: [Class..][epoch:144, iter: 787,000, lr:(1.039e-06,)] [eta: 2 days, 20:48:45, time (data): 1.168 (0.002)] l_pix: 6.4146e-03 
2023-11-24 08:57:36,590 INFO: [Class..][epoch:144, iter: 787,100, lr:(1.023e-06,)] [eta: 2 days, 20:46:59, time (data): 1.165 (0.002)] l_pix: 1.3811e-02 
2023-11-24 08:59:33,615 INFO: [Class..][epoch:144, iter: 787,200, lr:(1.007e-06,)] [eta: 2 days, 20:45:24, time (data): 1.168 (0.002)] l_pix: 1.6815e-02 
2023-11-24 09:01:30,207 INFO: [Class..][epoch:144, iter: 787,300, lr:(9.918e-07,)] [eta: 2 days, 20:43:36, time (data): 1.165 (0.002)] l_pix: 5.6922e-03 
2023-11-24 09:03:26,615 INFO: [Class..][epoch:144, iter: 787,400, lr:(9.763e-07,)] [eta: 2 days, 20:41:42, time (data): 1.164 (0.002)] l_pix: 1.2162e-02 
2023-11-24 09:05:23,037 INFO: [Class..][epoch:144, iter: 787,500, lr:(9.609e-07,)] [eta: 2 days, 20:39:48, time (data): 1.164 (0.002)] l_pix: 1.2619e-02 
2023-11-24 09:07:19,895 INFO: [Class..][epoch:144, iter: 787,600, lr:(9.456e-07,)] [eta: 2 days, 20:38:07, time (data): 1.167 (0.002)] l_pix: 3.0801e-02 
2023-11-24 09:09:17,425 INFO: [Class..][epoch:144, iter: 787,700, lr:(9.305e-07,)] [eta: 2 days, 20:36:43, time (data): 1.178 (0.002)] l_pix: 1.0797e-02 
2023-11-24 09:11:14,757 INFO: [Class..][epoch:144, iter: 787,800, lr:(9.155e-07,)] [eta: 2 days, 20:35:14, time (data): 1.175 (0.002)] l_pix: 8.0195e-03 
2023-11-24 09:13:11,991 INFO: [Class..][epoch:144, iter: 787,900, lr:(9.006e-07,)] [eta: 2 days, 20:33:41, time (data): 1.174 (0.002)] l_pix: 1.5027e-02 
2023-11-24 09:15:08,676 INFO: [Class..][epoch:144, iter: 788,000, lr:(8.858e-07,)] [eta: 2 days, 20:31:53, time (data): 1.169 (0.002)] l_pix: 1.4739e-02 
2023-11-24 09:17:04,912 INFO: [Class..][epoch:144, iter: 788,100, lr:(8.711e-07,)] [eta: 2 days, 20:29:53, time (data): 1.165 (0.002)] l_pix: 9.5367e-03 
2023-11-24 09:19:01,351 INFO: [Class..][epoch:144, iter: 788,200, lr:(8.566e-07,)] [eta: 2 days, 20:27:58, time (data): 1.164 (0.002)] l_pix: 1.0108e-02 
2023-11-24 09:20:57,700 INFO: [Class..][epoch:144, iter: 788,300, lr:(8.422e-07,)] [eta: 2 days, 20:26:01, time (data): 1.164 (0.002)] l_pix: 1.0193e-02 
2023-11-24 09:22:54,085 INFO: [Class..][epoch:144, iter: 788,400, lr:(8.279e-07,)] [eta: 2 days, 20:24:05, time (data): 1.164 (0.002)] l_pix: 1.5560e-02 
2023-11-24 09:24:50,541 INFO: [Class..][epoch:144, iter: 788,500, lr:(8.137e-07,)] [eta: 2 days, 20:22:11, time (data): 1.165 (0.002)] l_pix: 1.4461e-02 
2023-11-24 09:26:47,772 INFO: [Class..][epoch:144, iter: 788,600, lr:(7.997e-07,)] [eta: 2 days, 20:20:36, time (data): 1.169 (0.002)] l_pix: 1.6203e-02 
2023-11-24 09:28:44,719 INFO: [Class..][epoch:144, iter: 788,700, lr:(7.857e-07,)] [eta: 2 days, 20:18:53, time (data): 1.171 (0.002)] l_pix: 7.1921e-03 
2023-11-24 09:30:42,206 INFO: [Class..][epoch:144, iter: 788,800, lr:(7.719e-07,)] [eta: 2 days, 20:17:23, time (data): 1.173 (0.002)] l_pix: 1.7001e-02 
2023-11-24 09:32:39,772 INFO: [Class..][epoch:144, iter: 788,900, lr:(7.582e-07,)] [eta: 2 days, 20:15:54, time (data): 1.177 (0.002)] l_pix: 6.2949e-03 
2023-11-24 09:34:36,796 INFO: [Class..][epoch:144, iter: 789,000, lr:(7.447e-07,)] [eta: 2 days, 20:14:12, time (data): 1.173 (0.002)] l_pix: 1.4282e-02 
2023-11-24 09:36:33,439 INFO: [Class..][epoch:144, iter: 789,100, lr:(7.312e-07,)] [eta: 2 days, 20:12:20, time (data): 1.167 (0.002)] l_pix: 8.4410e-03 
2023-11-24 09:38:29,497 INFO: [Class..][epoch:144, iter: 789,200, lr:(7.179e-07,)] [eta: 2 days, 20:10:16, time (data): 1.163 (0.002)] l_pix: 1.5185e-02 
2023-11-24 09:40:26,096 INFO: [Class..][epoch:144, iter: 789,300, lr:(7.047e-07,)] [eta: 2 days, 20:08:23, time (data): 1.166 (0.002)] l_pix: 1.0185e-02 
2023-11-24 09:42:12,135 INFO: [Class..][epoch:144, iter: 789,400, lr:(6.916e-07,)] [eta: 2 days, 20:02:34, time (data): 1.097 (0.002)] l_pix: 1.4050e-02 
2023-11-24 09:43:51,922 INFO: [Class..][epoch:144, iter: 789,500, lr:(6.787e-07,)] [eta: 2 days, 19:54:32, time (data): 0.995 (0.002)] l_pix: 1.2351e-02 
2023-11-24 09:45:35,201 INFO: [Class..][epoch:144, iter: 789,600, lr:(6.658e-07,)] [eta: 2 days, 19:47:54, time (data): 1.020 (0.002)] l_pix: 6.5015e-03 
2023-11-24 09:47:22,363 INFO: [Class..][epoch:144, iter: 789,700, lr:(6.531e-07,)] [eta: 2 days, 19:42:46, time (data): 1.071 (0.002)] l_pix: 1.5235e-02 
2023-11-24 09:49:09,696 INFO: [Class..][epoch:144, iter: 789,800, lr:(6.405e-07,)] [eta: 2 days, 19:37:46, time (data): 1.073 (0.002)] l_pix: 1.1895e-02 
2023-11-24 09:50:57,683 INFO: [Class..][epoch:144, iter: 789,900, lr:(6.281e-07,)] [eta: 2 days, 19:33:04, time (data): 1.082 (0.003)] l_pix: 8.5075e-03 
2023-11-24 09:52:45,560 INFO: [Class..][epoch:144, iter: 790,000, lr:(6.157e-07,)] [eta: 2 days, 19:28:23, time (data): 1.080 (0.003)] l_pix: 1.7195e-02 
2023-11-24 09:52:45,561 INFO: Saving models and training states.
2023-11-24 09:52:46,576 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-24 09:52:59,939 INFO: Validation Set5
	 # psnr: 38.3639	Best: 38.3639 @ 790000 iter
	 # ssim: 0.9620	Best: 0.9620 @ 790000 iter

2023-11-24 09:53:46,221 INFO: Validation Set14
	 # psnr: 34.1453	Best: 34.1453 @ 790000 iter
	 # ssim: 0.9227	Best: 0.9227 @ 790000 iter

2023-11-24 09:57:45,564 INFO: Validation BSD100
	 # psnr: 32.4616	Best: 32.4616 @ 790000 iter
	 # ssim: 0.9031	Best: 0.9031 @ 790000 iter

2023-11-24 10:14:35,138 INFO: Validation Urban100
	 # psnr: 33.4836	Best: 33.4836 @ 790000 iter
	 # ssim: 0.9398	Best: 0.9398 @ 790000 iter

2023-11-24 10:36:27,004 INFO: Validation Manga109
	 # psnr: 39.6442	Best: 39.6442 @ 790000 iter
	 # ssim: 0.9790	Best: 0.9790 @ 790000 iter

2023-11-24 10:38:24,804 INFO: [Class..][epoch:144, iter: 790,100, lr:(6.035e-07,)] [eta: 3 days, 10:35:05, time (data): 1.176 (0.002)] l_pix: 1.7543e-02 
2023-11-24 10:40:21,961 INFO: [Class..][epoch:144, iter: 790,200, lr:(5.914e-07,)] [eta: 3 days, 10:24:20, time (data): 1.173 (0.002)] l_pix: 8.0099e-03 
2023-11-24 10:42:20,441 INFO: [Class..][epoch:144, iter: 790,300, lr:(5.794e-07,)] [eta: 3 days, 10:14:12, time (data): 1.180 (0.002)] l_pix: 2.1392e-02 
2023-11-24 10:44:18,185 INFO: [Class..][epoch:144, iter: 790,400, lr:(5.675e-07,)] [eta: 3 days, 10:03:58, time (data): 1.178 (0.002)] l_pix: 1.2395e-02 
2023-11-24 10:46:15,629 INFO: [Class..][epoch:144, iter: 790,500, lr:(5.558e-07,)] [eta: 3 days, 9:53:48, time (data): 1.174 (0.002)] l_pix: 1.5603e-02 
2023-11-24 10:48:13,249 INFO: [Class..][epoch:144, iter: 790,600, lr:(5.442e-07,)] [eta: 3 days, 9:43:51, time (data): 1.176 (0.002)] l_pix: 1.1070e-02 
2023-11-24 10:50:09,549 INFO: [Class..][epoch:144, iter: 790,700, lr:(5.327e-07,)] [eta: 3 days, 9:33:37, time (data): 1.161 (0.002)] l_pix: 1.1332e-02 
2023-11-24 10:52:06,085 INFO: [Class..][epoch:144, iter: 790,800, lr:(5.213e-07,)] [eta: 3 days, 9:23:37, time (data): 1.164 (0.002)] l_pix: 2.2203e-02 
2023-11-24 10:54:03,372 INFO: [Class..][epoch:145, iter: 790,900, lr:(5.101e-07,)] [eta: 3 days, 9:14:00, time (data): 1.182 (0.015)] l_pix: 8.0462e-03 
2023-11-24 10:56:00,005 INFO: [Class..][epoch:145, iter: 791,000, lr:(4.989e-07,)] [eta: 3 days, 9:04:19, time (data): 1.171 (0.006)] l_pix: 5.5065e-03 
2023-11-24 10:57:56,998 INFO: [Class..][epoch:145, iter: 791,100, lr:(4.879e-07,)] [eta: 3 days, 8:54:53, time (data): 1.171 (0.002)] l_pix: 1.5627e-02 
2023-11-24 10:59:54,072 INFO: [Class..][epoch:145, iter: 791,200, lr:(4.770e-07,)] [eta: 3 days, 8:45:36, time (data): 1.171 (0.002)] l_pix: 1.2842e-02 
2023-11-24 11:01:51,191 INFO: [Class..][epoch:145, iter: 791,300, lr:(4.663e-07,)] [eta: 3 days, 8:36:29, time (data): 1.168 (0.002)] l_pix: 1.0037e-02 
2023-11-24 11:03:47,861 INFO: [Class..][epoch:145, iter: 791,400, lr:(4.556e-07,)] [eta: 3 days, 8:27:20, time (data): 1.167 (0.002)] l_pix: 5.9418e-03 
2023-11-24 11:05:44,699 INFO: [Class..][epoch:145, iter: 791,500, lr:(4.451e-07,)] [eta: 3 days, 8:18:22, time (data): 1.167 (0.002)] l_pix: 2.5054e-02 
2023-11-24 11:07:42,039 INFO: [Class..][epoch:145, iter: 791,600, lr:(4.347e-07,)] [eta: 3 days, 8:09:41, time (data): 1.172 (0.002)] l_pix: 1.6178e-02 
2023-11-24 11:09:39,137 INFO: [Class..][epoch:145, iter: 791,700, lr:(4.244e-07,)] [eta: 3 days, 8:01:02, time (data): 1.168 (0.002)] l_pix: 5.5941e-03 
2023-11-24 11:11:35,676 INFO: [Class..][epoch:145, iter: 791,800, lr:(4.143e-07,)] [eta: 3 days, 7:52:19, time (data): 1.166 (0.002)] l_pix: 1.0357e-02 
2023-11-24 11:13:32,654 INFO: [Class..][epoch:145, iter: 791,900, lr:(4.043e-07,)] [eta: 3 days, 7:43:52, time (data): 1.167 (0.002)] l_pix: 1.1799e-02 
2023-11-24 11:15:29,511 INFO: [Class..][epoch:145, iter: 792,000, lr:(3.944e-07,)] [eta: 3 days, 7:35:29, time (data): 1.168 (0.002)] l_pix: 1.2717e-02 
2023-11-24 11:17:26,778 INFO: [Class..][epoch:145, iter: 792,100, lr:(3.846e-07,)] [eta: 3 days, 7:27:19, time (data): 1.176 (0.002)] l_pix: 9.9971e-03 
2023-11-24 11:19:23,575 INFO: [Class..][epoch:145, iter: 792,200, lr:(3.749e-07,)] [eta: 3 days, 7:19:07, time (data): 1.170 (0.002)] l_pix: 9.2999e-03 
2023-11-24 11:21:20,334 INFO: [Class..][epoch:145, iter: 792,300, lr:(3.654e-07,)] [eta: 3 days, 7:11:01, time (data): 1.167 (0.002)] l_pix: 1.2871e-02 
2023-11-24 11:23:17,117 INFO: [Class..][epoch:145, iter: 792,400, lr:(3.560e-07,)] [eta: 3 days, 7:03:01, time (data): 1.167 (0.002)] l_pix: 1.5653e-02 
2023-11-24 11:25:13,639 INFO: [Class..][epoch:145, iter: 792,500, lr:(3.467e-07,)] [eta: 3 days, 6:55:03, time (data): 1.163 (0.002)] l_pix: 1.5526e-02 
2023-11-24 11:27:09,283 INFO: [Class..][epoch:145, iter: 792,600, lr:(3.375e-07,)] [eta: 3 days, 6:46:56, time (data): 1.158 (0.002)] l_pix: 1.3316e-02 
2023-11-24 11:29:04,328 INFO: [Class..][epoch:145, iter: 792,700, lr:(3.284e-07,)] [eta: 3 days, 6:38:45, time (data): 1.150 (0.002)] l_pix: 7.6633e-03 
2023-11-24 11:30:59,350 INFO: [Class..][epoch:145, iter: 792,800, lr:(3.195e-07,)] [eta: 3 days, 6:30:39, time (data): 1.150 (0.002)] l_pix: 1.3657e-02 
2023-11-24 11:32:54,523 INFO: [Class..][epoch:145, iter: 792,900, lr:(3.107e-07,)] [eta: 3 days, 6:22:42, time (data): 1.151 (0.002)] l_pix: 6.3950e-03 
2023-11-24 11:34:50,208 INFO: [Class..][epoch:145, iter: 793,000, lr:(3.020e-07,)] [eta: 3 days, 6:14:58, time (data): 1.155 (0.002)] l_pix: 7.4361e-03 
2023-11-24 11:36:45,805 INFO: [Class..][epoch:145, iter: 793,100, lr:(2.935e-07,)] [eta: 3 days, 6:07:19, time (data): 1.159 (0.002)] l_pix: 1.4632e-02 
2023-11-24 11:38:41,191 INFO: [Class..][epoch:145, iter: 793,200, lr:(2.850e-07,)] [eta: 3 days, 5:59:41, time (data): 1.155 (0.002)] l_pix: 1.4446e-02 
2023-11-24 11:40:37,115 INFO: [Class..][epoch:145, iter: 793,300, lr:(2.767e-07,)] [eta: 3 days, 5:52:17, time (data): 1.158 (0.002)] l_pix: 1.6923e-02 
2023-11-24 11:42:33,059 INFO: [Class..][epoch:145, iter: 793,400, lr:(2.685e-07,)] [eta: 3 days, 5:44:58, time (data): 1.159 (0.002)] l_pix: 1.2517e-02 
2023-11-24 11:44:28,144 INFO: [Class..][epoch:145, iter: 793,500, lr:(2.605e-07,)] [eta: 3 days, 5:37:30, time (data): 1.150 (0.002)] l_pix: 1.2722e-02 
2023-11-24 11:46:23,951 INFO: [Class..][epoch:145, iter: 793,600, lr:(2.525e-07,)] [eta: 3 days, 5:30:19, time (data): 1.156 (0.002)] l_pix: 8.5478e-03 
2023-11-24 11:48:19,697 INFO: [Class..][epoch:145, iter: 793,700, lr:(2.447e-07,)] [eta: 3 days, 5:23:11, time (data): 1.155 (0.002)] l_pix: 1.2746e-02 
2023-11-24 11:50:15,263 INFO: [Class..][epoch:145, iter: 793,800, lr:(2.370e-07,)] [eta: 3 days, 5:16:05, time (data): 1.156 (0.002)] l_pix: 1.8043e-02 
2023-11-24 11:52:11,710 INFO: [Class..][epoch:145, iter: 793,900, lr:(2.294e-07,)] [eta: 3 days, 5:09:16, time (data): 1.169 (0.002)] l_pix: 9.0290e-03 
2023-11-24 11:54:07,776 INFO: [Class..][epoch:145, iter: 794,000, lr:(2.220e-07,)] [eta: 3 days, 5:02:26, time (data): 1.163 (0.002)] l_pix: 2.0632e-02 
2023-11-24 11:56:03,083 INFO: [Class..][epoch:145, iter: 794,100, lr:(2.146e-07,)] [eta: 3 days, 4:55:29, time (data): 1.158 (0.002)] l_pix: 8.4151e-03 
2023-11-24 11:57:58,186 INFO: [Class..][epoch:145, iter: 794,200, lr:(2.074e-07,)] [eta: 3 days, 4:48:34, time (data): 1.153 (0.002)] l_pix: 1.1884e-02 
2023-11-24 11:59:53,122 INFO: [Class..][epoch:145, iter: 794,300, lr:(2.004e-07,)] [eta: 3 days, 4:41:40, time (data): 1.148 (0.002)] l_pix: 1.5223e-02 
2023-11-24 12:01:47,996 INFO: [Class..][epoch:145, iter: 794,400, lr:(1.934e-07,)] [eta: 3 days, 4:34:50, time (data): 1.149 (0.002)] l_pix: 1.2686e-02 
2023-11-24 12:03:42,899 INFO: [Class..][epoch:145, iter: 794,500, lr:(1.865e-07,)] [eta: 3 days, 4:28:04, time (data): 1.148 (0.002)] l_pix: 1.0810e-02 
2023-11-24 12:05:38,084 INFO: [Class..][epoch:145, iter: 794,600, lr:(1.798e-07,)] [eta: 3 days, 4:21:26, time (data): 1.151 (0.002)] l_pix: 1.4973e-02 
2023-11-24 12:07:33,796 INFO: [Class..][epoch:145, iter: 794,700, lr:(1.732e-07,)] [eta: 3 days, 4:14:59, time (data): 1.150 (0.002)] l_pix: 7.7308e-03 
2023-11-24 12:09:29,130 INFO: [Class..][epoch:145, iter: 794,800, lr:(1.668e-07,)] [eta: 3 days, 4:08:30, time (data): 1.153 (0.002)] l_pix: 7.7931e-03 
2023-11-24 12:11:23,787 INFO: [Class..][epoch:145, iter: 794,900, lr:(1.604e-07,)] [eta: 3 days, 4:01:56, time (data): 1.145 (0.002)] l_pix: 1.4151e-02 
2023-11-24 12:13:19,436 INFO: [Class..][epoch:145, iter: 795,000, lr:(1.542e-07,)] [eta: 3 days, 3:55:39, time (data): 1.154 (0.002)] l_pix: 8.1379e-03 
2023-11-24 12:15:14,965 INFO: [Class..][epoch:145, iter: 795,100, lr:(1.481e-07,)] [eta: 3 days, 3:49:24, time (data): 1.154 (0.002)] l_pix: 1.3826e-02 
2023-11-24 12:17:10,127 INFO: [Class..][epoch:145, iter: 795,200, lr:(1.421e-07,)] [eta: 3 days, 3:43:08, time (data): 1.152 (0.002)] l_pix: 1.1976e-02 
2023-11-24 12:19:05,507 INFO: [Class..][epoch:145, iter: 795,300, lr:(1.363e-07,)] [eta: 3 days, 3:36:58, time (data): 1.156 (0.002)] l_pix: 1.6680e-02 
2023-11-24 12:21:01,261 INFO: [Class..][epoch:145, iter: 795,400, lr:(1.305e-07,)] [eta: 3 days, 3:30:56, time (data): 1.157 (0.002)] l_pix: 2.2624e-02 
2023-11-24 12:22:56,599 INFO: [Class..][epoch:145, iter: 795,500, lr:(1.249e-07,)] [eta: 3 days, 3:24:52, time (data): 1.158 (0.002)] l_pix: 1.8323e-02 
2023-11-24 12:24:51,422 INFO: [Class..][epoch:145, iter: 795,600, lr:(1.194e-07,)] [eta: 3 days, 3:18:44, time (data): 1.150 (0.002)] l_pix: 1.9410e-02 
2023-11-24 12:26:46,222 INFO: [Class..][epoch:145, iter: 795,700, lr:(1.141e-07,)] [eta: 3 days, 3:12:39, time (data): 1.152 (0.002)] l_pix: 1.4084e-02 
2023-11-24 12:28:41,293 INFO: [Class..][epoch:145, iter: 795,800, lr:(1.088e-07,)] [eta: 3 days, 3:06:41, time (data): 1.151 (0.002)] l_pix: 9.0675e-03 
2023-11-24 12:30:36,512 INFO: [Class..][epoch:145, iter: 795,900, lr:(1.037e-07,)] [eta: 3 days, 3:00:48, time (data): 1.151 (0.002)] l_pix: 1.5910e-02 
2023-11-24 12:32:31,803 INFO: [Class..][epoch:145, iter: 796,000, lr:(9.871e-08,)] [eta: 3 days, 2:54:58, time (data): 1.153 (0.002)] l_pix: 7.8144e-03 
2023-11-24 12:34:26,928 INFO: [Class..][epoch:145, iter: 796,100, lr:(9.384e-08,)] [eta: 3 days, 2:49:10, time (data): 1.154 (0.002)] l_pix: 9.8586e-03 
2023-11-24 12:36:22,499 INFO: [Class..][epoch:145, iter: 796,200, lr:(8.909e-08,)] [eta: 3 days, 2:43:30, time (data): 1.155 (0.002)] l_pix: 9.4657e-03 
2023-11-24 12:38:19,317 INFO: [Class..][epoch:146, iter: 796,300, lr:(8.447e-08,)] [eta: 3 days, 2:38:08, time (data): 1.208 (0.060)] l_pix: 1.0626e-02 
2023-11-24 12:40:15,212 INFO: [Class..][epoch:146, iter: 796,400, lr:(7.997e-08,)] [eta: 3 days, 2:32:37, time (data): 1.167 (0.011)] l_pix: 9.8964e-03 
2023-11-24 12:42:10,745 INFO: [Class..][epoch:146, iter: 796,500, lr:(7.559e-08,)] [eta: 3 days, 2:27:05, time (data): 1.157 (0.002)] l_pix: 1.6015e-02 
2023-11-24 12:44:06,911 INFO: [Class..][epoch:146, iter: 796,600, lr:(7.133e-08,)] [eta: 3 days, 2:21:43, time (data): 1.160 (0.002)] l_pix: 1.8115e-02 
2023-11-24 12:46:02,708 INFO: [Class..][epoch:146, iter: 796,700, lr:(6.720e-08,)] [eta: 3 days, 2:16:19, time (data): 1.161 (0.002)] l_pix: 8.0151e-03 
2023-11-24 12:47:58,295 INFO: [Class..][epoch:146, iter: 796,800, lr:(6.319e-08,)] [eta: 3 days, 2:10:54, time (data): 1.157 (0.002)] l_pix: 1.4493e-02 
2023-11-24 12:49:54,115 INFO: [Class..][epoch:146, iter: 796,900, lr:(5.931e-08,)] [eta: 3 days, 2:05:35, time (data): 1.159 (0.002)] l_pix: 6.7311e-03 
2023-11-24 12:51:50,185 INFO: [Class..][epoch:146, iter: 797,000, lr:(5.554e-08,)] [eta: 3 days, 2:00:22, time (data): 1.161 (0.002)] l_pix: 9.1933e-03 
2023-11-24 12:53:45,908 INFO: [Class..][epoch:146, iter: 797,100, lr:(5.190e-08,)] [eta: 3 days, 1:55:07, time (data): 1.164 (0.002)] l_pix: 1.2574e-02 
2023-11-24 12:55:41,608 INFO: [Class..][epoch:146, iter: 797,200, lr:(4.839e-08,)] [eta: 3 days, 1:49:53, time (data): 1.158 (0.002)] l_pix: 1.1644e-02 
