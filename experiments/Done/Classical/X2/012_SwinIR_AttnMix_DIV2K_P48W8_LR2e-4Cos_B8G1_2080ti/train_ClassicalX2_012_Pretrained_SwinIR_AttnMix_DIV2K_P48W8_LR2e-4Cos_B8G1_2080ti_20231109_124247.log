2023-11-09 12:42:47,990 INFO: 
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	PyTorch: 2.0.1
	TorchVision: 0.15.2
2023-11-09 12:42:47,991 INFO: 
  name: ClassicalX2_012_Pretrained_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
  model_type: SwinIRModel
  scale: 2
  num_gpu: 1
  manual_seed: 3407
  datasets:[
    train:[
      name: DIV2K
      type: PairedImageDataset
      dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub
      dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic/X2_sub
      meta_info_file: data/meta_info/meta_info_DIV2K800sub_GT.txt
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      gt_size: 96
      use_hflip: True
      use_rot: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 16
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 2
    ]
    val_1:[
      name: Set5
      type: PairedImageDataset
      dataroot_gt: datasets/Set5/GTmod12
      dataroot_lq: datasets/Set5/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_2:[
      name: Set14
      type: PairedImageDataset
      dataroot_gt: datasets/Set14/GTmod12
      dataroot_lq: datasets/Set14/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_3:[
      name: BSD100
      type: PairedImageDataset
      dataroot_gt: datasets/BSDS100/GTmod12
      dataroot_lq: datasets/BSDS100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_4:[
      name: Urban100
      type: PairedImageDataset
      dataroot_gt: datasets/urban100/GTmod12
      dataroot_lq: datasets/urban100/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
    val_5:[
      name: Manga109
      type: PairedImageDataset
      dataroot_gt: datasets/manga109/GTmod12
      dataroot_lq: datasets/manga109/LRbicx2
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 2
    ]
  ]
  network_g:[
    type: SwinIR
    upscale: 2
    in_chans: 3
    img_size: 48
    window_size: 8
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_320000.pth
    strict_load_g: False
    resume_state: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/training_states/320000.state
    experiments_root: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
    models: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights
    training_states: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/training_states
    log: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti
    visualization: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/visualization
    tb_logger: /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/tb_logger
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: CosineAnnealingRestartLR
      periods: [200000, 200000, 200000, 200000, 200000]
      restart_weights: [1, 1, 0.5, 0.5, 0.5]
    ]
    total_iter: 1000000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 10000.0
    save_img: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 2
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 2
        test_y_channel: True
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 10000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: True
  is_train: True
  root_path: /share3/home/renzihao

2023-11-09 12:42:55,203 INFO: Dataset [PairedImageDataset] - DIV2K is built.
2023-11-09 12:42:55,203 INFO: Training statistics:
	Number of train images: 32592
	Dataset enlarge ratio: 1
	Batch size per gpu: 16
	World size (gpu number): 1
	Require iter number per epoch: 2037
	Total epochs: 491; iters: 1000000.
2023-11-09 12:42:55,204 INFO: Dataset [PairedImageDataset] - Set5 is built.
2023-11-09 12:42:55,204 INFO: Number of val images/folders in Set5: 5
2023-11-09 12:42:55,204 INFO: Dataset [PairedImageDataset] - Set14 is built.
2023-11-09 12:42:55,204 INFO: Number of val images/folders in Set14: 14
2023-11-09 12:42:55,208 INFO: Dataset [PairedImageDataset] - BSD100 is built.
2023-11-09 12:42:55,208 INFO: Number of val images/folders in BSD100: 100
2023-11-09 12:42:55,211 INFO: Dataset [PairedImageDataset] - Urban100 is built.
2023-11-09 12:42:55,212 INFO: Number of val images/folders in Urban100: 100
2023-11-09 12:42:55,215 INFO: Dataset [PairedImageDataset] - Manga109 is built.
2023-11-09 12:42:55,215 INFO: Number of val images/folders in Manga109: 109
2023-11-09 12:42:57,384 INFO: Network: SwinIR, with parameters: 12,267,593
2023-11-09 12:42:57,384 INFO: SwinIR(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (edge_ex): EdgeExtraction(
    (hpf): Sobel(
      (conv_sobel_x): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
      (conv_sobel_y): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)
    )
    (conv): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1-5): 5 x RSTB(
      (residual_group): BasicLayer(
        dim=180, input_resolution=(48, 48), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=180, input_resolution=(48, 48), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=180, window_size=(8, 8), num_heads=6
              (qk): Linear(in_features=180, out_features=360, bias=True)
              (v): Linear(in_features=180, out_features=180, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_scale): LearnableScale()
            (conv_block): CAB(
              (cab): Sequential(
                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (1): GELU(approximate='none')
                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)
                (3): ChannelAttention(
                  (attention): Sequential(
                    (0): AdaptiveAvgPool2d(output_size=1)
                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (2): ReLU(inplace=True)
                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1), groups=6)
                    (4): Sigmoid()
                  )
                )
              )
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=180, out_features=360, bias=True)
              (act): GELU(approximate='none')
              (dwconv): dwconv(
                (depthwise_conv): Sequential(
                  (0): Conv2d(360, 360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=360)
                  (1): GELU(approximate='none')
                )
              )
              (fc2): Linear(in_features=360, out_features=180, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (edge_convs): ModuleList(
    (0-5): 6 x EdgeConv(
      (dwconv): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180)
      (gelu): GELU(approximate='none')
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2023-11-09 12:42:58,236 INFO: Loading SwinIR model from /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_320000.pth, with param key: [params].
2023-11-09 12:42:58,412 INFO: Use Exponential Moving Average with decay: 0.999
2023-11-09 12:42:58,582 INFO: Loading SwinIR model from /share3/home/renzihao/Pipeline/experiments/Doing/012_SwinIR_AttnMix_DIV2K_P48W8_LR2e-4Cos_B8G1_2080ti/weights/net_g_320000.pth, with param key: [params_ema].
2023-11-09 12:42:58,766 INFO: Loss [L1Loss] is created.
2023-11-09 12:42:58,766 WARNING: Params edge_ex.hpf.conv_sobel_x.weight will not be optimized.
2023-11-09 12:42:58,766 WARNING: Params edge_ex.hpf.conv_sobel_y.weight will not be optimized.
2023-11-09 12:42:58,770 INFO: Model [SwinIRModel] is created.
2023-11-09 12:42:58,989 INFO: Resuming training from epoch: 56, iter: 320000.
2023-11-09 12:42:59,211 INFO: Start training from epoch: 56, iter: 320000
2023-11-09 12:46:13,060 INFO: [Class..][epoch: 56, iter: 320,100, lr:(6.895e-05,)] [eta: 15 days, 2:53:26, time (data): 1.938 (0.017)] l_pix: 1.0354e-02 
2023-11-09 12:49:24,983 INFO: [Class..][epoch: 56, iter: 320,200, lr:(6.880e-05,)] [eta: 15 days, 2:37:42, time (data): 1.929 (0.009)] l_pix: 1.5309e-02 
2023-11-09 12:52:40,989 INFO: [Class..][epoch: 56, iter: 320,300, lr:(6.865e-05,)] [eta: 15 days, 5:03:52, time (data): 1.960 (0.002)] l_pix: 1.3329e-02 
2023-11-09 12:55:55,192 INFO: [Class..][epoch: 56, iter: 320,400, lr:(6.850e-05,)] [eta: 15 days, 5:24:35, time (data): 1.951 (0.002)] l_pix: 1.2739e-02 
2023-11-09 12:59:08,351 INFO: [Class..][epoch: 56, iter: 320,500, lr:(6.835e-05,)] [eta: 15 days, 5:12:09, time (data): 1.932 (0.002)] l_pix: 9.9240e-03 
2023-11-09 13:02:21,901 INFO: [Class..][epoch: 56, iter: 320,600, lr:(6.820e-05,)] [eta: 15 days, 5:10:09, time (data): 1.934 (0.002)] l_pix: 1.2263e-02 
2023-11-09 13:05:36,211 INFO: [Class..][epoch: 56, iter: 320,700, lr:(6.806e-05,)] [eta: 15 days, 5:20:05, time (data): 1.943 (0.002)] l_pix: 1.3635e-02 
2023-11-09 13:08:50,513 INFO: [Class..][epoch: 56, iter: 320,800, lr:(6.791e-05,)] [eta: 15 days, 5:26:36, time (data): 1.943 (0.002)] l_pix: 1.3219e-02 
2023-11-09 13:12:04,266 INFO: [Class..][epoch: 56, iter: 320,900, lr:(6.776e-05,)] [eta: 15 days, 5:24:03, time (data): 1.937 (0.002)] l_pix: 1.1452e-02 
2023-11-09 13:15:17,994 INFO: [Class..][epoch: 56, iter: 321,000, lr:(6.761e-05,)] [eta: 15 days, 5:21:06, time (data): 1.937 (0.002)] l_pix: 8.2117e-03 
2023-11-09 13:18:33,127 INFO: [Class..][epoch: 56, iter: 321,100, lr:(6.746e-05,)] [eta: 15 days, 5:32:32, time (data): 1.953 (0.003)] l_pix: 1.1226e-02 
2023-11-09 13:21:48,126 INFO: [Class..][epoch: 56, iter: 321,200, lr:(6.731e-05,)] [eta: 15 days, 5:40:15, time (data): 1.951 (0.002)] l_pix: 1.3500e-02 
2023-11-09 13:25:02,732 INFO: [Class..][epoch: 56, iter: 321,300, lr:(6.716e-05,)] [eta: 15 days, 5:42:52, time (data): 1.944 (0.002)] l_pix: 9.9565e-03 
2023-11-09 13:28:16,377 INFO: [Class..][epoch: 56, iter: 321,400, lr:(6.702e-05,)] [eta: 15 days, 5:36:54, time (data): 1.940 (0.002)] l_pix: 1.3191e-02 
2023-11-09 13:31:29,947 INFO: [Class..][epoch: 56, iter: 321,500, lr:(6.687e-05,)] [eta: 15 days, 5:30:43, time (data): 1.936 (0.002)] l_pix: 1.5569e-02 
2023-11-09 13:34:43,738 INFO: [Class..][epoch: 56, iter: 321,600, lr:(6.672e-05,)] [eta: 15 days, 5:26:28, time (data): 1.937 (0.002)] l_pix: 1.3271e-02 
2023-11-09 13:37:57,891 INFO: [Class..][epoch: 56, iter: 321,700, lr:(6.657e-05,)] [eta: 15 days, 5:24:45, time (data): 1.943 (0.002)] l_pix: 1.1166e-02 
2023-11-09 13:41:12,057 INFO: [Class..][epoch: 56, iter: 321,800, lr:(6.642e-05,)] [eta: 15 days, 5:22:57, time (data): 1.942 (0.002)] l_pix: 1.2575e-02 
2023-11-09 13:44:25,749 INFO: [Class..][epoch: 56, iter: 321,900, lr:(6.628e-05,)] [eta: 15 days, 5:18:10, time (data): 1.936 (0.002)] l_pix: 8.9273e-03 
2023-11-09 13:47:38,989 INFO: [Class..][epoch: 56, iter: 322,000, lr:(6.613e-05,)] [eta: 15 days, 5:11:00, time (data): 1.934 (0.002)] l_pix: 1.5675e-02 
2023-11-09 13:50:53,753 INFO: [Class..][epoch: 57, iter: 322,100, lr:(6.598e-05,)] [eta: 15 days, 5:12:24, time (data): 1.950 (0.010)] l_pix: 1.1903e-02 
2023-11-09 13:54:07,192 INFO: [Class..][epoch: 57, iter: 322,200, lr:(6.583e-05,)] [eta: 15 days, 5:06:34, time (data): 1.942 (0.006)] l_pix: 1.3065e-02 
2023-11-09 13:57:20,749 INFO: [Class..][epoch: 57, iter: 322,300, lr:(6.568e-05,)] [eta: 15 days, 5:01:33, time (data): 1.936 (0.002)] l_pix: 1.3762e-02 
2023-11-09 14:00:35,034 INFO: [Class..][epoch: 57, iter: 322,400, lr:(6.554e-05,)] [eta: 15 days, 5:00:07, time (data): 1.940 (0.002)] l_pix: 1.3091e-02 
2023-11-09 14:03:49,110 INFO: [Class..][epoch: 57, iter: 322,500, lr:(6.539e-05,)] [eta: 15 days, 4:57:35, time (data): 1.941 (0.002)] l_pix: 1.3416e-02 
2023-11-09 14:07:03,039 INFO: [Class..][epoch: 57, iter: 322,600, lr:(6.524e-05,)] [eta: 15 days, 4:54:21, time (data): 1.940 (0.002)] l_pix: 1.1760e-02 
2023-11-09 14:10:16,312 INFO: [Class..][epoch: 57, iter: 322,700, lr:(6.510e-05,)] [eta: 15 days, 4:48:23, time (data): 1.934 (0.002)] l_pix: 1.3651e-02 
2023-11-09 14:13:29,120 INFO: [Class..][epoch: 57, iter: 322,800, lr:(6.495e-05,)] [eta: 15 days, 4:40:45, time (data): 1.931 (0.002)] l_pix: 1.2803e-02 
2023-11-09 14:16:41,533 INFO: [Class..][epoch: 57, iter: 322,900, lr:(6.480e-05,)] [eta: 15 days, 4:31:52, time (data): 1.924 (0.002)] l_pix: 1.0740e-02 
2023-11-09 14:19:54,605 INFO: [Class..][epoch: 57, iter: 323,000, lr:(6.465e-05,)] [eta: 15 days, 4:25:51, time (data): 1.927 (0.002)] l_pix: 9.2045e-03 
2023-11-09 14:23:07,861 INFO: [Class..][epoch: 57, iter: 323,100, lr:(6.451e-05,)] [eta: 15 days, 4:20:41, time (data): 1.932 (0.002)] l_pix: 1.8989e-02 
2023-11-09 14:26:20,242 INFO: [Class..][epoch: 57, iter: 323,200, lr:(6.436e-05,)] [eta: 15 days, 4:12:33, time (data): 1.927 (0.002)] l_pix: 1.1251e-02 
2023-11-09 14:29:32,492 INFO: [Class..][epoch: 57, iter: 323,300, lr:(6.421e-05,)] [eta: 15 days, 4:04:16, time (data): 1.922 (0.002)] l_pix: 1.8242e-02 
2023-11-09 14:32:44,851 INFO: [Class..][epoch: 57, iter: 323,400, lr:(6.407e-05,)] [eta: 15 days, 3:56:39, time (data): 1.923 (0.002)] l_pix: 1.1906e-02 
2023-11-09 14:35:57,742 INFO: [Class..][epoch: 57, iter: 323,500, lr:(6.392e-05,)] [eta: 15 days, 3:50:59, time (data): 1.930 (0.002)] l_pix: 1.1753e-02 
2023-11-09 14:39:12,385 INFO: [Class..][epoch: 57, iter: 323,600, lr:(6.377e-05,)] [eta: 15 days, 3:50:57, time (data): 1.939 (0.002)] l_pix: 1.0265e-02 
2023-11-09 14:42:26,827 INFO: [Class..][epoch: 57, iter: 323,700, lr:(6.363e-05,)] [eta: 15 days, 3:50:08, time (data): 1.944 (0.002)] l_pix: 1.2359e-02 
2023-11-09 14:45:40,777 INFO: [Class..][epoch: 57, iter: 323,800, lr:(6.348e-05,)] [eta: 15 days, 3:47:44, time (data): 1.942 (0.002)] l_pix: 1.1656e-02 
2023-11-09 14:48:55,188 INFO: [Class..][epoch: 57, iter: 323,900, lr:(6.334e-05,)] [eta: 15 days, 3:46:36, time (data): 1.945 (0.002)] l_pix: 1.6039e-02 
2023-11-09 14:52:09,039 INFO: [Class..][epoch: 57, iter: 324,000, lr:(6.319e-05,)] [eta: 15 days, 3:43:49, time (data): 1.941 (0.002)] l_pix: 1.0884e-02 
2023-11-09 14:55:23,147 INFO: [Class..][epoch: 58, iter: 324,100, lr:(6.304e-05,)] [eta: 15 days, 3:41:42, time (data): 1.942 (0.010)] l_pix: 8.8466e-03 
2023-11-09 14:58:37,197 INFO: [Class..][epoch: 58, iter: 324,200, lr:(6.290e-05,)] [eta: 15 days, 3:39:22, time (data): 1.941 (0.006)] l_pix: 1.0913e-02 
2023-11-09 15:01:51,709 INFO: [Class..][epoch: 58, iter: 324,300, lr:(6.275e-05,)] [eta: 15 days, 3:38:13, time (data): 1.947 (0.002)] l_pix: 9.2145e-03 
2023-11-09 15:05:05,650 INFO: [Class..][epoch: 58, iter: 324,400, lr:(6.261e-05,)] [eta: 15 days, 3:35:30, time (data): 1.943 (0.002)] l_pix: 1.2962e-02 
2023-11-09 15:08:20,121 INFO: [Class..][epoch: 58, iter: 324,500, lr:(6.246e-05,)] [eta: 15 days, 3:34:05, time (data): 1.948 (0.002)] l_pix: 1.1566e-02 
2023-11-09 15:11:33,453 INFO: [Class..][epoch: 58, iter: 324,600, lr:(6.231e-05,)] [eta: 15 days, 3:29:49, time (data): 1.940 (0.002)] l_pix: 1.5558e-02 
2023-11-09 15:14:50,406 INFO: [Class..][epoch: 58, iter: 324,700, lr:(6.217e-05,)] [eta: 15 days, 3:34:15, time (data): 1.964 (0.003)] l_pix: 1.2960e-02 
2023-11-09 15:18:08,016 INFO: [Class..][epoch: 58, iter: 324,800, lr:(6.202e-05,)] [eta: 15 days, 3:39:54, time (data): 1.971 (0.003)] l_pix: 8.7744e-03 
2023-11-09 15:21:27,928 INFO: [Class..][epoch: 58, iter: 324,900, lr:(6.188e-05,)] [eta: 15 days, 3:50:29, time (data): 2.000 (0.003)] l_pix: 1.3922e-02 
2023-11-09 15:24:46,155 INFO: [Class..][epoch: 58, iter: 325,000, lr:(6.173e-05,)] [eta: 15 days, 3:56:43, time (data): 1.990 (0.003)] l_pix: 1.8800e-02 
2023-11-09 15:28:02,016 INFO: [Class..][epoch: 58, iter: 325,100, lr:(6.159e-05,)] [eta: 15 days, 3:57:21, time (data): 1.948 (0.002)] l_pix: 9.3684e-03 
2023-11-09 15:31:16,499 INFO: [Class..][epoch: 58, iter: 325,200, lr:(6.144e-05,)] [eta: 15 days, 3:54:52, time (data): 1.946 (0.002)] l_pix: 1.1246e-02 
2023-11-09 15:34:30,628 INFO: [Class..][epoch: 58, iter: 325,300, lr:(6.130e-05,)] [eta: 15 days, 3:51:35, time (data): 1.940 (0.002)] l_pix: 1.8807e-02 
2023-11-09 15:37:44,331 INFO: [Class..][epoch: 58, iter: 325,400, lr:(6.115e-05,)] [eta: 15 days, 3:47:26, time (data): 1.938 (0.002)] l_pix: 1.4579e-02 
2023-11-09 15:40:58,812 INFO: [Class..][epoch: 58, iter: 325,500, lr:(6.101e-05,)] [eta: 15 days, 3:44:54, time (data): 1.948 (0.002)] l_pix: 1.5421e-02 
2023-11-09 15:44:13,474 INFO: [Class..][epoch: 58, iter: 325,600, lr:(6.086e-05,)] [eta: 15 days, 3:42:42, time (data): 1.947 (0.002)] l_pix: 1.0838e-02 
2023-11-09 15:47:27,370 INFO: [Class..][epoch: 58, iter: 325,700, lr:(6.072e-05,)] [eta: 15 days, 3:38:58, time (data): 1.939 (0.002)] l_pix: 1.5253e-02 
2023-11-09 15:50:40,951 INFO: [Class..][epoch: 58, iter: 325,800, lr:(6.058e-05,)] [eta: 15 days, 3:34:38, time (data): 1.937 (0.002)] l_pix: 1.0436e-02 
2023-11-09 15:53:54,327 INFO: [Class..][epoch: 58, iter: 325,900, lr:(6.043e-05,)] [eta: 15 days, 3:29:57, time (data): 1.933 (0.002)] l_pix: 1.3254e-02 
2023-11-09 15:57:07,962 INFO: [Class..][epoch: 58, iter: 326,000, lr:(6.029e-05,)] [eta: 15 days, 3:25:47, time (data): 1.935 (0.002)] l_pix: 1.5663e-02 
2023-11-09 16:00:22,013 INFO: [Class..][epoch: 58, iter: 326,100, lr:(6.014e-05,)] [eta: 15 days, 3:22:26, time (data): 1.940 (0.002)] l_pix: 1.0630e-02 
2023-11-09 16:03:38,088 INFO: [Class..][epoch: 59, iter: 326,200, lr:(6.000e-05,)] [eta: 15 days, 3:22:45, time (data): 1.952 (0.006)] l_pix: 1.1567e-02 
2023-11-09 16:06:52,887 INFO: [Class..][epoch: 59, iter: 326,300, lr:(5.985e-05,)] [eta: 15 days, 3:20:40, time (data): 1.949 (0.002)] l_pix: 1.1333e-02 
2023-11-09 16:10:06,756 INFO: [Class..][epoch: 59, iter: 326,400, lr:(5.971e-05,)] [eta: 15 days, 3:16:56, time (data): 1.943 (0.002)] l_pix: 1.4516e-02 
2023-11-09 16:13:19,220 INFO: [Class..][epoch: 59, iter: 326,500, lr:(5.957e-05,)] [eta: 15 days, 3:10:46, time (data): 1.926 (0.002)] l_pix: 1.0976e-02 
2023-11-09 16:16:31,588 INFO: [Class..][epoch: 59, iter: 326,600, lr:(5.942e-05,)] [eta: 15 days, 3:04:33, time (data): 1.925 (0.002)] l_pix: 1.1626e-02 
2023-11-09 16:19:44,004 INFO: [Class..][epoch: 59, iter: 326,700, lr:(5.928e-05,)] [eta: 15 days, 2:58:29, time (data): 1.925 (0.002)] l_pix: 1.2034e-02 
2023-11-09 16:22:57,141 INFO: [Class..][epoch: 59, iter: 326,800, lr:(5.914e-05,)] [eta: 15 days, 2:53:42, time (data): 1.929 (0.002)] l_pix: 1.4303e-02 
2023-11-09 16:26:10,682 INFO: [Class..][epoch: 59, iter: 326,900, lr:(5.899e-05,)] [eta: 15 days, 2:49:37, time (data): 1.936 (0.002)] l_pix: 1.1903e-02 
2023-11-09 16:29:23,451 INFO: [Class..][epoch: 59, iter: 327,000, lr:(5.885e-05,)] [eta: 15 days, 2:44:20, time (data): 1.931 (0.002)] l_pix: 1.6731e-02 
2023-11-09 16:32:36,011 INFO: [Class..][epoch: 59, iter: 327,100, lr:(5.871e-05,)] [eta: 15 days, 2:38:46, time (data): 1.923 (0.002)] l_pix: 1.9746e-02 
2023-11-09 16:35:48,257 INFO: [Class..][epoch: 59, iter: 327,200, lr:(5.856e-05,)] [eta: 15 days, 2:32:47, time (data): 1.923 (0.002)] l_pix: 1.7053e-02 
2023-11-09 16:39:00,600 INFO: [Class..][epoch: 59, iter: 327,300, lr:(5.842e-05,)] [eta: 15 days, 2:27:01, time (data): 1.924 (0.002)] l_pix: 1.5082e-02 
2023-11-09 16:42:13,346 INFO: [Class..][epoch: 59, iter: 327,400, lr:(5.828e-05,)] [eta: 15 days, 2:21:56, time (data): 1.926 (0.002)] l_pix: 1.1714e-02 
2023-11-09 16:45:26,531 INFO: [Class..][epoch: 59, iter: 327,500, lr:(5.814e-05,)] [eta: 15 days, 2:17:33, time (data): 1.932 (0.002)] l_pix: 1.3644e-02 
2023-11-09 16:48:39,434 INFO: [Class..][epoch: 59, iter: 327,600, lr:(5.799e-05,)] [eta: 15 days, 2:12:47, time (data): 1.930 (0.002)] l_pix: 1.7384e-02 
2023-11-09 16:51:51,704 INFO: [Class..][epoch: 59, iter: 327,700, lr:(5.785e-05,)] [eta: 15 days, 2:07:09, time (data): 1.923 (0.002)] l_pix: 9.1067e-03 
2023-11-09 16:55:03,973 INFO: [Class..][epoch: 59, iter: 327,800, lr:(5.771e-05,)] [eta: 15 days, 2:01:34, time (data): 1.923 (0.002)] l_pix: 1.1527e-02 
2023-11-09 16:58:16,435 INFO: [Class..][epoch: 59, iter: 327,900, lr:(5.757e-05,)] [eta: 15 days, 1:56:19, time (data): 1.926 (0.002)] l_pix: 9.4200e-03 
2023-11-09 17:01:28,924 INFO: [Class..][epoch: 59, iter: 328,000, lr:(5.742e-05,)] [eta: 15 days, 1:51:09, time (data): 1.925 (0.002)] l_pix: 2.3117e-02 
2023-11-09 17:04:42,423 INFO: [Class..][epoch: 59, iter: 328,100, lr:(5.728e-05,)] [eta: 15 days, 1:47:26, time (data): 1.939 (0.002)] l_pix: 1.4900e-02 
2023-11-09 17:07:56,964 INFO: [Class..][epoch: 60, iter: 328,200, lr:(5.714e-05,)] [eta: 15 days, 1:45:09, time (data): 1.943 (0.006)] l_pix: 9.4627e-03 
2023-11-09 17:11:09,427 INFO: [Class..][epoch: 60, iter: 328,300, lr:(5.700e-05,)] [eta: 15 days, 1:40:03, time (data): 1.922 (0.002)] l_pix: 9.5586e-03 
2023-11-09 17:14:21,867 INFO: [Class..][epoch: 60, iter: 328,400, lr:(5.686e-05,)] [eta: 15 days, 1:34:57, time (data): 1.923 (0.002)] l_pix: 9.3860e-03 
2023-11-09 17:17:34,186 INFO: [Class..][epoch: 60, iter: 328,500, lr:(5.671e-05,)] [eta: 15 days, 1:29:45, time (data): 1.923 (0.002)] l_pix: 1.1673e-02 
2023-11-09 17:20:46,784 INFO: [Class..][epoch: 60, iter: 328,600, lr:(5.657e-05,)] [eta: 15 days, 1:24:57, time (data): 1.925 (0.002)] l_pix: 1.3368e-02 
2023-11-09 17:23:59,534 INFO: [Class..][epoch: 60, iter: 328,700, lr:(5.643e-05,)] [eta: 15 days, 1:20:23, time (data): 1.929 (0.002)] l_pix: 1.1856e-02 
2023-11-09 17:27:12,910 INFO: [Class..][epoch: 60, iter: 328,800, lr:(5.629e-05,)] [eta: 15 days, 1:16:39, time (data): 1.932 (0.002)] l_pix: 9.8863e-03 
2023-11-09 17:30:26,071 INFO: [Class..][epoch: 60, iter: 328,900, lr:(5.615e-05,)] [eta: 15 days, 1:12:39, time (data): 1.930 (0.002)] l_pix: 1.2028e-02 
2023-11-09 17:33:38,886 INFO: [Class..][epoch: 60, iter: 329,000, lr:(5.601e-05,)] [eta: 15 days, 1:08:14, time (data): 1.929 (0.002)] l_pix: 1.0325e-02 
2023-11-09 17:36:51,899 INFO: [Class..][epoch: 60, iter: 329,100, lr:(5.587e-05,)] [eta: 15 days, 1:04:06, time (data): 1.923 (0.002)] l_pix: 1.2976e-02 
2023-11-09 17:40:04,118 INFO: [Class..][epoch: 60, iter: 329,200, lr:(5.573e-05,)] [eta: 15 days, 0:59:01, time (data): 1.922 (0.002)] l_pix: 9.2018e-03 
2023-11-09 17:43:16,986 INFO: [Class..][epoch: 60, iter: 329,300, lr:(5.558e-05,)] [eta: 15 days, 0:54:45, time (data): 1.929 (0.002)] l_pix: 1.2498e-02 
2023-11-09 17:46:30,438 INFO: [Class..][epoch: 60, iter: 329,400, lr:(5.544e-05,)] [eta: 15 days, 0:51:12, time (data): 1.932 (0.002)] l_pix: 1.5618e-02 
2023-11-09 17:49:43,579 INFO: [Class..][epoch: 60, iter: 329,500, lr:(5.530e-05,)] [eta: 15 days, 0:47:17, time (data): 1.929 (0.002)] l_pix: 1.6363e-02 
2023-11-09 17:52:56,041 INFO: [Class..][epoch: 60, iter: 329,600, lr:(5.516e-05,)] [eta: 15 days, 0:42:36, time (data): 1.926 (0.002)] l_pix: 1.1423e-02 
2023-11-09 17:56:10,867 INFO: [Class..][epoch: 60, iter: 329,700, lr:(5.502e-05,)] [eta: 15 days, 0:40:41, time (data): 1.950 (0.002)] l_pix: 1.0481e-02 
2023-11-09 17:59:25,770 INFO: [Class..][epoch: 60, iter: 329,800, lr:(5.488e-05,)] [eta: 15 days, 0:38:48, time (data): 1.949 (0.002)] l_pix: 1.5094e-02 
2023-11-09 18:02:41,195 INFO: [Class..][epoch: 60, iter: 329,900, lr:(5.474e-05,)] [eta: 15 days, 0:37:30, time (data): 1.955 (0.002)] l_pix: 1.4011e-02 
2023-11-09 18:05:55,126 INFO: [Class..][epoch: 60, iter: 330,000, lr:(5.460e-05,)] [eta: 15 days, 0:34:29, time (data): 1.944 (0.002)] l_pix: 9.6167e-03 
2023-11-09 18:05:55,127 INFO: Saving models and training states.
2023-11-09 18:05:55,878 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-09 18:05:59,775 INFO: Validation Set5
	 # psnr: 38.2613	Best: 38.2613 @ 330000 iter
	 # ssim: 0.9623	Best: 0.9623 @ 330000 iter

2023-11-09 18:06:21,142 INFO: Validation Set14
	 # psnr: 33.9875	Best: 33.9875 @ 330000 iter
	 # ssim: 0.9223	Best: 0.9223 @ 330000 iter

2023-11-09 18:07:36,795 INFO: Validation BSD100
	 # psnr: 32.4237	Best: 32.4237 @ 330000 iter
	 # ssim: 0.9035	Best: 0.9035 @ 330000 iter

2023-11-09 18:16:15,428 INFO: Validation Urban100
	 # psnr: 33.3052	Best: 33.3052 @ 330000 iter
	 # ssim: 0.9386	Best: 0.9386 @ 330000 iter

2023-11-09 18:27:14,538 INFO: Validation Manga109
	 # psnr: 39.4941	Best: 39.4941 @ 330000 iter
	 # ssim: 0.9791	Best: 0.9791 @ 330000 iter

2023-11-09 18:30:27,854 INFO: [Class..][epoch: 60, iter: 330,100, lr:(5.446e-05,)] [eta: 16 days, 0:04:58, time (data): 1.937 (0.002)] l_pix: 1.3565e-02 
2023-11-09 18:33:41,424 INFO: [Class..][epoch: 61, iter: 330,200, lr:(5.432e-05,)] [eta: 15 days, 23:47:28, time (data): 1.936 (0.007)] l_pix: 1.1122e-02 
2023-11-09 18:36:54,825 INFO: [Class..][epoch: 61, iter: 330,300, lr:(5.418e-05,)] [eta: 15 days, 23:30:05, time (data): 1.931 (0.002)] l_pix: 1.2032e-02 
2023-11-09 18:40:08,099 INFO: [Class..][epoch: 61, iter: 330,400, lr:(5.404e-05,)] [eta: 15 days, 23:12:50, time (data): 1.932 (0.002)] l_pix: 1.8780e-02 
2023-11-09 18:43:20,913 INFO: [Class..][epoch: 61, iter: 330,500, lr:(5.390e-05,)] [eta: 15 days, 22:55:21, time (data): 1.926 (0.002)] l_pix: 1.7126e-02 
2023-11-09 18:46:34,572 INFO: [Class..][epoch: 61, iter: 330,600, lr:(5.376e-05,)] [eta: 15 days, 22:39:02, time (data): 1.933 (0.002)] l_pix: 1.3684e-02 
2023-11-09 18:49:48,245 INFO: [Class..][epoch: 61, iter: 330,700, lr:(5.363e-05,)] [eta: 15 days, 22:22:59, time (data): 1.935 (0.002)] l_pix: 1.5735e-02 
2023-11-09 18:53:00,912 INFO: [Class..][epoch: 61, iter: 330,800, lr:(5.349e-05,)] [eta: 15 days, 22:06:07, time (data): 1.929 (0.002)] l_pix: 1.1333e-02 
2023-11-09 18:56:13,920 INFO: [Class..][epoch: 61, iter: 330,900, lr:(5.335e-05,)] [eta: 15 days, 21:49:51, time (data): 1.928 (0.002)] l_pix: 1.4467e-02 
2023-11-09 18:59:26,530 INFO: [Class..][epoch: 61, iter: 331,000, lr:(5.321e-05,)] [eta: 15 days, 21:33:26, time (data): 1.927 (0.002)] l_pix: 7.0903e-03 
2023-11-09 19:02:39,256 INFO: [Class..][epoch: 61, iter: 331,100, lr:(5.307e-05,)] [eta: 15 days, 21:17:21, time (data): 1.929 (0.002)] l_pix: 9.9638e-03 
2023-11-09 19:05:52,708 INFO: [Class..][epoch: 61, iter: 331,200, lr:(5.293e-05,)] [eta: 15 days, 21:02:14, time (data): 1.933 (0.002)] l_pix: 1.0134e-02 
2023-11-09 19:09:07,176 INFO: [Class..][epoch: 61, iter: 331,300, lr:(5.279e-05,)] [eta: 15 days, 20:48:20, time (data): 1.944 (0.002)] l_pix: 7.8914e-03 
2023-11-09 19:12:21,014 INFO: [Class..][epoch: 61, iter: 331,400, lr:(5.265e-05,)] [eta: 15 days, 20:33:59, time (data): 1.940 (0.002)] l_pix: 9.1653e-03 
2023-11-09 19:15:34,021 INFO: [Class..][epoch: 61, iter: 331,500, lr:(5.252e-05,)] [eta: 15 days, 20:19:03, time (data): 1.928 (0.002)] l_pix: 1.8166e-02 
2023-11-09 19:18:46,649 INFO: [Class..][epoch: 61, iter: 331,600, lr:(5.238e-05,)] [eta: 15 days, 20:03:56, time (data): 1.927 (0.002)] l_pix: 1.4826e-02 
2023-11-09 19:22:00,668 INFO: [Class..][epoch: 61, iter: 331,700, lr:(5.224e-05,)] [eta: 15 days, 19:50:21, time (data): 1.943 (0.002)] l_pix: 1.3385e-02 
2023-11-09 19:25:13,849 INFO: [Class..][epoch: 61, iter: 331,800, lr:(5.210e-05,)] [eta: 15 days, 19:36:09, time (data): 1.935 (0.002)] l_pix: 9.2234e-03 
2023-11-09 19:28:27,511 INFO: [Class..][epoch: 61, iter: 331,900, lr:(5.196e-05,)] [eta: 15 days, 19:22:35, time (data): 1.938 (0.002)] l_pix: 1.1623e-02 
2023-11-09 19:31:40,745 INFO: [Class..][epoch: 61, iter: 332,000, lr:(5.183e-05,)] [eta: 15 days, 19:08:48, time (data): 1.934 (0.002)] l_pix: 1.1959e-02 
2023-11-09 19:34:53,255 INFO: [Class..][epoch: 61, iter: 332,100, lr:(5.169e-05,)] [eta: 15 days, 18:54:31, time (data): 1.924 (0.002)] l_pix: 1.2645e-02 
2023-11-09 19:38:06,197 INFO: [Class..][epoch: 61, iter: 332,200, lr:(5.155e-05,)] [eta: 15 days, 18:40:49, time (data): 1.928 (0.002)] l_pix: 8.8220e-03 
2023-11-09 19:41:19,570 INFO: [Class..][epoch: 62, iter: 332,300, lr:(5.141e-05,)] [eta: 15 days, 18:27:40, time (data): 1.923 (0.002)] l_pix: 1.2366e-02 
2023-11-09 19:44:32,241 INFO: [Class..][epoch: 62, iter: 332,400, lr:(5.128e-05,)] [eta: 15 days, 18:14:04, time (data): 1.926 (0.002)] l_pix: 9.0051e-03 
2023-11-09 19:47:46,736 INFO: [Class..][epoch: 62, iter: 332,500, lr:(5.114e-05,)] [eta: 15 days, 18:02:14, time (data): 1.941 (0.002)] l_pix: 1.0479e-02 
2023-11-09 19:51:00,408 INFO: [Class..][epoch: 62, iter: 332,600, lr:(5.100e-05,)] [eta: 15 days, 17:49:49, time (data): 1.938 (0.002)] l_pix: 1.2631e-02 
2023-11-09 19:54:13,327 INFO: [Class..][epoch: 62, iter: 332,700, lr:(5.087e-05,)] [eta: 15 days, 17:36:54, time (data): 1.925 (0.002)] l_pix: 1.9271e-02 
2023-11-09 19:57:26,224 INFO: [Class..][epoch: 62, iter: 332,800, lr:(5.073e-05,)] [eta: 15 days, 17:24:06, time (data): 1.928 (0.002)] l_pix: 1.3113e-02 
2023-11-09 20:00:39,225 INFO: [Class..][epoch: 62, iter: 332,900, lr:(5.059e-05,)] [eta: 15 days, 17:11:32, time (data): 1.931 (0.002)] l_pix: 8.3655e-03 
2023-11-09 20:03:52,085 INFO: [Class..][epoch: 62, iter: 333,000, lr:(5.046e-05,)] [eta: 15 days, 16:59:00, time (data): 1.929 (0.002)] l_pix: 1.4289e-02 
2023-11-09 20:07:05,213 INFO: [Class..][epoch: 62, iter: 333,100, lr:(5.032e-05,)] [eta: 15 days, 16:46:50, time (data): 1.938 (0.002)] l_pix: 1.2682e-02 
2023-11-09 20:10:18,689 INFO: [Class..][epoch: 62, iter: 333,200, lr:(5.018e-05,)] [eta: 15 days, 16:35:06, time (data): 1.936 (0.002)] l_pix: 1.4848e-02 
2023-11-09 20:13:32,245 INFO: [Class..][epoch: 62, iter: 333,300, lr:(5.005e-05,)] [eta: 15 days, 16:23:34, time (data): 1.932 (0.002)] l_pix: 1.1195e-02 
2023-11-09 20:16:44,648 INFO: [Class..][epoch: 62, iter: 333,400, lr:(4.991e-05,)] [eta: 15 days, 16:11:11, time (data): 1.926 (0.002)] l_pix: 1.2132e-02 
2023-11-09 20:19:57,223 INFO: [Class..][epoch: 62, iter: 333,500, lr:(4.977e-05,)] [eta: 15 days, 15:59:06, time (data): 1.923 (0.002)] l_pix: 7.7857e-03 
2023-11-09 20:23:10,057 INFO: [Class..][epoch: 62, iter: 333,600, lr:(4.964e-05,)] [eta: 15 days, 15:47:20, time (data): 1.927 (0.002)] l_pix: 1.0582e-02 
2023-11-09 20:26:22,865 INFO: [Class..][epoch: 62, iter: 333,700, lr:(4.950e-05,)] [eta: 15 days, 15:35:41, time (data): 1.929 (0.002)] l_pix: 1.1572e-02 
2023-11-09 20:29:36,371 INFO: [Class..][epoch: 62, iter: 333,800, lr:(4.937e-05,)] [eta: 15 days, 15:24:43, time (data): 1.934 (0.002)] l_pix: 8.4895e-03 
2023-11-09 20:32:50,879 INFO: [Class..][epoch: 62, iter: 333,900, lr:(4.923e-05,)] [eta: 15 days, 15:14:40, time (data): 1.960 (0.002)] l_pix: 1.0602e-02 
2023-11-09 20:36:06,061 INFO: [Class..][epoch: 62, iter: 334,000, lr:(4.910e-05,)] [eta: 15 days, 15:05:15, time (data): 1.954 (0.002)] l_pix: 1.0678e-02 
2023-11-09 20:39:20,830 INFO: [Class..][epoch: 62, iter: 334,100, lr:(4.896e-05,)] [eta: 15 days, 14:55:35, time (data): 1.948 (0.002)] l_pix: 1.3637e-02 
2023-11-09 20:42:35,924 INFO: [Class..][epoch: 62, iter: 334,200, lr:(4.883e-05,)] [eta: 15 days, 14:46:16, time (data): 1.950 (0.002)] l_pix: 9.6259e-03 
2023-11-09 20:45:49,753 INFO: [Class..][epoch: 63, iter: 334,300, lr:(4.869e-05,)] [eta: 15 days, 14:36:03, time (data): 1.934 (0.002)] l_pix: 1.1801e-02 
2023-11-09 20:49:02,929 INFO: [Class..][epoch: 63, iter: 334,400, lr:(4.856e-05,)] [eta: 15 days, 14:25:26, time (data): 1.932 (0.002)] l_pix: 9.1475e-03 
2023-11-09 20:52:17,061 INFO: [Class..][epoch: 63, iter: 334,500, lr:(4.842e-05,)] [eta: 15 days, 14:15:39, time (data): 1.946 (0.002)] l_pix: 1.3788e-02 
2023-11-09 20:55:31,100 INFO: [Class..][epoch: 63, iter: 334,600, lr:(4.829e-05,)] [eta: 15 days, 14:05:53, time (data): 1.942 (0.002)] l_pix: 1.0950e-02 
2023-11-09 20:58:44,379 INFO: [Class..][epoch: 63, iter: 334,700, lr:(4.815e-05,)] [eta: 15 days, 13:55:38, time (data): 1.932 (0.002)] l_pix: 1.0768e-02 
2023-11-09 21:01:57,192 INFO: [Class..][epoch: 63, iter: 334,800, lr:(4.802e-05,)] [eta: 15 days, 13:45:07, time (data): 1.929 (0.002)] l_pix: 1.7647e-02 
2023-11-09 21:05:10,370 INFO: [Class..][epoch: 63, iter: 334,900, lr:(4.789e-05,)] [eta: 15 days, 13:34:59, time (data): 1.934 (0.002)] l_pix: 6.8471e-03 
2023-11-09 21:08:23,415 INFO: [Class..][epoch: 63, iter: 335,000, lr:(4.775e-05,)] [eta: 15 days, 13:24:51, time (data): 1.931 (0.002)] l_pix: 1.2553e-02 
2023-11-09 21:11:36,999 INFO: [Class..][epoch: 63, iter: 335,100, lr:(4.762e-05,)] [eta: 15 days, 13:15:11, time (data): 1.942 (0.002)] l_pix: 1.0375e-02 
2023-11-09 21:14:50,896 INFO: [Class..][epoch: 63, iter: 335,200, lr:(4.748e-05,)] [eta: 15 days, 13:05:51, time (data): 1.940 (0.002)] l_pix: 1.4476e-02 
2023-11-09 21:18:03,834 INFO: [Class..][epoch: 63, iter: 335,300, lr:(4.735e-05,)] [eta: 15 days, 12:55:53, time (data): 1.931 (0.002)] l_pix: 1.1985e-02 
2023-11-09 21:21:16,257 INFO: [Class..][epoch: 63, iter: 335,400, lr:(4.722e-05,)] [eta: 15 days, 12:45:39, time (data): 1.926 (0.002)] l_pix: 1.2654e-02 
2023-11-09 21:24:29,199 INFO: [Class..][epoch: 63, iter: 335,500, lr:(4.708e-05,)] [eta: 15 days, 12:35:52, time (data): 1.936 (0.002)] l_pix: 1.0055e-02 
2023-11-09 21:27:41,746 INFO: [Class..][epoch: 63, iter: 335,600, lr:(4.695e-05,)] [eta: 15 days, 12:25:54, time (data): 1.927 (0.002)] l_pix: 9.6244e-03 
2023-11-09 21:30:54,801 INFO: [Class..][epoch: 63, iter: 335,700, lr:(4.682e-05,)] [eta: 15 days, 12:16:22, time (data): 1.938 (0.002)] l_pix: 1.3010e-02 
2023-11-09 21:34:08,359 INFO: [Class..][epoch: 63, iter: 335,800, lr:(4.668e-05,)] [eta: 15 days, 12:07:16, time (data): 1.936 (0.002)] l_pix: 1.4007e-02 
2023-11-09 21:37:21,386 INFO: [Class..][epoch: 63, iter: 335,900, lr:(4.655e-05,)] [eta: 15 days, 11:57:53, time (data): 1.926 (0.002)] l_pix: 1.8252e-02 
2023-11-09 21:40:33,856 INFO: [Class..][epoch: 63, iter: 336,000, lr:(4.642e-05,)] [eta: 15 days, 11:48:11, time (data): 1.925 (0.002)] l_pix: 1.7217e-02 
2023-11-09 21:43:46,917 INFO: [Class..][epoch: 63, iter: 336,100, lr:(4.629e-05,)] [eta: 15 days, 11:38:58, time (data): 1.938 (0.002)] l_pix: 8.2176e-03 
2023-11-09 21:46:59,570 INFO: [Class..][epoch: 63, iter: 336,200, lr:(4.615e-05,)] [eta: 15 days, 11:29:33, time (data): 1.928 (0.002)] l_pix: 1.3321e-02 
2023-11-09 21:50:13,682 INFO: [Class..][epoch: 64, iter: 336,300, lr:(4.602e-05,)] [eta: 15 days, 11:21:12, time (data): 1.970 (0.039)] l_pix: 1.9598e-02 
2023-11-09 21:53:27,254 INFO: [Class..][epoch: 64, iter: 336,400, lr:(4.589e-05,)] [eta: 15 days, 11:12:32, time (data): 1.941 (0.008)] l_pix: 6.4030e-03 
2023-11-09 21:56:40,768 INFO: [Class..][epoch: 64, iter: 336,500, lr:(4.576e-05,)] [eta: 15 days, 11:03:55, time (data): 1.929 (0.002)] l_pix: 1.5107e-02 
2023-11-09 21:59:53,691 INFO: [Class..][epoch: 64, iter: 336,600, lr:(4.563e-05,)] [eta: 15 days, 10:54:57, time (data): 1.929 (0.002)] l_pix: 1.3948e-02 
2023-11-09 22:03:06,220 INFO: [Class..][epoch: 64, iter: 336,700, lr:(4.549e-05,)] [eta: 15 days, 10:45:48, time (data): 1.919 (0.002)] l_pix: 1.6416e-02 
2023-11-09 22:06:19,057 INFO: [Class..][epoch: 64, iter: 336,800, lr:(4.536e-05,)] [eta: 15 days, 10:36:56, time (data): 1.927 (0.002)] l_pix: 9.9520e-03 
2023-11-09 22:09:32,381 INFO: [Class..][epoch: 64, iter: 336,900, lr:(4.523e-05,)] [eta: 15 days, 10:28:27, time (data): 1.928 (0.003)] l_pix: 1.1502e-02 
2023-11-09 22:12:46,239 INFO: [Class..][epoch: 64, iter: 337,000, lr:(4.510e-05,)] [eta: 15 days, 10:20:22, time (data): 1.937 (0.002)] l_pix: 1.2638e-02 
2023-11-09 22:16:00,584 INFO: [Class..][epoch: 64, iter: 337,100, lr:(4.497e-05,)] [eta: 15 days, 10:12:39, time (data): 1.940 (0.002)] l_pix: 1.3068e-02 
2023-11-09 22:19:13,907 INFO: [Class..][epoch: 64, iter: 337,200, lr:(4.484e-05,)] [eta: 15 days, 10:04:20, time (data): 1.934 (0.002)] l_pix: 1.6758e-02 
2023-11-09 22:22:26,643 INFO: [Class..][epoch: 64, iter: 337,300, lr:(4.471e-05,)] [eta: 15 days, 9:55:43, time (data): 1.935 (0.002)] l_pix: 1.2484e-02 
2023-11-09 22:25:39,804 INFO: [Class..][epoch: 64, iter: 337,400, lr:(4.457e-05,)] [eta: 15 days, 9:47:25, time (data): 1.932 (0.002)] l_pix: 9.7286e-03 
2023-11-09 22:28:52,733 INFO: [Class..][epoch: 64, iter: 337,500, lr:(4.444e-05,)] [eta: 15 days, 9:39:02, time (data): 1.926 (0.002)] l_pix: 8.5357e-03 
2023-11-09 22:32:06,272 INFO: [Class..][epoch: 64, iter: 337,600, lr:(4.431e-05,)] [eta: 15 days, 9:31:05, time (data): 1.934 (0.002)] l_pix: 1.5145e-02 
2023-11-09 22:35:20,160 INFO: [Class..][epoch: 64, iter: 337,700, lr:(4.418e-05,)] [eta: 15 days, 9:23:25, time (data): 1.941 (0.002)] l_pix: 1.0278e-02 
2023-11-09 22:38:33,901 INFO: [Class..][epoch: 64, iter: 337,800, lr:(4.405e-05,)] [eta: 15 days, 9:15:42, time (data): 1.938 (0.002)] l_pix: 1.0074e-02 
2023-11-09 22:41:47,026 INFO: [Class..][epoch: 64, iter: 337,900, lr:(4.392e-05,)] [eta: 15 days, 9:07:39, time (data): 1.935 (0.002)] l_pix: 1.0986e-02 
2023-11-09 22:44:59,936 INFO: [Class..][epoch: 64, iter: 338,000, lr:(4.379e-05,)] [eta: 15 days, 8:59:32, time (data): 1.930 (0.002)] l_pix: 1.5186e-02 
2023-11-09 22:48:13,366 INFO: [Class..][epoch: 64, iter: 338,100, lr:(4.366e-05,)] [eta: 15 days, 8:51:47, time (data): 1.932 (0.002)] l_pix: 1.6570e-02 
2023-11-09 22:51:27,041 INFO: [Class..][epoch: 64, iter: 338,200, lr:(4.353e-05,)] [eta: 15 days, 8:44:14, time (data): 1.936 (0.002)] l_pix: 1.5156e-02 
2023-11-09 22:54:41,272 INFO: [Class..][epoch: 64, iter: 338,300, lr:(4.340e-05,)] [eta: 15 days, 8:37:03, time (data): 1.939 (0.002)] l_pix: 1.1789e-02 
2023-11-09 22:57:56,158 INFO: [Class..][epoch: 65, iter: 338,400, lr:(4.327e-05,)] [eta: 15 days, 8:30:19, time (data): 1.948 (0.009)] l_pix: 1.3856e-02 
2023-11-09 23:01:09,591 INFO: [Class..][epoch: 65, iter: 338,500, lr:(4.315e-05,)] [eta: 15 days, 8:22:45, time (data): 1.925 (0.002)] l_pix: 1.9902e-02 
2023-11-09 23:04:22,891 INFO: [Class..][epoch: 65, iter: 338,600, lr:(4.302e-05,)] [eta: 15 days, 8:15:10, time (data): 1.932 (0.002)] l_pix: 1.0840e-02 
2023-11-09 23:07:36,591 INFO: [Class..][epoch: 65, iter: 338,700, lr:(4.289e-05,)] [eta: 15 days, 8:07:51, time (data): 1.935 (0.002)] l_pix: 9.8453e-03 
2023-11-09 23:10:50,757 INFO: [Class..][epoch: 65, iter: 338,800, lr:(4.276e-05,)] [eta: 15 days, 8:00:51, time (data): 1.941 (0.003)] l_pix: 9.1849e-03 
2023-11-09 23:14:06,386 INFO: [Class..][epoch: 65, iter: 338,900, lr:(4.263e-05,)] [eta: 15 days, 7:54:45, time (data): 1.958 (0.003)] l_pix: 1.1206e-02 
2023-11-09 23:17:22,365 INFO: [Class..][epoch: 65, iter: 339,000, lr:(4.250e-05,)] [eta: 15 days, 7:48:53, time (data): 1.960 (0.003)] l_pix: 1.1363e-02 
2023-11-09 23:20:37,635 INFO: [Class..][epoch: 65, iter: 339,100, lr:(4.237e-05,)] [eta: 15 days, 7:42:37, time (data): 1.940 (0.003)] l_pix: 1.2982e-02 
2023-11-09 23:23:51,426 INFO: [Class..][epoch: 65, iter: 339,200, lr:(4.224e-05,)] [eta: 15 days, 7:35:33, time (data): 1.938 (0.002)] l_pix: 8.8778e-03 
2023-11-09 23:27:04,903 INFO: [Class..][epoch: 65, iter: 339,300, lr:(4.212e-05,)] [eta: 15 days, 7:28:21, time (data): 1.926 (0.002)] l_pix: 9.1268e-03 
2023-11-09 23:30:18,100 INFO: [Class..][epoch: 65, iter: 339,400, lr:(4.199e-05,)] [eta: 15 days, 7:21:01, time (data): 1.932 (0.002)] l_pix: 1.6014e-02 
2023-11-09 23:33:32,068 INFO: [Class..][epoch: 65, iter: 339,500, lr:(4.186e-05,)] [eta: 15 days, 7:14:10, time (data): 1.966 (0.003)] l_pix: 1.2941e-02 
2023-11-09 23:36:45,802 INFO: [Class..][epoch: 65, iter: 339,600, lr:(4.173e-05,)] [eta: 15 days, 7:07:13, time (data): 1.938 (0.002)] l_pix: 1.6382e-02 
2023-11-09 23:39:58,744 INFO: [Class..][epoch: 65, iter: 339,700, lr:(4.160e-05,)] [eta: 15 days, 6:59:53, time (data): 1.940 (0.002)] l_pix: 1.1863e-02 
2023-11-09 23:43:11,354 INFO: [Class..][epoch: 65, iter: 339,800, lr:(4.148e-05,)] [eta: 15 days, 6:52:23, time (data): 1.926 (0.002)] l_pix: 1.6073e-02 
2023-11-09 23:46:24,243 INFO: [Class..][epoch: 65, iter: 339,900, lr:(4.135e-05,)] [eta: 15 days, 6:45:05, time (data): 1.914 (0.002)] l_pix: 1.5757e-02 
2023-11-09 23:49:37,094 INFO: [Class..][epoch: 65, iter: 340,000, lr:(4.122e-05,)] [eta: 15 days, 6:37:49, time (data): 1.928 (0.002)] l_pix: 9.2776e-03 
2023-11-09 23:49:37,095 INFO: Saving models and training states.
2023-11-09 23:49:37,786 WARNING: Multiple validation datasets are *only* supported by SRModel.
2023-11-09 23:49:40,633 INFO: Validation Set5
	 # psnr: 38.2822	Best: 38.2822 @ 340000 iter
	 # ssim: 0.9623	Best: 0.9623 @ 340000 iter

2023-11-09 23:49:58,363 INFO: Validation Set14
	 # psnr: 34.0397	Best: 34.0397 @ 340000 iter
	 # ssim: 0.9228	Best: 0.9228 @ 340000 iter

2023-11-09 23:51:09,805 INFO: Validation BSD100
	 # psnr: 32.4398	Best: 32.4398 @ 340000 iter
	 # ssim: 0.9036	Best: 0.9036 @ 340000 iter

2023-11-09 23:59:19,573 INFO: Validation Urban100
	 # psnr: 33.3460	Best: 33.3460 @ 340000 iter
	 # ssim: 0.9389	Best: 0.9389 @ 340000 iter

2023-11-10 00:10:16,918 INFO: Validation Manga109
	 # psnr: 39.5620	Best: 39.5620 @ 340000 iter
	 # ssim: 0.9792	Best: 0.9792 @ 340000 iter

2023-11-10 00:13:30,709 INFO: [Class..][epoch: 65, iter: 340,100, lr:(4.110e-05,)] [eta: 15 days, 17:49:28, time (data): 1.933 (0.002)] l_pix: 1.1017e-02 
2023-11-10 00:16:44,639 INFO: [Class..][epoch: 65, iter: 340,200, lr:(4.097e-05,)] [eta: 15 days, 17:39:24, time (data): 1.939 (0.002)] l_pix: 1.3692e-02 
2023-11-10 00:19:57,460 INFO: [Class..][epoch: 65, iter: 340,300, lr:(4.084e-05,)] [eta: 15 days, 17:28:48, time (data): 1.934 (0.002)] l_pix: 1.1776e-02 
2023-11-10 00:23:11,530 INFO: [Class..][epoch: 66, iter: 340,400, lr:(4.072e-05,)] [eta: 15 days, 17:18:56, time (data): 1.941 (0.011)] l_pix: 1.0601e-02 
2023-11-10 00:26:24,822 INFO: [Class..][epoch: 66, iter: 340,500, lr:(4.059e-05,)] [eta: 15 days, 17:08:44, time (data): 1.937 (0.006)] l_pix: 9.3039e-03 
2023-11-10 00:29:37,553 INFO: [Class..][epoch: 66, iter: 340,600, lr:(4.046e-05,)] [eta: 15 days, 16:58:17, time (data): 1.928 (0.002)] l_pix: 1.3439e-02 
2023-11-10 00:32:50,914 INFO: [Class..][epoch: 66, iter: 340,700, lr:(4.034e-05,)] [eta: 15 days, 16:48:15, time (data): 1.931 (0.002)] l_pix: 1.5674e-02 
2023-11-10 00:36:04,868 INFO: [Class..][epoch: 66, iter: 340,800, lr:(4.021e-05,)] [eta: 15 days, 16:38:35, time (data): 1.939 (0.002)] l_pix: 1.6628e-02 
2023-11-10 00:39:17,977 INFO: [Class..][epoch: 66, iter: 340,900, lr:(4.008e-05,)] [eta: 15 days, 16:28:33, time (data): 1.935 (0.002)] l_pix: 1.5852e-02 
2023-11-10 00:42:30,572 INFO: [Class..][epoch: 66, iter: 341,000, lr:(3.996e-05,)] [eta: 15 days, 16:18:18, time (data): 1.926 (0.002)] l_pix: 1.2857e-02 
2023-11-10 00:45:43,421 INFO: [Class..][epoch: 66, iter: 341,100, lr:(3.983e-05,)] [eta: 15 days, 16:08:16, time (data): 1.927 (0.002)] l_pix: 1.2997e-02 
2023-11-10 00:48:56,236 INFO: [Class..][epoch: 66, iter: 341,200, lr:(3.971e-05,)] [eta: 15 days, 15:58:16, time (data): 1.928 (0.002)] l_pix: 7.8748e-03 
2023-11-10 00:52:10,382 INFO: [Class..][epoch: 66, iter: 341,300, lr:(3.958e-05,)] [eta: 15 days, 15:49:01, time (data): 1.935 (0.002)] l_pix: 1.6321e-02 
2023-11-10 00:55:24,764 INFO: [Class..][epoch: 66, iter: 341,400, lr:(3.946e-05,)] [eta: 15 days, 15:39:56, time (data): 1.944 (0.002)] l_pix: 1.2531e-02 
2023-11-10 00:58:38,774 INFO: [Class..][epoch: 66, iter: 341,500, lr:(3.933e-05,)] [eta: 15 days, 15:30:44, time (data): 1.942 (0.002)] l_pix: 1.9248e-02 
2023-11-10 01:01:52,289 INFO: [Class..][epoch: 66, iter: 341,600, lr:(3.921e-05,)] [eta: 15 days, 15:21:20, time (data): 1.935 (0.002)] l_pix: 1.3570e-02 
2023-11-10 01:05:05,378 INFO: [Class..][epoch: 66, iter: 341,700, lr:(3.908e-05,)] [eta: 15 days, 15:11:46, time (data): 1.933 (0.002)] l_pix: 9.3959e-03 
2023-11-10 01:08:18,550 INFO: [Class..][epoch: 66, iter: 341,800, lr:(3.896e-05,)] [eta: 15 days, 15:02:18, time (data): 1.932 (0.002)] l_pix: 6.3147e-03 
2023-11-10 01:11:31,803 INFO: [Class..][epoch: 66, iter: 341,900, lr:(3.883e-05,)] [eta: 15 days, 14:52:56, time (data): 1.932 (0.002)] l_pix: 1.3387e-02 
2023-11-10 01:14:46,053 INFO: [Class..][epoch: 66, iter: 342,000, lr:(3.871e-05,)] [eta: 15 days, 14:44:07, time (data): 1.942 (0.002)] l_pix: 1.7035e-02 
2023-11-10 01:18:00,001 INFO: [Class..][epoch: 66, iter: 342,100, lr:(3.859e-05,)] [eta: 15 days, 14:35:13, time (data): 1.941 (0.002)] l_pix: 8.6108e-03 
2023-11-10 01:21:13,953 INFO: [Class..][epoch: 66, iter: 342,200, lr:(3.846e-05,)] [eta: 15 days, 14:26:21, time (data): 1.939 (0.002)] l_pix: 1.4344e-02 
2023-11-10 01:24:27,867 INFO: [Class..][epoch: 66, iter: 342,300, lr:(3.834e-05,)] [eta: 15 days, 14:17:32, time (data): 1.939 (0.002)] l_pix: 1.6833e-02 
2023-11-10 01:27:41,498 INFO: [Class..][epoch: 66, iter: 342,400, lr:(3.822e-05,)] [eta: 15 days, 14:08:37, time (data): 1.937 (0.003)] l_pix: 1.1685e-02 
2023-11-10 01:30:56,163 INFO: [Class..][epoch: 67, iter: 342,500, lr:(3.809e-05,)] [eta: 15 days, 14:00:15, time (data): 1.942 (0.007)] l_pix: 1.4941e-02 
2023-11-10 01:34:10,446 INFO: [Class..][epoch: 67, iter: 342,600, lr:(3.797e-05,)] [eta: 15 days, 13:51:45, time (data): 1.944 (0.002)] l_pix: 1.8541e-02 
2023-11-10 01:37:25,224 INFO: [Class..][epoch: 67, iter: 342,700, lr:(3.785e-05,)] [eta: 15 days, 13:43:32, time (data): 1.946 (0.003)] l_pix: 1.6294e-02 
